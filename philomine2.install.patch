diff -Nuar philomine2/cgi-bin/config.pl philomine2patched/cgi-bin/config.pl
--- philomine2/cgi-bin/config.pl	2008-06-13 16:58:08.000000000 -0500
+++ philomine2patched/cgi-bin/config.pl	2018-07-30 15:34:07.897618391 -0500
@@ -4,15 +4,15 @@
 use DBI;
 
 # PHILOLOGIC CONFIG
-$PHILOSITECFG = "/etc/philologic";
+$PHILOSITECFG = "/etc/philologic31";
 do "$PHILOSITECFG/dbnames";
-do "$PHILOSITECFG/philologic.cfg";
+do "$PHILOSITECFG/philologic31.cfg";
 
 # PHILOMINE CONFIG
-require "/etc/philologic/philomine.cfg";
+require "/etc/philologic31/philomine.cfg";
 
 # MYSQL CONFIG
-$dbh = DBI->connect("DBI:mysql:$MYSQLDB", $MYSQLUSER, $MYSQLPASS);
+$dbh = DBI->connect("DBI:mysql:$MYSQLDB;mysql_socket=/var/lib/mysql/mysql.sock", $MYSQLUSER, $MYSQLPASS);
 
 # Available featuresets
 @featuresets = ('SURFACE', 'LEMMA', 'BILEMMA', 'BIGRAM');
diff -Nuar philomine2/cgi-bin/feature_functions.pl philomine2patched/cgi-bin/feature_functions.pl
--- philomine2/cgi-bin/feature_functions.pl	2008-06-16 12:19:51.000000000 -0500
+++ philomine2patched/cgi-bin/feature_functions.pl	2018-08-11 17:00:34.448296712 -0500
@@ -29,7 +29,7 @@
 ################################################################################
 sub getAndFilterFeatures() {
 	
-	my $debug = 50;
+	my $debug = 99;
 	
 	my $params = $_[0];
 	my $instances = $_[1];
diff -Nuar philomine2/cgi-bin/form_components/form_functions.pl philomine2patched/cgi-bin/form_components/form_functions.pl
--- philomine2/cgi-bin/form_components/form_functions.pl	2008-06-13 16:03:15.000000000 -0500
+++ philomine2patched/cgi-bin/form_components/form_functions.pl	2018-07-30 19:23:21.220967984 -0500
@@ -32,7 +32,7 @@
 
 sub corporaSettings() {
 
-	my $debug = 0;
+	my $debug = 99;
 
 	my $params = $_[0];
 	
@@ -81,7 +81,7 @@
 
 sub corpusSettings() {
 	
-	my $debug = 0;
+	my $debug = 99;
 
 	my $params = $_[0];
 	my $corpus_id = $_[1];
@@ -175,7 +175,7 @@
 
 sub taskSelect() {
 	
-	my $debug = 0;
+	my $debug = 99;
 	
 	my $params = $_[0];
 	
@@ -310,14 +310,17 @@
 	
 	my $dbname = $params->{'c' . $corpus_id . '_dbname'};
 	
-	&bugger($debug, "DBNAME: $dbanme<br>");
+	&bugger($debug, "DBNAME: $dbname<br>");
 	
 	my $output = '<select name="c' . $corpus_id . '_dbname" id="c' . $corpus_id . '_dbname" class="dbnameselect"><option value="">Select...</option>' . "\n";
 	
 	# Go through the PhiloLogic install directory and print a select
 	# option for each database that has a philominesubs.pl in /lib
-	
+
+	&bugger($debug, "PHILODATADIR: $PHILODATADIR<br>");
+
 	opendir(DIR, "$PHILODATADIR/databases");
+#	opendir(DIR, "/var/lib/philologic31/databases");
 	my @databases = grep(/^[^\.]/, readdir(DIR));
 	closedir(DIR);
 
@@ -326,6 +329,8 @@
 		my $selected_string = '';
 		
 		if (-e "$PHILODATADIR/databases/$db/lib/philominesubs.pl") {
+#		if (-f '/var/lib/philologic/Makefile') {
+			&bugger($debug, "databases: $PHILODATADIR/databases/$db/lib/philominesubs.pl<br>");
 			if ($db eq $dbname) {
 				$selected_string = " selected";
 			} else {
@@ -348,7 +353,7 @@
 
 sub selectFromQuery() {	
 	
-	$debug = 0;
+	$debug = 99;
 	
 	my $dbh = $_[0];
 	my $sql = $_[1];
@@ -478,4 +483,4 @@
 
 
 
-1;
\ No newline at end of file
+1;
diff -Nuar philomine2/cgi-bin/form_components/get_part.pl philomine2patched/cgi-bin/form_components/get_part.pl
--- philomine2/cgi-bin/form_components/get_part.pl	2008-06-13 16:03:15.000000000 -0500
+++ philomine2patched/cgi-bin/form_components/get_part.pl	2018-07-30 16:14:43.124276924 -0500
@@ -10,7 +10,7 @@
 &prepareParams(\%params);
 &setParamsDefaults(\%params, \%defaults);
 
-my $debug = 0;
+my $debug = 59;
 
 print header;
 
diff -Nuar philomine2/cgi-bin/instance_functions.pl philomine2patched/cgi-bin/instance_functions.pl
--- philomine2/cgi-bin/instance_functions.pl	2008-06-13 16:03:18.000000000 -0500
+++ philomine2patched/cgi-bin/instance_functions.pl	2018-08-13 18:50:17.566785273 -0500
@@ -36,10 +36,10 @@
 	my $instances = $_[1];
 	my $corpus = $_[2];
 	my $classes_by_instance = $_[3];
-	
+
 	my @sqlargs = ();
 	my $dbname = $params->{$corpus . '_dbname'};
-	
+
 	# Load in the minefields and subminefields from the philimesubs in the appropriate
 	# philologic database directory
 	require "$PHILODATADIR/databases/$dbname/lib/philominesubs.pl";
@@ -307,6 +307,7 @@
 ################################################################################
 sub instanceWordCountFilter() {
 
+
 	my $debug =0;
 
 	my $params = $_[0];
@@ -336,7 +337,7 @@
 			if ($instances->[0] =~ /:/) {
 				# DIV level instances, or DOC-level with multiple divs		
 				my $count_file = $SYSTEM_DIR . '/' . $divtotalfiles{$featureset};
-				&bugger($debug, "Instnace is div-level<br>");
+				&bugger($debug, "Instance is div-level<br>");
 				&bugger($debug, "Countfile: $count_file<br><br>");
 				open COUNTIN, $count_file;
 				while (my $line = <COUNTIN>) {
@@ -349,7 +350,7 @@
 			} else {
 				# DOC level instances, no div criteria
 				my $count_file = $SYSTEM_DIR . '/' . $doctotalfiles{$featureset};
-				&bugger($debug, "Instnace is doc-level, no div criteria<br>");
+				&bugger($debug, "Instance is doc-level, no div criteria<br>");
 				&bugger($debug, "Countfile: $count_file<br><br>");
 				open COUNTIN, $count_file;
 				while (my $line = <COUNTIN>) {
diff -Nuar philomine2/cgi-bin/instance_functions.pl.08.13.2018 philomine2patched/cgi-bin/instance_functions.pl.08.13.2018
--- philomine2/cgi-bin/instance_functions.pl.08.13.2018	1969-12-31 18:00:00.000000000 -0600
+++ philomine2patched/cgi-bin/instance_functions.pl.08.13.2018	2018-07-28 16:46:40.942340712 -0500
@@ -0,0 +1,637 @@
+# We should really be reading this in from philo-db.cfg somehow
+$BIBOPS{"title"}="regexp";
+$BIBOPS{"author"}="regexp";
+$BIBOPS{"date"}="numeric";
+$BIBOPS{"createdate"}="numeric";
+$BIBOPS{"genre"}="regexp";
+$BIBOPS{"publisher"}="regexp";
+$BIBOPS{"pubplace"}="regexp";
+$BIBOPS{"extent"}="regexp";
+$BIBOPS{"editor"}="regexp";
+$BIBOPS{"pubdate"}="regexp";
+$BIBOPS{"authordates"}="regexp";
+$BIBOPS{"keywords"}="regexp";
+$BIBOPS{"language"}="regexp";
+$BIBOPS{"collection"}="regexp";
+$BIBOPS{"gender"}="regexp";
+$BIBOPS{"sourcenote"}="regexp";
+$BIBOPS{"period"}="regexp";
+$BIBOPS{"shrtcite"}="regexp";
+$BIBOPS{"filename"}="regexp";
+$BIBOPS{"filesize"}="numeric";
+$BIBOPS{"philodocid"}="exact";
+$BIBOPS{"keywords"}="regexp";
+$BIBOPS{"language"}="regexp";
+
+################################################################################
+# sub getInstances
+################################################################################
+# Send the bibliographic parameters to gimme and get back a list of documents
+################################################################################
+sub getInstances { 
+
+	my $debug = 0;
+
+	my $params = $_[0];
+	my $instances = $_[1];
+	my $corpus = $_[2];
+	my $classes_by_instance = $_[3];
+	
+	my @sqlargs = ();
+	my $dbname = $params->{$corpus . '_dbname'};
+	
+	# Load in the minefields and subminefields from the philimesubs in the appropriate
+	# philologic database directory
+	require "$PHILODATADIR/databases/$dbname/lib/philominesubs.pl";
+	&bugger($debug, "Reuired: $PHILODATADIR/databases/$dbname/lib/philominesubs.pl<br>");
+
+	# Document-level metadata limiters
+	foreach my $field (keys(%minefields)) {
+		if (exists($params->{$corpus . '_' . $field}) && ($params->{$corpus . '_' . $field} ne "")) {
+			push(@sqlargs, '(' . formatSQLParams($params->{$corpus . '_' . $field}, $dbname . '.' . $field) . ')');
+			$corpus_doc_args .= '&' . &uri_escape($field) . '=' . &uri_escape($params->{$corpus . '_' . $field});
+		}
+	}
+
+	# Sub-document (div) level selectors
+	my $corpus_div_args = '';
+	my $have_div_args = 0;
+	foreach my $field (keys(%subminefields)) {
+		if (exists($params->{$corpus . '_' . $field}) && ($params->{$corpus . '_' . $field} ne "")) {
+			push(@sqlargs, '(' . formatSQLParams($params->{$corpus . '_' . $field}, $dbname . 'dividx.' . $field) . ')');
+			$corpus_div_args .= '&' . &uri_escape($field) . '=' . &uri_escape($params->{$corpus . '_' . $field});
+			$have_div_args = 1;
+			
+		}
+	}
+
+	$params->{$corpus . '_div_args'} = $corpus_div_args;
+	$params->{$corpus . '_doc_args'} = $corpus_doc_args;
+
+	&bugger($debug, "Class $corpus div args: " . 	$params->{$corpus . '_div_args'} . "<br>");
+	&bugger($debug, "getInstances: \$gimme_arg: $gimme_arg<br>");
+
+	# INSTANCE TYPE
+	# $instance_type is either 'document', 'div' or 'multidiv' (if we have document level instances
+	# with div-level criteria, we end up with a collection of divs from a single document as our instance)
+	my $instance_type = '';
+	if ($params->{'INSTANCELEVEL'} eq "div") {
+		$instance_type = 'div';
+	} elsif ($params->{'INSTANCELEVEL'} eq "document") {
+		if ($have_div_args) {
+			$instance_type = 'multidiv';
+		} else {
+			$instance_type = 'document';
+		}
+	}
+
+	&bugger($debug, "<br><br>Instance type determined: $instance_type<br><br>");
+
+	my $sql_where = '';
+	if (@sqlargs > 0) {
+		$sql_where .= ' WHERE ' . join(' AND ', @sqlargs);
+	}
+
+	# CLASS FIELD
+	# Do we have a class field we need to capture? If not, capture the coprus label,
+	# which IS the class for binary classification and other types of runs
+	my $class_field = '';
+	if ($params->{'TASK'} eq 'predict_on_unseen' || $params->{'TASK'} eq 'vectorspace_knn') {
+		if ($params->{'CLASSIFYON'} eq '') {
+			&throwError("Please choose a field to classify on for predicting on unseen data.");
+		} else {
+			$class_field = ', ' . $params->{'CLASSIFYON'};
+		}
+	} else {
+		$class_field = ", '$corpus'";
+	}
+	
+	&bugger($debug, "Class field found: $class_field<br>");
+	
+	# DESCRIPTOR FIELDS
+	# In philominesubs.pl, @doc_title_fields and @div_title_fields are set to 
+	if ($instance_type eq 'div') {
+		$descriptor_sql = 'CONCAT(' . join(", ' - ', ", @div_descriptor_fields) . ') AS descriptor';
+	} elsif ($instance_type eq 'document' || $instance_type eq 'multidiv') {
+		$descriptor_sql = 'CONCAT(' . join(", ' - ', ", @doc_descriptor_fields) . ') AS descriptor';
+	}
+		
+	# Do we need to join the divindex table? Yes, if our instance level is div,
+	# or if we have div-level criteria
+	my $sql = '';
+	if ($instance_type eq 'div' || $instance_type eq 'multidiv') {
+		$sql = "SELECT title, philodocid, dgphilodivid$class_field, $descriptor_sql
+				FROM $dbname
+				LEFT JOIN $dbname" . "dividx ON ($dbname" . ".philodocid = $dbname" . "dividx.dgphilodocid)
+				$join_sql
+				$sql_where
+				ORDER BY dgphilodivid";
+
+	} elsif ($instance_type eq 'document') {
+		$sql = "SELECT title, philodocid$class_field, $descriptor_sql
+				FROM $dbname
+				$sql_where
+				ORDER BY philodocid";
+	}
+	
+	&bugger($debug, "SQL:xxx $sql  xxx<br>");
+
+	my $result = $dbh->prepare($sql);
+	$result->execute;
+
+	print INSTANCESOUT "$corpus: $sql<br>";
+
+	my $title = '';
+	my $philodocid = '';
+	my $dgphilodivid = '';
+	my $last_title = '';
+
+	# DIV instances
+	if ($instance_type eq 'div') {
+		while ((my $title, my $philodocid, my $dgphilodivid, my $class_label, my $descriptor) = $result->fetchrow_array()) {
+			$instances->{$dgphilodivid} = $descriptor;
+			$classes_by_instance->{$dgphilodivid} = $class_label;
+			&bugger($debug, "Adding to instances: div level " . $dgphilodivid . '::' . $title . ' class: ' . $classes_by_instance->{$dgphilodivid} . '<br>');
+		}
+
+	# DOC instances with div criteria
+	# We are doing instances by document level, but using div-level criteria, so we need to 
+	# store instances as comma-delimited groups of divs grouped by document
+	} elsif ($instance_type eq 'multidiv') {
+		my $previous_doc = "NONE";
+		my @instance_divs = ();
+
+		# Accumulate the divs for each philodocid
+		while ((my $title, my $philodocid, my $dgphilodivid, my $class_label, my $descriptor) = $result->fetchrow_array()) {
+			&bugger($debug, "Title: $title philodcid: $philodocid dgphilodivid: $dgphilodivid class_label: $class_label<br>");
+			if ($class_label eq '') {
+				$class_label = 'NA';
+			}
+			if ($previous_doc eq $philodocid || $previous_doc eq "NONE") {
+				push(@instance_divs, $dgphilodivid);
+			} else {
+				my $instance_string = join(',', @instance_divs);
+				$instances->{$instance_string} = scalar(@instance_divs) . ' divs from ' . $descriptor;
+				@instance_divs = ();
+				push(@instance_divs, $dgphilodivid);
+				$classes_by_instance->{$instance_string} = $class_label;
+				&bugger($debug, "Adding inside loop, instance $instance_string class label: $class_label<br>");
+			}
+			$previous_doc = $philodocid;
+			$last_title = $title;
+			$last_class_label = $class_label;
+		}
+
+		my $instance_string = join(',', @instance_divs);
+		$instances->{$instance_string} = scalar(@instance_divs) . ' from ' . $last_title;
+		$classes_by_instance->{$instance_string} = $last_class_label;
+		&bugger($debug, "DOC LEVEL, with div crit, Instances -- doc: $instance_string: " . $instances->{$instance_string} . " class: $last_class_label<br>");
+
+	# DOC level instances, no div-level criteria
+	} elsif ($instance_type eq 'document') {
+		while ((my $title, my $philodocid, my $class_label, my $descriptor) = $result->fetchrow_array()) {		
+			$instances->{$philodocid} = $descriptor;
+			$classes_by_instance->{$philodocid} = $class_label;
+			&bugger($debug, "DOC LEVEL Instances -- doc: " . $instances->{$philodocid} . " class: " . $classes_by_instance->{$philodocid} . " $class_label<br>");
+		}
+
+    }
+
+	if ($debug eq $debug_true_value) {
+		print "<br><br><br>";
+		foreach my $instance (keys(%$instances)) {
+			print "Instance: $instance value: " . $instances->{$instance} . " class: " . $classes_by_instance->{$instance} . "<br>";
+		}
+		print "<br><br><br>";
+	}
+	
+	if (scalar(keys(%$instances)) == 0) {
+		&throwError("No instances were found for class $corpus using SQL:<br>$sql<br><br> Please change your criteria and try again.");
+	}
+}
+
+################################################################################
+# sub formatSQLParam - format part of an SQL query
+################################################################################
+################################################################################
+sub formatSQLParams() {
+
+	my $value = $_[0];
+	my $field = $_[1];
+	
+	my $sql = '';
+
+	my $criterion = '';
+	my $operator = '';
+	my $last_operator = '';
+	my $remainder = '';
+	
+	while ($value =~ /^(.+?)( AND | OR )(\s*\S+.*)$/) {
+		$criterion = $1;
+		$operator = $2;
+		$value = $3;
+		
+		$sql .= $last_operator . formatSQLParam($criterion, $field);
+		
+		$last_operator = $operator;
+	}
+	
+	$sql .= $operator . formatSQLParam($value, $field);	
+	
+	return $sql;
+}
+
+sub formatSQLParam() {
+	
+	my $debug = 0;
+	
+	my $value = $_[0];
+	my $field = $_[1];
+	
+	my $sql = '';
+	my $not = '';
+	if ($value =~ /^\s*NOT/) {
+		$not = ' NOT ';
+		$value =~ s/^\s*NOT\s*//g;
+	} else {
+		$not = '';
+	}
+	
+	# In philo-db.cfg for each resource, there are some BIBOPS set that
+	# tell us whether the field is a numeric one
+	my $plainfield = $field;
+	$plainfield =~ s/^.*\.(.*?)$/\1/g;
+	&bugger($debug, "formatSQLParam: value: $value field: $field plainfield: $plainfield<br>");
+	
+	if ($BIBOPS{$plainfield} eq 'numeric') {
+		&bugger($debug, "formatSQLParam: $field is numeric<br>");
+		if ($value =~ /^(.*)\-(.*)$/) {
+			my $start = $1;
+			my $end = $2;
+			$sql .= "$field >= $start AND $field <= $end";
+		} else {
+			$sql .= "$field = $value";
+		}
+	} else {
+		if ($value =~ /^[\'a-z0-9A-Z\177-\377\s]*$/) {
+			$sql .= "$field$not LIKE '%" . $value . "%'";
+		} else {
+			$sql .= "$field$not REGEXP '" . $value . "'";
+		}
+	}
+	return $sql;
+}
+
+################################################################################
+# sub filterInstances
+################################################################################
+# Just a shell to call instanceWordCountFilter, if we ever add more instance
+# filters we'll call them here as well.
+################################################################################
+sub filterInstances() {
+
+	my $params = $_[0];
+	my $classes = $_[1];
+	my $instances = $_[2];
+	local *INSTANCESOUT = $_[3];
+
+	return instanceWordCountFilter($params, $classes, $instances, *INSTANCESOUT);
+}
+
+
+################################################################################
+# sub instanceWordCountFilter
+################################################################################
+# Take an array of pointers to instance arrays and remove those instances that
+# do not meet the criteria for number of words per instance
+################################################################################
+sub instanceWordCountFilter() {
+
+	my $debug =0;
+
+	my $params = $_[0];
+	my $corpora = $_[1];
+	my $instances = $_[2];
+	local *INSTANCESOUT = $_[3];
+
+	# Create an array that gives the total feature count per instance by reading
+	# in the word counts by docid from the philo system directory.
+
+	# There are three possibilities for what we can see in an instance...
+	# 1) philodocid - doc level instances
+	# 2) single dgphilodivid - div level instances, or doc level instances with div criteria
+	# 3) multiple dgphilodivids - doc level instances with div criteria
+
+	my %instance_counts = ();
+
+	&bugger($debug, "Starting instanceWordCOuntFiler with " . scalar(keys(%{$corpora->{'c1'}})) . " instances in c1<br>");
+
+	# Total all the features for each featureset
+	foreach $featureset (@featuresets) {
+
+		&bugger($debug, "Featureset: $featureset<br>");
+
+		if (exists($params->{'FEATURESET' . $featureset})) {
+
+			if ($instances->[0] =~ /:/) {
+				# DIV level instances, or DOC-level with multiple divs		
+				my $count_file = $SYSTEM_DIR . '/' . $divtotalfiles{$featureset};
+				&bugger($debug, "Instnace is div-level<br>");
+				&bugger($debug, "Countfile: $count_file<br><br>");
+				open COUNTIN, $count_file;
+				while (my $line = <COUNTIN>) {
+					if ($line =~ /^([\d:]+)\s+(.*)$/) {
+						&bugger($debug, "Line in: $1 xxx $2<br><br>");
+						$instance_counts{$1} += $2;
+					}
+				}
+				close COUNTIN;
+			} else {
+				# DOC level instances, no div criteria
+				my $count_file = $SYSTEM_DIR . '/' . $doctotalfiles{$featureset};
+				&bugger($debug, "Instnace is doc-level, no div criteria<br>");
+				&bugger($debug, "Countfile: $count_file<br><br>");
+				open COUNTIN, $count_file;
+				while (my $line = <COUNTIN>) {
+					if ($line =~ /^(\d+)(:\d+)*\s+(.*)$/) {
+						&bugger($debug, "Line in: $1 xxx $2 xxx $3<br><br>");
+						$instance_counts{$1} += $3;
+					}
+				}
+				close COUNTIN;
+			}
+		}
+	}
+	
+	# Find out which filters are set
+	my $min_word_count = 0;
+	my $max_word_count = 0;
+
+	if (exists($params->{'MINFEATURESTOTALPERINSTANCE'}) && ($params->{'MINFEATURESTOTALPERINSTANCE'} ne '') ) {
+		$min_word_count = $params->{'MINFEATURESTOTALPERINSTANCE'};
+	} else {
+		$min_word_count = 1;
+	}
+	
+	if (exists($params->{'MAXFEATURESTOTALPERINSTANCE'}) && ($params->{'MAXFEATURESTOTALPERINSTANCE'} ne '') ) {
+		$max_word_count = $params->{'MAXFEATURESTOTALPERINSTANCE'};
+		&bugger($debug, "Setting max_word_count: $max_word_count<br><br>");
+	}
+
+	# Run through the instances and remove those that don't meet the criteria	
+	my $deleted_instance_under_min_count = 0;
+	my $deleted_instance_over_max_count = 0;
+	my %under_min_deletion_counts = ();
+	my %over_max_deletion_counts = ();
+
+	foreach my $corpus (keys(%$corpora)) {
+		$under_min_deletion_counts{$corpus} = 0;
+		$over_max_deletion_counts{$corpus} = 0;
+		foreach my $instance_id (keys(%{$corpora->{$corpus}})) {
+			my $instance = $instances->[$instance_id];
+			if ($min_word_count && ($instance_counts{$instance} < $min_word_count) ) {
+				delete $corpora->{$corpus}{$instance_id};
+				$under_min_deletion_counts{$corpus}++;
+				&bugger($debug, "Deleting corpus: $corpus instance $instance value: " . $instance_counts{$instance} . " \$under_min_deletion_counts{\$corpus} = " . $under_min_deletion_counts{$corpus} . "<br>");
+			}
+			if ($max_word_count && ($instance_counts{$instance} > $max_word_count) ) {
+				delete $corpora->{$corpus}{$instance_id};
+				$over_max_deletion_counts{$corpus}++;
+				&bugger($debug, "Deleting corpus: $corpus instance $instance value: " . $instance_counts{$instance} . " \$over_max_deletion_counts{\$class} = " . $over_max_deletion_counts{$class} . "<br>");
+			}
+		}
+	}
+	
+	if ($min_word_count) {
+		my $min_count_deletion_total = 0;
+		print INSTANCESOUT "<tr><th>Deleted < $min_word_count features</th>";
+		foreach my $corpus (sort(keys(%$corpora))) {
+			print INSTANCESOUT '<td>' . &formatDeletedNumber($under_min_deletion_counts{$corpus})  . '</td>';
+			$min_count_deletion_total += $under_min_deletion_counts{$corpus};
+		}
+		print INSTANCESOUT '<td>' . &formatDeletedNumber($min_count_deletion_total) . '</td></tr>';
+	}
+
+	if ($max_word_count) {
+		my $max_count_deletion_total = 0;
+		print INSTANCESOUT "<tr><th>Deleted > $max_word_count features</th>";
+		foreach my $corpus (sort(keys(%$corpora))) {
+			print INSTANCESOUT '<td>' . &formatDeletedNumber($over_max_deletion_counts{$corpus}) . '</td>';
+			$max_count_deletion_total += $over_max_deletion_counts{$corpus};
+		}
+		print INSTANCESOUT '<td>' . &formatDeletedNumber($max_count_deletion_total) . '</td></tr>';
+	}
+	
+	undef(%instance_counts);
+}
+
+
+
+################################################################################
+# sub balanceCorpora
+################################################################################
+# Take a pointer to the %classes  array and truncate each instance array to the
+# size of the smallest of them
+################################################################################
+sub balanceCorpora {
+
+	my $debug = 1;
+
+	my $params = $_[0];
+	my $classes = $_[1];
+	
+	my $output = '<tr><th>Balancing Classes</th>';
+	
+	# Find out which of our classes is the smallest
+	my $smallest_class = 0;
+	foreach my $class (keys(%$classes)) {
+		if ((! $smallest_class) || keys(%{$classes->{$class}}) < $smallest_class) {
+			$smallest_class = keys(%{$classes->{$class}});
+		}
+	}
+	
+	&bugger($debug, "<br>balanceInstances: \$smallest_class = $smallest_class<br>");
+	
+	my %deleted_instances = ();
+	$deleted_instances{'total'} = 0;
+	# Truncate all of the class instance arrays to the size of the smallest
+	foreach my $class (sort(keys(%$classes))) {
+		$deleted_instances{$class} = 0;
+		while (keys(%{$classes->{$class}}) > $smallest_class) {
+			my @instances = keys(%{$classes->{$class}});
+			my $random_index = rand @instances;
+			delete $classes->{$class}{$instances[$random_index]};
+			$deleted_instances{$class}++;
+			$deleted_instances{'total'}++;
+		}
+		$output .= '<td>' . &formatDeletedNumber($deleted_instances{$class}) . "</td>";
+	}
+	
+	$output .= "<td>" . &formatDeletedNumber($deleted_instances{'total'}) . "</td></tr>";
+	
+	return $output;
+}
+
+################################################################################
+# sub randomizeInstanceClasses
+################################################################################
+# Take an array of pointers to instance arrays randomly re-assing each instance
+# to an array, so that effectively the class labels are randomly reassigned.
+# This is for a random falsification run, to see if your classifier is too good
+# for its own good.
+#
+# Note: This function is NOT suitable for randomizing the %classes array after 
+# feature values have been added.
+################################################################################
+sub randomizeInstanceClasses {
+
+	my $debug = 0;
+
+	my $params = $_[0];
+	my $classes = $_[1];
+
+	my $output = '';
+
+	# Create an array that contains all instances from all classes, and an array
+	# that stores the original instance hashes for each class
+	my @all_instances = ();
+	foreach my $class (sort(keys(%{$classes}))) {
+		foreach my $instance_id (keys(%{$classes->{$class}})) {
+			push (@all_instances, $instance_id);
+		}
+	}
+	
+	&bugger($debug, "<br>randomizeInstanceClasses: \@all_instances = " . join(" ", @all_instances) . "<br>");
+	
+	# Now randomize the order of all the elements in the array
+	&randomizeArrayOrder(\@all_instances);
+
+	&bugger($debug, "<br>randomizeInstanceClasses: Randomized \@all_instances = " . join(" ", @all_instances) . "<br>");
+	
+	# Now re-assign the instances back into the classes, using the random order
+	foreach my $class (keys(%{$classes})) {
+
+		# How many instances were there originally in the class? I think we 
+		# should preserve class size, although that is surely debatable.
+		my $class_size = keys(%{$classes->{$class}});
+		# Remove the whole contents of this class hash,
+		# we'll rebuild it one instance at a time
+		$classes->{$class} = ();
+		for (my $i = 0; $i < $class_size; $i++) {
+			my $new_instance_id = pop(@all_instances);
+			$classes->{$class}{$new_instance_id} = ();
+		}
+	}
+
+	$output .= "<br>Class assignments for all instances were randomized.<br><br>";
+	return $output;
+	
+	undef(@all_instances);
+			
+}
+
+################################################################################
+# writeMultidocFiles
+################################################################################
+# We need to write out the multidoc strings so that we can pass around a 
+# reference to a file that contains them, instead of the strings themselves,
+# which can become quite unwieldy.
+################################################################################
+sub writeMultidocFiles {
+	
+	my $debug = 0;
+
+	my $params = $_[0];
+	my $classes = $_[1];
+	my $instances_by_id = $_[2];
+
+	$alldocfile = $params->{'rundir'} . "/docfiles/all";
+	open ALLDOCOUT, ">$alldocfile";
+
+	&bugger($debug, "All doc out: $alldocfile<br><br>");
+	
+	my %all_instances = ();
+	
+	foreach my $class (keys(%$classes)) {
+
+		my %class_instances = ();
+
+		&bugger($debug, "Class: $class <br><br>");
+		$classfile = $params->{'rundir'} . "/docfiles/$class";
+		open CLASSDOCOUT, ">$classfile";
+		&bugger($debug, "Classdoc out: $classdocfile<br><br>");
+		foreach my $instance_id (keys(%{$classes->{$class}})) {
+			&bugger($debug, "Class: $class <br><br>");
+			my $instance = $instances_by_id->[$instance_id];
+			# Only write out the philodocid -- not the div 
+			$instance =~ s/^(\d+).*?$/\1/g;
+			$class_instances{$instance} = 1;
+			$all_instances{$instance} = 1;
+		}
+		
+		foreach my $instance (sort numerically keys(%class_instances)) {
+			print CLASSDOCOUT '&multidocid=' . $instance;
+
+		}
+
+		close CLASSDOCOUT;
+	}
+	
+	foreach my $instance (sort numerically keys(%all_instances)) {
+		print ALLDOCOUT '&multidocid=' . $instance;
+	}
+	
+	close ALLDOCOUT;
+	
+	undef(%all_instances);
+	undef(%class_instances);
+}
+
+################################################################################
+# sub cleanCorpusPattern
+################################################################################
+# Modifies the user supplied metadata arguments to search for.  
+# Transforms " OR " in to "|", " AND " to " ", in cases where we do not have 
+# SQL, so old style gimme will run. The corpus pattern is a simple argument 
+# string which goes to gimme as a command line argument:
+#      title=poetical+subjects  author=robinson
+#
+# Parameters:
+#
+#	$gimme_args - the argument string to be passed to gimme
+#
+# Returns: 
+#	
+#	$gimme_arg - modified arguments
+#
+################################################################################
+# TODO this normally is part of philosubs and operates on a global, but i have
+# duplicated it here to take an argument. are we actually using anything from
+# philosubs, if we don't need this?
+
+sub cleanCorpusPattern {
+	
+	my $gimme_arg = $_[0];
+
+	$gimme_arg =~ s/%20/+/g;
+	$gimme_arg =~ s/%../pack("H2", substr($&,1))/ge;
+	$gimme_arg = &postfix2UTF8($gimme_arg);
+	$gimme_arg =~ s/[ \+]+\|[ \+]+/\|/g;
+	if (!$SQLenabled) {  # if no SQL, use gimme notation
+		$gimme_arg =~ s/[ \+]+OR[ \+]+/\|/g;
+		$gimme_arg =~ s/[ \+]+AND[ \+]+/\+/g;
+	}
+	$gimme_arg =~ s/([^\.\]\)])\*/$1\.\*/g;
+	$gimme_arg =~ s/=\++/\=/g;              # get rid of leading spaces
+	$gimme_arg =~ s/\++ / /g;               # get rid of trailing spaces
+	$gimme_arg =~ s/\++$//g;                # get rid of trailing spaces
+	$gimme_arg =~ s/'/\\'/g;                # Escape apostrophes
+	$gimme_arg =~ s/;/\\;/g;                # Escape semi-colons
+	$gimme_arg =~ s/\|/\\\|/g;              # Escape "|"
+	$gimme_arg =~ s/\"/\\\"/g;              # Escape """
+
+	return $gimme_arg;
+
+}
+
+1;
diff -Nuar philomine2/cgi-bin/perlbayes_functions.pl philomine2patched/cgi-bin/perlbayes_functions.pl
--- philomine2/cgi-bin/perlbayes_functions.pl	2008-06-13 16:03:18.000000000 -0500
+++ philomine2patched/cgi-bin/perlbayes_functions.pl	2018-08-14 19:45:24.293978257 -0500
@@ -17,14 +17,17 @@
 sub MultiBayes {
 
 	use Algorithm::NaiveBayes;
+	use Data::Dumper;
 
-	my $debug = 20;
+	my $debug = 99;
 
 	my $params  = $_[0];
 	
 	my $runname = $params->{'runname'};
 	my $rundir =  $params->{'rundir'};
 
+	print $rundir;
+
 	# DIRECTORIES
 	# The directory for this mining function for this run
 	my $function_dir = "$rundir/PerlMultiBayes";
@@ -165,6 +168,7 @@
 		print CLASSOUT '</div>';
 		close CLASSOUT;	
 		&printOutFile($classification_outfile);
+		&bugger($debug, "TEST" . $classification_outfile . "<br>");
 		close CSVOUT;
 	
 		# FEATURE STATS
@@ -447,7 +451,7 @@
 	my $features = $_[3];
 	my $corpora = $_[4];
 	local (*FEATOUT) = $_[5];
-	
+
 	# Feature Statistics Display
 	# Find the most highly scored features for each class (as judged by the ratio
 	# of the class probability to the sum of all other class probabilities for that
@@ -526,7 +530,8 @@
 			$displayed_features++;
 			last if ($displayed_features > $params->{'FEATUREDISPLAYLIMIT'});
 			
-			my $feature = $features->[$feature_id];
+#			my $feature = $features->[$feature_id];
+			my $feature = $features[$feature_id];
 			$features_string .= $feature . ' ';
 			
 			print FEATOUT "<tr>";
@@ -569,7 +574,8 @@
 			$displayed_features++;
 			last if ($displayed_features > $params->{'FEATUREDISPLAYLIMIT'});
 
-			my $feature = $features->[$feature_id];
+#			my $feature = $features->[$feature_id];
+			my $feature = $features[$feature_id];
 			$features_string .= $feature . ' ';
 			
 			print FEATOUT "<tr>";
@@ -583,7 +589,7 @@
 		print FEATOUT "</table><br>";
 		print FEATOUT "</td></tr></table>";
 
-		print FEATOUT $features_string;
+#		print FEATOUT $features_string;
 	}
 
 	print FEATOUT &closeFeatureListForm();
diff -Nuar philomine2/cgi-bin/perlrelativerate_functions.pl philomine2patched/cgi-bin/perlrelativerate_functions.pl
--- philomine2/cgi-bin/perlrelativerate_functions.pl	2008-06-13 16:03:18.000000000 -0500
+++ philomine2patched/cgi-bin/perlrelativerate_functions.pl	2018-08-14 20:03:19.167310193 -0500
@@ -3,6 +3,8 @@
 # =====================================================================
 sub DiffRelativeRate {
 
+	use Data::Dumper;
+
 	my $debug = 0;
 
 	my $params  = $_[0];
@@ -33,7 +35,7 @@
 		$corpus_index++;
 	}
 	my @instances = ();
-	my @features = ();
+	my $features = ();
 	my @instance_descriptors = ();
 	my %instance_data = ();
 	my @classes_by_instance_id = ();
@@ -233,4 +235,4 @@
 	return $output;
 }
 
-1;
\ No newline at end of file
+1;
diff -Nuar philomine2/cgi-bin/perlrelativerate_functions.pl.08142018 philomine2patched/cgi-bin/perlrelativerate_functions.pl.08142018
--- philomine2/cgi-bin/perlrelativerate_functions.pl.08142018	1969-12-31 18:00:00.000000000 -0600
+++ philomine2patched/cgi-bin/perlrelativerate_functions.pl.08142018	2018-07-28 16:46:40.970340763 -0500
@@ -0,0 +1,236 @@
+# =====================================================================
+# Subroutine: DiffRelativeRate
+# =====================================================================
+sub DiffRelativeRate {
+
+	my $debug = 0;
+
+	my $params  = $_[0];
+
+	my $runname = $params->{'runname'};
+	my $rundir =  $params->{'rundir'};
+
+	# The directory for this mining function for this run
+	my $function_dir = "$rundir/PerlDecisionTree";
+	$params->{'function_dir'} = $function_dir;
+
+	# Create the directory to store the Perl Relative Rate files
+	$res = `mkdir -p $function_dir/{data,html,model,weights,classification,output}`;
+	
+	# INFO
+	my $info_outfile = "$function_dir/html/info.html";
+	open INFOOUT, ">$info_outfile";
+	print INFOOUT &DiffRelativeRateInfo($params);
+	close INFOOUT; 
+	&printOutFile($info_outfile);
+	
+	# CORPORA
+	# TODO allow more than 2, read class names from the form
+	my %corpora = ();
+	my $corpus_index = 1;
+	while (exists($params->{'c' . $corpus_index . '_name'}) && $params->{'c' . $corpus_index . '_name'} ne '') {
+		$corpora{$params->{'c' . $corpus_index . '_name'}} = ();
+		$corpus_index++;
+	}
+	my @instances = ();
+	my @features = ();
+	my @instance_descriptors = ();
+	my %instance_data = ();
+	my @classes_by_instance_id = ();
+	&buildCorpora($params, \%corpora, \@minefields, $function_dir, \@instances, \@features, \@instance_descriptors, \@classes_by_instance_id, \%instance_data);
+
+	my $num_corpora = scalar(keys(%corpora));
+
+	# Total # of tokens (sum of feature values) in class
+	my %corpus_token_counts = ();
+	# Count of feature_id occurrences in class
+	my %corpus_feature_counts = ();
+	# Rate per thousand for feature_id in class
+	my %corpus_feature_rpt = ();
+	# Rate per thousand for feature_id in all classes other than class
+	my %othercorpus_feature_rpt = ();
+	# Ration of rpt for feature in this class versus all other classes
+	my %corpus_rpt_ratios = ();
+	# Feature_ids only occuring in one class
+	my %corpus_shibbolethss = ();
+
+
+	foreach my $corpus (keys(%corpora)) {
+		foreach my $instance_id (keys(%{$corpora{$corpus}})) {
+			foreach my $feature_id (keys(%{$instance_data{$instance_id}})) {
+				$corpus_token_counts{$corpus} += $instance_data{$instance_id}{$feature_id};
+				$corpus_feature_counts{$corpus}{$feature_id} += $instance_data{$instance_id}{$feature_id};
+			}
+		}
+
+		for (my $feature_id = 0; $feature_id < scalar(@features); $feature_id++) {
+			$corpus_feature_rpt{$corpus}{$feature_id} = 1000 * ($corpus_feature_counts{$corpus}{$feature_id} / $corpus_token_counts{$corpus});
+		}
+		
+	}
+
+	foreach my $corpus (keys(%corpora)) {
+		%{$corpus_shibbolethss{$corpus}} = ();
+		for (my $feature_id = 0; $feature_id < scalar(@features); $feature_id++) {
+			my $othercorpus_rpt_total = 0;
+			foreach my $othercorpus (keys(%corpora)) {
+				if ($othercorpus ne $corpus) {
+					$othercorpus_rpt_total += $corpus_feature_rpt{$othercorpus}{$feature_id};
+				}
+			}
+			my $othercorpus_rpt_avg = $othercorpus_rpt_total / ($num_corpora -1);
+			if ($othercorpus_rpt_avg > 0) {
+				$corpus_rpt_ratios{$corpus}{$feature_id} = $corpus_feature_rpt{$corpus}{$feature_id} / $othercorpus_rpt_avg;
+			} else {
+				$corpus_shibbolethss{$corpus}{$feature_id} = $corpus_feature_rpt{$corpus}{$feature_id};
+			}
+		}
+	}
+	
+	foreach my $corpus (keys(%corpora)) {
+		for (my $feature_id = 0; $feature_id < scalar(@features); $feature_id++) {
+			my $feature = $features[$feature_id];
+		}
+	}
+
+	my $selectrate = .9;
+	my $crateupper = 1.3;
+	my $cratelower = 0.8;
+	my $boldrateupper = 1.6;
+	my $boldratelower = 0.7;
+	my $mindoccount = $totaldoccount / 10;
+	$mindoccount = sprintf("%.0f",$mindoccount);
+
+	my $featurestats_outfile = "$function_dir/html/featurestats.html";
+	open FEATOUT, ">$featurestats_outfile";
+	print FEATOUT "<div class='optiongroup'><h3>Features Statistics</h3>";
+	print FEATOUT &openFeatureListForm($params);
+
+	foreach my $corpus (sort(keys(%corpora))) {
+		
+		print FEATOUT "<table class=\"results\"><tr><td>";	
+		print FEATOUT "<b>$corpus</b> features:<br>";		
+		print FEATOUT "<table class=\"results\"><tr>";
+		print FEATOUT "<td></td>"; # For the checkboxes
+		print FEATOUT "<th>Rank</th>"; 
+		print FEATOUT "<th>Feature</th>"; 
+		print FEATOUT "<th>$corpus #pk</th>";
+		print FEATOUT "<th>Ratio</th>";
+
+		foreach $othercorpus (sort(keys(%corpora))) { 
+			if ($corpus ne $othercorpus) {
+				print FEATOUT "<th>$othercorpus #pk</th>";
+			}
+		}
+	
+		print FEATOUT "</tr>";
+
+		my $displayed_features = 0;
+
+		foreach my $feature_id ( sort { $corpus_rpt_ratios{$corpus}{$b} <=> $corpus_rpt_ratios{$corpus}{$a} } keys(%{$corpus_rpt_ratios{$corpus}}) ) {
+			&bugger($debug, "Feature_id: $feature_id ");
+
+			$displayed_features++;
+			last if ($displayed_features > $params->{'FEATUREDISPLAYLIMIT'});
+		
+			my $feature = $features[$feature_id];
+		
+			print FEATOUT "<tr>";
+			print FEATOUT "<td><input type=\"checkbox\" name=\"FEATURELIST\" value=\"$feature\"></td>";
+			print FEATOUT "<td>$displayed_features</td>";
+			print FEATOUT "<td>$feature</td>";
+			print FEATOUT "<td>" . $corpus_feature_rpt{$corpus}{$feature_id} . "</td>";
+			print FEATOUT "<td>" . $corpus_rpt_ratios{$corpus}{$feature_id} . "</td>";
+	
+			foreach $othercorpus (sort(keys(%corpora))) {
+				if ($corpus ne $othercorpus) {
+					print FEATOUT "<td>" . $corpus_feature_rpt{$othercorpus}{$feature_id} . "</td>";
+				}
+			}
+		
+			print FEATOUT "</tr>";
+		}
+	
+		print FEATOUT "</table>";
+		print FEATOUT "</td><td>";
+
+		# Table of features that are unique to this class
+
+		print FEATOUT "<b>$corpus</b> unique features:<br>";		
+
+		print FEATOUT "<table class=\"results\"><tr>";
+		print FEATOUT "<td></td>"; # For the checkboxes
+		print FEATOUT "<th>Rank</th>"; 
+		print FEATOUT "<th>Feature</th>"; 
+		print FEATOUT "<th>$corpus #pk</th>";
+
+		my $displayed_features = 0;
+
+	    foreach my $feature_id ( sort { $corpus_shibbolethss{$corpus}{$b} <=> $corpus_shibbolethss{$corpus}{$a} } keys(%{$corpus_shibbolethss{$corpus}}) ) {
+			&bugger($debug, "Feature_id: $feature_id ");
+
+			$displayed_features++;
+			last if ($displayed_features > $params->{'FEATUREDISPLAYLIMIT'});
+
+			my $feature = $features[$feature_id];
+
+			print FEATOUT "<tr>";
+			print FEATOUT "<td><input type=\"checkbox\" name=\"FEATURELIST\" value=\"$feature\"></td>";
+			print FEATOUT "<td>$displayed_features</td>";
+			print FEATOUT "<td>$feature</td>";
+			print FEATOUT "<td>" . $corpus_feature_rpt{$corpus}{$feature_id} . "</td>";
+			print FEATOUT "</tr>";
+		}
+
+		print FEATOUT "</table><br>";
+		print FEATOUT "</td></tr></table>";
+	}
+
+	print FEATOUT &closeFeatureListForm();
+
+	print FEATOUT '</div>';
+
+	close FEATOUT;
+
+	&printOutFile($featurestats_outfile);
+}
+# TODO make these stats work
+#print "<p>";
+#print "Count of C1 words > $selectrate per 10000: $initrate <br>";
+#print "Count of comparison words within upper/lower bounds: $diffrate <br>";
+#print "Count of words associated with C1 docs: $numofc1words <br>";
+#print "Minimum document count = $mindoccount <br>";
+#print "<hr noshade>";
+
+# Write out the seach buttons and set up form...
+
+
+
+################################################################################
+# DiffRelativeRateInfo -- summarize the run in human language, with all settings
+################################################################################
+################################################################################
+sub DiffRelativeRateInfo {
+
+	my $params = $_[0];
+
+	my $output = '';
+	
+	$output .= "<div class=\"optiongroup\">";
+
+	$output .= "<table class=\"info_table\"><tr>";
+	$output .= "<td>" . &describeRunSettings($params) . "</td>";
+	$output .= "<td>" . &describeCorporaSettings($params) . "</td>";
+
+	$output .= "<td><h3>Function</h3>";
+	$output .= "<span class='optionlabel'>Function:</span> Differential Relative Rates<br>";
+
+	$output .= "<td>" . &describeFeatureSettings($params) . "</td>";
+	$output .= "</tr></table>";
+	
+	$output .= "</div>";
+	
+	return $output;
+}
+
+1;
\ No newline at end of file
diff -Nuar philomine2/cgi-bin/philomine2 philomine2patched/cgi-bin/philomine2
--- philomine2/cgi-bin/philomine2	2008-06-16 12:26:59.000000000 -0500
+++ philomine2patched/cgi-bin/philomine2	2018-08-14 19:49:13.614278665 -0500
@@ -8,6 +8,7 @@
 use URI::Escape;
 use POSIX qw(ceil floor);
 use IO::Tee;
+use Data::Dumper;
 
 # TODO what does this do?
 no strict "refs";
@@ -20,8 +21,8 @@
 require "description_functions.pl";
 require "utility_functions.pl";
 require "form_components/function_data.pl";
-require "/etc/philologic/dbnames";
-require "/etc/philologic/philologic.cfg";
+require "/etc/philologic31/dbnames";
+require "/etc/philologic31/philologic31.cfg";
 
 # Query param state saved via CGI.pm
 my $state_filename = "/tmp/$$" . "_philomine_params.state";
@@ -308,7 +309,7 @@
 ################################################################################
 sub WriteReQueryForm {
 	local ($arg, $var, $value);
-        $thisformaction = "<form action=\"http://diderot.uchicago.edu/cgi-bin/philologic/philomine?";
+        $thisformaction = "<form action=\"http://artflsrv02.uchicago.edu/cgi-bin/perseus31/philomine2/philomine?";
         $thisformaction .= "\" target='rerun'>";
         print $thisformaction;
 	foreach $arg (@argbuffer) {
@@ -583,7 +584,9 @@
 	my $vector = $_[0];
 	my $scalar = $_[1];
 	foreach $feature (keys(%$vector)) {
+#		print $vector->{$feature};
 		$vector->{$feature} = $vector->{$feature} * $scalar;
+#		print "\n$vector->{$feature}";
 	}
 }
 
@@ -661,9 +664,9 @@
 	my @old_classes_by_instance_id = @$classes_by_instance_id;
 	my @old_instances = @$instances;
 	%$corpora = ();
-	@$instances = ();
-	@$instance_descriptors = ();
-	@$classes_by_instance_id = ();
+	@instances = ();
+	@instance_descriptors = ();
+	@classes_by_instance_id = ();
 	
 	foreach my $corpus (sort(keys(%old_corpora))) {
 		
@@ -744,7 +747,7 @@
 	 	print INSTANCESOUT  '<td>' . $corpus_size . '</td>';
 	}
  	print INSTANCESOUT  '<td>' . @$instances . '</td></tr>';
-		
+
 	# FILTER the instances
 	&filterInstances($params, $corpora, $instances, *INSTANCESOUT);
 
@@ -774,7 +777,8 @@
 	# Randomize the corpus assignments of the instances for a random falsification
 	# test.
 	if ($params{'SHUFFLE'}) {
-		print INSTANCESOUT  &randomizeInstanceCorpora($params, $corpora);
+#		print INSTANCESOUT  &randomizeInstanceCorpora($params, $corpora);
+		print INSTANCESOUT  &randomizeInstanceClasses($params, $corpora);
 	}
 	print INSTANCESOUT '</div>';
 	close INSTANCESOUT;
@@ -859,8 +863,12 @@
 			my $feature_id;
 
 			foreach $feature (keys(%feature_instance_counts)) {
-				push(@$features, $feature);
-				$feature_id = $#{@$features};
+				push(@features, $feature);
+#				print $feature . "\n";
+#				$feature_id = $#{@$features};
+				$feature_id = $#features;
+#				print "(" . $feature_id . ")";
+#				print $feature_id . "\n";
 				$all_ids_by_feature->{$feature} = $feature_id;
 			}
 			
@@ -883,6 +891,7 @@
 					}
 				}
 			}
+#			print "[" . Dumper($all_ids_by_feature) . "]";
 
 			undef(%seen_instances);
 			undef(%instance_feature_values);
@@ -903,7 +912,7 @@
 		
 
 
-	print FEATURESOUT "<b>Total features:</b> " . scalar(@$features) . '<br>';
+	print FEATURESOUT "<b>Total features:</b> " . scalar(@features) . '<br>';
 
 	
 	# MULTIDOCFILE
diff -Nuar philomine2/cgi-bin/philomine2.08132018.ok philomine2patched/cgi-bin/philomine2.08132018.ok
--- philomine2/cgi-bin/philomine2.08132018.ok	1969-12-31 18:00:00.000000000 -0600
+++ philomine2patched/cgi-bin/philomine2.08132018.ok	2018-08-11 19:28:08.303628444 -0500
@@ -0,0 +1,1162 @@
+#!/usr/bin/perl
+
+# DEBUGGING
+my $debug = 0;
+ 
+# MODULES
+use CGI;
+use URI::Escape;
+use POSIX qw(ceil floor);
+use IO::Tee;
+use Data::Dumper;
+
+# TODO what does this do?
+no strict "refs";
+
+# INCLUDES
+require "config.pl";
+require "instance_functions.pl";
+require "feature_functions.pl";
+require "feature_filter_functions.pl";
+require "description_functions.pl";
+require "utility_functions.pl";
+require "form_components/function_data.pl";
+require "/etc/philologic31/dbnames";
+require "/etc/philologic31/philologic31.cfg";
+
+# Query param state saved via CGI.pm
+my $state_filename = "/tmp/$$" . "_philomine_params.state";
+
+%params = ();
+# If ARVG contains something, we aren't being run as a CGI, but rather from the command line
+if ($ARGV[0] ne '') {
+	&prepareParamsFromState(\%params, $ARGV[0]);
+} else {
+
+	print "Content-type: text/html\n\n";
+
+	&prepareParams(\%params);
+	
+	if (exists($params{'OFFLINE'})) {
+		print "<html><body>Execute your run with this command:<br><br>&nbsp;&nbsp;&nbsp;&nbsp;";
+		print "perl " . $PHILOMINCGIPATH . "/philomine2 $state_filename";
+		print "</body></html>";
+		exit();
+	}
+}
+
+# RUNDIR
+&createRundir(\%params);
+
+# philominesubs.pl
+my $dbname = $params{'dbname'}; 
+require "$PHILODATADIR/databases/$dbname/lib/philominesubs.pl";
+
+# Archive the state in the rundir
+my $state_cmd = "cp $state_filename " . $params{'rundir'} . "/state/";
+$res = `$state_cmd`;
+ 
+
+# HTML OUTFILE -- ALLOUT is a global filehandle that printOutFile
+# write to (in addition to writing to STDOUT)
+$all_outfile = $params{'rundir'} . "/html/all.html";
+open ALLOUT, ">$all_outfile";
+
+# HEADER
+$header_outfile = $params{'rundir'} . "/html/header.html";
+open HEADOUT, ">$header_outfile";
+open HEADIN, "$PHILOMINHTMLDIR/philomine_header.html";
+while (my $line = <HEADIN>) {
+	print HEADOUT $line;
+}
+close HEADIN;
+close HEADOUT;
+&printOutFile($header_outfile);
+
+# CHECK
+&checkForErrors(\%params);
+# Process the submitted include or exclude features, if the user has submitted
+# any from checkboxes on the form on a previous mining run.
+&processFeatureLists(\%params);
+
+# ACCESS CONTROL
+# We now have a database to talk to and the database
+# specific parameters.  Let's see if we can run this search.
+if ($PhiloLogicAccesControl) {
+        $filetest = $SYSTEM_DIR . "/lib/security.ph";
+        if (! -e $filetest) {
+                $LINKDICT = 0;
+                print &mkTitle;
+                print "<p>\n<p>\n";
+                print "Cannot find required access control module for ";
+                print $dbname;
+                print ". Contact $ERRORCONTACT.";
+                print &kwicfooter;
+                exit (0);
+                }
+        require "security.ph";
+        if (!&security_check) {
+                $LINKDICT = 0;
+                print &mkTitle;
+                print "<p>\n<p>\n";
+                print $REJECT_MESSAGE;
+                print "<p>Requesting Computer Address: ";
+                if ($host) {
+                        print "$host ";
+                        }
+                if ($ip) {
+                        print " $ip";
+                        }
+                print "\n";
+                print &kwicfooter;
+                exit (0);
+                }
+        }
+
+# More variable setting....
+# TODO do we need this?
+$|=1;
+$ENV{'PATH'} = $SYSTEM_DIR . ":" . $PHILOCGIPATH . ":/bin:/usr/bin";
+$ENV{'SYSTEM_DIR'} = $SYSTEM_DIR;
+$parid = $$;
+
+
+
+# TODO does this work at all?
+if ($MINEMODE eq "SELECT") {
+
+	# TODO finish this up
+	# Use selected corpus mode -- there are two phases. First the user
+	# selects the corpora and then the mining is run. Let's see what phase
+	# we are in here. If there is anything in the c1 and c2selections 
+	# querystring parameters, then the selections have already been
+	# commited by the user. 
+	
+	# Has the user selected the corpora already?
+	if ($ENV{'QUERY_STRING'} =~ /c1selections=/ && $ENV{'QUERY_STRING'} =~ /c2selections=/) {
+		print "Selected!";
+		
+		# We need to 
+		
+	} else {
+
+		# We'll run the normal GetDocVectors routine, so that we'll only
+		# print out the documents that the user may have narrowed things
+		# down to by selecting some criteria on the previous form.
+		&GetDocVectors();
+		
+		print "<center><h2>Bibliography Corpus One</h2></center>";
+
+		# We want all the current URL parameters to get passed along to this
+		# page again when the user submits the form. Therefore, we print out
+		# hidden form fields for each current URL parameter. Is there a better way?
+		print "\n\n<form action='philomine2' method='GET'>\n\n"; 
+		
+		print &getHiddenQSFields($params);
+		
+		# Keep track of how many biblines have been printed, so we can get
+		# the philodocid out of the $c1docvector, which should contain the 
+		# same documents in the same order as the bibbuffers.
+		$c1bibcount = 0;
+	
+		foreach $bline (@c1bibbuffer) {
+			$philodocid = $c1docvector[$c1bibcount];
+			$c1bibcount++;
+					
+			print "<p>";
+			print '<input type="checkbox" name="c1selections" value="' . $philodocid . '">';
+			@r = split(/\t/, $bline);
+			$x = $r[$#r];
+			print &mkBiblio($bline);
+			print " wc=" . $countbydocid[$x] . " ";
+		}
+	                
+		print "<hr>";
+		print "<center><h2>Bibliography Corpus Two</h2></center>";
+	
+		$c2bibcount = 0;
+		foreach $bline (@c2bibbuffer) {
+			$philodocid = $c2docvector[$c2bibcount];
+			$c2bibcount++;
+	
+			print "<p>";
+			print '<input type="checkbox" name="c2selections" value="' . $philodocid . '">';
+			@r = split(/\t/, $bline);
+			$x = $r[$#r];
+			print &mkBiblio($bline);
+			print " wc=" . $countbydocid[$x] . " ";
+		}
+		
+		print "<hr>";
+		print "<input type='submit' name='Submit' value='Submit Corpora'></form>";
+		print &kwicfooter;
+		exit 0;
+	}
+}
+
+
+
+# FUNCTIONS
+%function_titles = ('RELRATE' => 'Differential Relative Word Frequencies', 
+					'MULTIBAYES' => 'Classifier: Multinominal Naive Bayes',
+					'DECISIONTREE' => 'Classifier: Decision Tree',
+					'WEKABAYES' => 'Classifier: Weka Naive Bayes',
+					'WEKAIG' => 'Information Gain (Weka)',
+					'WEKAJ48' => 'Decision Tree J48 (Weka)',
+					'WEKAMLP' => 'Multilayer Perceptron (Weka)',
+					'SVMLight' => 'Classifier: Support Vector Machine (SVM Light)',
+					'SVMLIGHTMULTIOVA' => 'Classifier: Support Vector Machine (SVM Light) Multiclass One-vs-All',
+					'SVMLIGHTMULTIOVO' => 'Classifier: Support Vector Machine (SVM Light) Multiclass One-vs-One',
+					'SVMLight' => 'Classifier: Support Vector Machine (SVM Light)',
+					'WEKASMO' => 'Classifier: Support Vector Machine (Weka SMO)',
+					'VECTORSPACE' => 'Classifier: Vector Space',
+					'CLUTO' => 'Clusterer: CLUTO',
+					'WRITEDATA' => 'Write Data');
+
+%function_includes = ('RELRATE' => 'perlrelativerate_functions.pl', 
+					'MULTIBAYES' => 'perlbayes_functions.pl',
+					'DECISIONTREE' => 'perldecisiontree_functions.pl',
+					'WEKABAYES' => 'wekabayes_functions.pl',
+					'WEKAIG' => 'wekaig_functions.pl',
+					'WEKAJ48' => 'wekaj48_functions.pl',
+					'WEKAMLP' => 'wekamlp_functions.pl',
+					'SVMLight' => 'svmlight_functions.pl',
+					'SVMLIGHTMULTIOVA' => 'svmlight_functions.pl',
+					'SVMLIGHTMULTIOVO' => 'svmlight_functions.pl',
+					'WEKASMO' => 'wekasmo_functions.pl',
+					'VECTORSPACE' => 'vectorspace_functions.pl',
+					'CLUTO' => 'cluto_functions.pl',
+					'WRITEDATA' => 'writedata_functions.pl');
+
+
+if (exists($params{'MINEFUN'}) && $params{'MINEFUN'} ne '') {
+	require $function_includes{$params{'MINEFUN'}};
+} else {
+	&throwError('Please choose an algorithm.');
+}
+
+# COMMAND
+if ($params{'MINEFUN'} eq 'RELRATE') {
+	&DiffRelativeRate(\%params);
+} elsif ($params{'MINEFUN'} eq 'MULTIBAYES') {
+	&MultiBayes(\%params);
+} elsif ($params{'MINEFUN'} eq 'DECISIONTREE') {
+	&DecisionTree(\%params);
+} elsif ($params{'MINEFUN'} eq 'WEKABAYES') {
+	&WekaBayes(\%params);
+} elsif ($params{'MINEFUN'} eq 'WEKAIG') {
+	&WekaIG(\%params);
+} elsif ($params{'MINEFUN'} eq 'WEKAJ48') {
+	&WekaJ48(\%params);
+} elsif ($params{'MINEFUN'} eq 'WEKAMLP') {
+	&WekaMLP(\%params);
+} elsif ($params{'MINEFUN'} eq 'SVMLight') {
+	&SVMLight(\%params);
+} elsif ($params{'MINEFUN'} eq 'SVMLIGHTMULTIOVA') {
+	&SVMLightMultiOVA(\%params);
+} elsif ($params{'MINEFUN'} eq 'SVMLIGHTMULTIOVO') {
+	&SVMLIGHTMULTIOVO(\%params);
+} elsif ($params{'MINEFUN'} eq 'WEKASMO') {
+	&WekaSMO(\%params);
+} elsif ($params{'MINEFUN'} eq 'VECTORSPACE') {
+	&VectorSpace(\%params);
+} elsif ($params{'MINEFUN'} eq 'CLUTO') {
+	&CLUTO(\%params);
+} elsif ($params{'MINEFUN'} eq 'WRITEDATA') {
+	&WriteData(\%params);
+}
+
+# FOOTER
+$footer_outfile = "$rundir/html/footer.html";
+open FOOTOUT, ">$footer_outfile";
+open FOOTIN, "$PHILOMINHTMLDIR/philomine_footer.html";
+while ($line = <FOOTIN>) {
+	print FOOTOUT $line;
+}
+close FOOTIN;
+close FOOTOUT;
+&printOutFile($footer_outfile);
+
+close ALLOUT;
+
+# If this was an offline run from the command line, print out a little something extra
+# to let them know where to look at the results online
+if (exists($params{'OFFLINE'})) {
+	print "\n\n\nLook for your results here:\n\n";
+	print $PHILOMINHTMLURL . "/runs/" . $params{'runname'} .  "/html/all.html\n\n";
+}
+
+# Unless otherwise specified on the form, DELETE the run directory
+if (! exists($params{'SAVERUN'})) {
+	my $cmd = "rm -rf " . $params{'rundir'};
+	my $res = `$cmd`;
+}
+
+################################################################################
+# End of main routine
+################################################################################
+
+################################################################################
+# sub WriteReQueryForm
+################################################################################
+# Purpose: Write out an opening form tag for re-running this 
+# run and curling the output to an outfile. Then, redirect this page to that
+# curled file once it is finished being downloaded.
+#
+# At the moment, there seem to be some problems with doing this on very, very
+# long runs (more than a couple hours).
+#
+################################################################################
+sub WriteReQueryForm {
+	local ($arg, $var, $value);
+        $thisformaction = "<form action=\"http://artflsrv02.uchicago.edu/cgi-bin/perseus31/philomine2/philomine?";
+        $thisformaction .= "\" target='rerun'>";
+        print $thisformaction;
+	foreach $arg (@argbuffer) {
+	        $arg =~ s/\%3A/:/g;
+                $arg =~ s/\%2C/,/g;
+       		$arg =~ s:\%2F:/:g;
+       		$arg =~ s:\%20: :g;
+                $arg =~ s/\%60//g;
+                $arg =~ m/(\s*)=/;
+                $arg =~ m/=(\s*)/;
+                ($var, $value) = split(/\s*=\s*/, $arg, 2);
+		if ($var eq "MINEFUN" ) {
+			$value = "MULTIBAYES";
+			}
+		if ($var eq "USERFEATURES") {
+			$donothing = "";
+			}
+		else {
+		    print "<input type=\"hidden\" name=\"" . $var . "\"";
+		    print " value=\"" . $value . "\">\n";
+			}
+		}
+return;
+}
+
+################################################################################
+# sub createRundir
+################################################################################
+# Purpose: create the directories needed for a philomine run
+# and assign a new $runname if the current one is already taken.
+################################################################################
+sub createRundir() {
+
+	my $params = $_[0];
+	
+	my $runname = $params->{'runname'};
+	my $newrunname = $params->{'runname'};
+
+	my $non_digits;
+	my $adddigit;
+
+	# If it ends in a number, we'll increment it
+	if ($runname =~ /^(.*?)(\d+)$/) {
+		$non_digits = $1;
+		$addigit = $2;
+	} else {
+		$non_digits = $runname;
+		$addigit = 1;
+	}
+
+	# Comment this bit out if you want to overwrite instead of 
+	# incrementing	
+	while (-e "$PHILOMINDIR/runs/$newrunname") {
+       $newrunname = $non_digits . $addigit;
+       $addigit++;
+	}
+	
+	$runname = $newrunname;
+
+	# The directory for this run
+	$rundir = $PHILOMINDIR . '/runs/' . $runname;
+
+	# If it already exists, destroy it
+	my $res = `rm -rf $rundir`;
+
+	# Create some directories to store the data.
+	$res = `mkdir -p $rundir/{arrays,html,docfiles,features,state}`;
+	if (exists($params->{'CSVOUTPUT'}) && exists($params->{'CSVOUTPUT'}) ne '') {
+		$res = `mkdir -p $rundir/csv`;	
+	}
+	
+	$params->{'runname'} = $runname;
+	$params->{'rundir'} = $rundir;
+}
+
+################################################################################
+# sub trimOutput($data)
+################################################################################
+# Purpose: We sometimes have really long lines that make for poor HTML
+# presentation. Let's trim them and leaves ellispes.
+################################################################################
+
+sub trimOutput() {
+
+	my $data = $_[0];
+
+	$data =~ s/^(.{130}).*$/\1&#8230;/mg;
+
+	return $data;
+}
+
+
+################################################################################
+# sub instanceLink
+################################################################################
+# Purpose: Create a link to the PhiloLogic display for an instance
+################################################################################
+sub instanceLink() {
+
+	my $debug = 0;
+
+	my $instance = $_[0];
+	my $dbname = $_[1];
+
+	# DOC level instance
+	if ($instance =~ /^\d*$/) {
+		$link = "$PHILOCGI/navigate.pl?$dbname.$instance";
+
+	# DOC level instance composed of multiple divs
+	} elsif ($instance =~ /,/) {
+		$instance =~ s/,/\+OR\+/g;
+		$link = "$PHILOCGI/search3t?dbname=$dbname&dgphilodivid=" . &uri_escape($instance);
+	
+	# DIV level instance
+	} elsif ($instance =~ /:/) {
+		$link = "$PHILOCGI/getobject.pl?c.$instance.$dbname";
+	}
+	
+	return $link;
+}
+	
+################################################################################
+# sub wordSearchLink
+################################################################################
+# Purpose: Create a link to search on a certain word
+################################################################################
+sub wordSearchLink() {
+
+	my $debug = 0;
+
+	my $params = $_[0];
+	my $word = $_[1];
+	my $linktext = $_[2];
+	my $corpus = $_[3];
+
+	# TODO to make this multi-db safe....
+
+	my $link = "<a href=\"". $PHILOSEARCH3T;
+	$link .= "?dbname=" . &uri_escape($params->{'dbname'});
+
+	# For bigrams and bilemmas, we'll do a proxy search with a distance of 2. This won't
+	# be perfect, but better than nothing.
+	if ($word =~ /_/) {
+		my $search_terms = $word;
+		$search_terms =~ s/_/ /g;
+		$link .= "&OUTPUT=conc&CONJUNCT=PROXY&DISTANCE=2";
+		$link .= "&word=" . &uri_escape($search_terms);
+	} else {
+		$link .= "&OUTPUT=conc&CONJUNCT=PHRASE";
+		$link .= "&word=" . &uri_escape($word);
+	}
+
+	&bugger($debug, "LINK Corpus $corpus div args: " . 	$params->{$corpus . '_div_args'} . "<br>");
+	
+	# We need to see if we are printing out a string that is the same as
+	# the c1multidoc, the c2multidoc, or the combined "all multidoc. If so,
+	# we'll pass a different paramter, multidocfile, that contains the location
+	# of the multidoc file that in turn contains the multidoc string.
+	
+	# We do this because the multidoc strings can be very long, and it generates
+	# an enormously unwieldy HTML file to have them encoded in every link.
+	# A hacked version of search3t knows how to dig out the multidoc file
+	# and get the bibliography from there.
+	
+	my $multidoc = "&multidocfile=" . $params->{'rundir'} . "/docfiles/$corpus";
+	
+	$link .= $multidoc . "\">" . $linktext . "</a>";
+	
+	# We don't want %20, we want +
+	$link =~ s/%20/\+/g;	
+
+	return $link;
+}
+
+################################################################################
+# sub allWordSearchLink - create a link to search for a word for all corpora
+################################################################################
+sub allWordSearchLink() {
+
+	my $params = $_[0];
+	my $corpora = $_[1];
+	my $word = $_[2];
+	my $id = $_[3];
+	my $class = $_[4];
+	
+	my $links = '<span id="linkedword_' . $class . $id . '" class="linkedword">' . $word;
+	$links .= ' <span id="wordlinks_' . $class . $id . '" class="wordlinks">';
+
+	foreach my $corpus (sort(keys(%$corpora))) {
+		$links .= ' ' . &wordSearchLink($params, $word, "[$corpus]", $corpus);
+	}
+	
+	$links .= ' ' . &wordSearchLink($params, $word, "[all]", 'all');
+	
+	$links .= '</span></span>';
+	
+	return $links;
+}
+
+
+################################################################################
+# sub getHiddenQSFields()
+################################################################################
+# Print out a hidden form field for each name value pair in the querystring
+# This is useful if you want to submit a new form to the same page, and retain
+# all of the current GET parameters.
+################################################################################
+sub getHiddenQSFields() {
+
+	my $params = $_[0];
+	
+	my $output = '';
+
+	foreach my $var (keys(%$params)) {
+		my $value = $params->{$var};
+		# Escape double quotes and backslashes
+		$value =~ s/\\/\\\\/g;
+		$value =~ s/"/\"/g;
+		$value =~ s/\+/ /g;
+		$output .= '<input type="hidden" name="' . $var . '" value="' . $value . "\">\n";		
+	}
+
+	return $output;
+}
+
+
+################################################################################
+# formLink - return a link to the CGI that draws up a form based on the 
+# parameters of this run
+################################################################################
+sub formLink() {
+
+	my $params = $_[0];
+
+	my $link;
+	my $qs;
+	
+	foreach my $var (keys(%$params)) {
+		my $value = $params->{$var};
+
+		# A literal + is a space
+		$value =~ s/\+/ /g;
+	
+		# URL encode the values, code taken from:
+		# http://support.internetconnection.net/CODE_LIBRARY/Perl_URL_Encode_and_Decode.shtml	
+		$value =~ s/([^A-Za-z0-9\-\.])/sprintf("%%%02X", ord($1))/seg;
+
+		$qs .= $var . '=' . $value . '&';
+	}
+	
+	$link = $PHILOMINECGIFORMURL . '?' . $qs . '&LINKEDFORM=yes';
+	return $link;
+}
+
+
+################################################################################
+# getVectorLength - return the length of the vector
+################################################################################
+sub getVectorLength() {
+	my $vector = $_[0];
+	my $length = 0;
+	foreach my $value (values(%$vector)) {
+		$length += $value**2;
+	}
+ 	return sqrt($length);
+}
+
+################################################################################
+# scaleVector - multiply every value in the vector by a value
+################################################################################
+sub scaleVector() {
+	my $vector = $_[0];
+	my $scalar = $_[1];
+	foreach $feature (keys(%$vector)) {
+		$vector->{$feature} = $vector->{$feature} * $scalar;
+	}
+}
+
+################################################################################
+# normalizeVector - perform an L2 noramlization on the vector, to unit length
+################################################################################
+sub normalizeVector() {
+	my $vector = $_[0];
+	my $length = &getVectorLength($vector);
+	if ($length != 0) {
+		&scaleVector($vector, 1/$length);
+	} else {
+		#print "Vector length 0... ";
+	}
+}
+
+################################################################################
+# normalizeInstanceData - perform an L2 noramlization on all data
+################################################################################
+sub normalizeInstanceData() {
+	my $debug = $debug;
+	my $instance_data = $_[0];
+	foreach my $instance_id (keys(%$instance_data)) {
+		&bugger($debug, "Normalizing instance_id: $instance_id<br>");
+		&normalizeVector($instance_data->{$instance_id});
+	}
+}	
+
+################################################################################
+# scaleDataRatePer10k - change instance data to rate per 10k
+################################################################################
+sub scaleDataRatePer10k() {
+
+	my $instance_data = $_[0];
+
+	foreach my $instance_id (keys(%$instance_data)) {
+		my $vector_size = 0;
+		foreach my $value (values(%{$instance_data->{$instance_id}})) {
+			$vector_size += $value;
+		}
+		my $scalar = 10000/$vector_size;
+		&scaleVector($instance_data->{$instance_id}, $scalar);
+	}
+}	
+	
+
+################################################################################
+# renumberInstances - after filtering instances, give them fresh IDs
+################################################################################
+sub renumberInstances() {
+
+	my $debug = 57;
+	
+	my $corpora = $_[0];
+	my $instances = $_[1];
+	my $all_ids_by_instance = $_[2];
+	my $instance_descriptors = $_[3];
+	my $classes_by_instance_id = $_[4];
+	
+	&bugger($debug, "renumbering, got corpora " . join(' ', sort(keys(%$corpora))). "<br>");
+
+	# We can't simply copy the array because in Perl nested hashes contain
+	# pointers to anonymous arrays, not the arrays themselves, so we resort
+	# to this, a per-instance clone of one array to another.
+
+	my %old_corpora = ();
+	foreach my $corpus (sort(keys(%$corpora))) {
+		$old_corpora{$corpus} = ();
+		foreach my $instance_id (keys(%{$corpora->{$corpus}})) {
+			$old_corpora{$corpus}{$instance_id} = $corpora->{$corpus}{$instance_id};
+		}
+	}
+	
+	my @old_instance_descriptors = @$instance_descriptors;
+	my @old_classes_by_instance_id = @$classes_by_instance_id;
+	my @old_instances = @$instances;
+	%$corpora = ();
+	@$instances = ();
+	@$instance_descriptors = ();
+	@$classes_by_instance_id = ();
+	
+	foreach my $corpus (sort(keys(%old_corpora))) {
+		
+		foreach my $old_instance_id (sort {&philosort($old_instances[$a], $old_instances[$b])} keys(%{$old_corpora{$corpus}}) ) {
+			my $instance = $old_instances[$old_instance_id];
+			push(@$instances, $instance);
+			my $new_instance_id = $#{$instances};
+			$instance_descriptors->[$new_instance_id] = $old_instance_descriptors[$old_instance_id];
+			$classes_by_instance_id->[$new_instance_id] = $old_classes_by_instance_id[$old_instance_id];
+			$corpora->{$corpus}{$new_instance_id} = ();
+		}		
+	}
+	
+	%$all_ids_by_instance = ();
+	&turnArrayIntoHash($instances, $all_ids_by_instance);
+}
+
+
+################################################################################
+# buildCorpora - maine function to assemble the instance data and features
+################################################################################
+sub buildCorpora() {
+
+	my $debug = 50;
+
+	my $params = $_[0];
+	my $corpora = $_[1];
+	
+	my $minefields = $_[2];
+	my $function_dir = $_[3];
+	my $instances = $_[4];
+	my $features = $_[5];
+	my $instance_descriptors = $_[6];
+	my $classes_by_instance_id = $_[7];
+	my $instance_data = $_[8];
+	
+	# INSTANCES 
+	my $instances_outfile = $params->{'rundir'} . "/html/instances.html";
+	open INSTANCESOUT, ">$instances_outfile";	
+ 	print INSTANCESOUT "<div class='optiongroup'><h3>Instances</h3>";
+	print INSTANCESOUT "<span class='toggleswitch' id='toggleswitch_sql'>►SQL</span>";
+	print INSTANCESOUT "<div class='toggle startoff' id='sql'>";
+	
+	# GET INSTANCES for each corpus
+	foreach my $corpus (sort(keys(%$corpora))) {
+		my %instances = ();
+		my %classes_by_instance = ();
+		&getInstances($params, \%instances, $corpus, \%classes_by_instance, *INSTANCESOUT);
+
+		# Add the instances to the @instances array, find out their
+		# instance_id, then add the instance_id to the %corpora hash and the 
+		# instance_descriptors array.
+		while ( (my $instance, my $instance_descriptor) = each (%instances) ) {
+			push(@$instances, $instance);
+			my $instance_id = $#{$instances};
+			$instance_descriptors->[$instance_id] = $instance_descriptor;
+			$corpora->{$corpus}{$instance_id} = ();
+			$classes_by_instance_id->[$instance_id] = $classes_by_instance{$instance};
+		}		
+		undef(%classes_by_instance);
+		undef(%instances);
+	}
+
+	print INSTANCESOUT "</div>";
+
+	my %all_ids_by_instance = ();
+	&turnArrayIntoHash($instances, \%all_ids_by_instance);
+
+	# Summarize the instances for each corpus
+ 	print INSTANCESOUT '<table class="results"><tr><td></td>';
+	foreach my $corpus (sort(keys(%$corpora))) {
+	 	print INSTANCESOUT '<th>' . $corpus . '</th>';
+	}
+	print INSTANCESOUT '<th>All Corpora</th></tr>';
+	print INSTANCESOUT '<tr><th>Initial Instances</th>';
+	foreach my $corpus (sort(keys(%$corpora))) {
+		my $corpus_size = keys(%{$corpora->{$corpus}});
+	 	print INSTANCESOUT  '<td>' . $corpus_size . '</td>';
+	}
+ 	print INSTANCESOUT  '<td>' . @$instances . '</td></tr>';
+		
+	# FILTER the instances
+	&filterInstances($params, $corpora, $instances, *INSTANCESOUT);
+
+	# Check to see if filtering has removed all of the instances from any corpus
+	foreach my $corpus (sort(keys(%$corpora))) {
+		if (scalar(keys(%{$corpora->{$corpus}})) == 0) {
+			&throwError("No instances are left after filtering for corpus $corpus. Please change your criteria and try again.");
+		}
+	}
+	
+	&renumberInstances($corpora, $instances, \%all_ids_by_instance, $instance_descriptors, $classes_by_instance_id);
+
+	# Balance the instances
+	if ($params->{'BALANCER'}) {
+	 	print INSTANCESOUT  &balanceCorpora($params, $corpora);
+		&renumberInstances($corpora, $instances, \%all_ids_by_instance, $instance_descriptors, $classes_by_instance_id);
+	}
+
+	print INSTANCESOUT '<tr><th>Final Instances</th>';
+	foreach my $corpus (sort(keys(%$corpora))) {
+		my $corpus_size = keys(%{$corpora->{$corpus}});
+	 	print INSTANCESOUT  '<td>' . $corpus_size . '</td>';
+	}
+ 	print INSTANCESOUT  '<td>' . @$instances . '</td></tr>';
+ 	print INSTANCESOUT '</table><br>';
+
+	# Randomize the corpus assignments of the instances for a random falsification
+	# test.
+	if ($params{'SHUFFLE'}) {
+		print INSTANCESOUT  &randomizeInstanceCorpora($params, $corpora);
+	}
+	print INSTANCESOUT '</div>';
+	close INSTANCESOUT;
+	
+	&printOutFile($instances_outfile);
+
+	# DIV ARGS
+	# Are all the corpora div arguments the same? If so, we should set $params->{'all_div_args'}
+	# so that when we push searches to PhiloLogic, the div args are pushed for 'all'. If they
+	# differ between corpora, there's nothing we can do, because we can't tell PhiloLogic to use
+	# different div args for different documents, so we don't use any div args at all.
+	my $last_args = 'NONE'; 
+	my $args_differ = 0;
+	my $have_div_args = 0;
+	my $instance_type = '';
+	foreach my $corpus (sort(keys(%$corpora))) {
+		if ($last_args eq 'NONE') {
+			$last_args = $params->{$corpus . '_div_args'};
+		} else {
+			if ($last_args ne $params->{$corpus . '_div_args'}) {
+				$args_differ = 1;
+				last;
+			} else {
+				$last_args = $params->{$corpus . '_div_args'};
+			}
+		}
+		if ($params->{$corpus . '_div_args'} ne '') {
+			$have_div_args = 1;
+		}
+	}
+	if ($args_differ) {
+		$params->{'all_div_args'} = '';
+	} else {
+		$params->{'all_div_args'} = $last_args;
+	}
+	if ($params->{'INSTANCELEVEL'} eq 'div') {
+		$instance_type = 'div';
+	} elsif ($params->{'INSTANCELEVEL'} eq 'document' && $have_div_args) {
+		$instance_type = 'multidiv';
+	} else {
+		$instance_type = 'document';
+	}
+
+	############################################################################
+	# Features 
+	# Now that we have all the instances, we can get all the feature values for
+	# them.
+	############################################################################
+
+	my $features_outfile = $params->{'rundir'} . "/html/features.html";
+	open FEATURESOUT, ">$features_outfile";
+
+	print FEATURESOUT "<div class='optiongroup'><h3>Features</h3>";
+
+	# Make sure we have at least one featureset
+	my $found_a_featureset = 0;
+
+	foreach $featureset (@featuresets) {
+
+		if (exists($params->{'FEATURESET' . $featureset})) {
+
+			$found_a_featureset = 1;
+
+			print FEATURESOUT "Featureset: $featureset<br><br>";
+
+			my $featureset_dir = "$rundir/featuresets/$featureset";
+			my %instance_feature_values = ();
+			my %feature_instance_counts = ();
+			my %instance_feature_value_totals = ();
+	
+			&getAndFilterFeatures($params, $instances, \%all_ids_by_instance, \%instance_feature_values, \%feature_instance_counts, \%instance_feature_value_totals, $featureset, $featureset_dir, $instance_type, *FEATURESOUT);
+	
+			# Now that we have received back the features, we need to integrate them into
+			# the all_features arrays. If we are dealing with multiple feature sets, we
+			# need to make sure we only refer to them by $feature_id, or there could
+			# be collisions. Probably shouldn't allow featuresets to name-collide anyway,
+			# WEKA etc might not like it.
+
+			my $instance_id;
+			my $instance;
+			my $feature;
+			my $feature_id;
+
+			foreach $feature (keys(%feature_instance_counts)) {
+#				push(@$features, $feature);
+				push(@features, $feature);
+#				print $feature . "\n";
+#				$feature_id = $#{@$features};
+				$feature_id = $#features;
+#				print #feature_id . "\n";
+				$all_ids_by_feature->{$feature} = $feature_id;
+			}
+			
+			# Now that we have assigned this feature an id, store the value of this
+			# feature for each instance in the %instance_data array.
+			$feature_id = $all_ids_by_feature->{$feature};
+			my %seen_instances = ();
+			for (my $instance_id = 0; $instance_id < scalar(@$instances); $instance_id++) {
+				my $instance = $instances->[$instance_id];
+				
+				if (exists($seen_instances{$instance})) {
+				#	print "Seen $seen instance: $instance instance_id $instance_id other instanceid: " . $seen_instances{$instance} ." \<br>";
+					$instance_data->{$instance_id} = $instance_data->{$seen_instances{$instance}};
+				#	print "After adding: ". $instance_data->{$instance_id} . " from " . $instance_data->{$seen_instances{$instance}} . "<br>";
+				} else {				
+					$seen_instances{$instance} = $instance_id;
+					foreach $feature (keys(%{$instance_feature_values{$instance_id}})) {
+						$feature_id = $all_ids_by_feature->{$feature};
+						$instance_data->{$instance_id}{$feature_id} = $instance_feature_values{$instance_id}{$feature};
+					}
+				}
+			}
+#			print "[" . Dumper($all_ids_by_feature) . "]";
+
+			undef(%seen_instances);
+			undef(%instance_feature_values);
+		}
+	}
+	
+	# We have gone through each featureset, accumulated the features and assigned them
+	# an id, and store their values in the %all_feature_instance_values array.
+	# Now let's complete the %instance_data array by storing each value for each feature for
+	# each instance for each corpus.
+
+	if (! $found_a_featureset) {
+		&throwError("Please choose at least one feature set for this run.");
+	}
+
+	undef(%all_ids_by_feature);
+	undef(%seen_instances);
+		
+
+
+	print FEATURESOUT "<b>Total features:</b> " . scalar(@$features) . '<br>';
+
+	
+	# MULTIDOCFILE
+	# Write out the multidoc file, which contains all the philodocids for each corpus, 
+	# so we can pass around a reference to that file in URLs and not the whole darn
+	# list, which can get pretty massive (especially when we have to print it
+	# thousands of times on a single page).
+	&writeMultidocFiles($params, $corpora, $instances);
+
+	# TF-IDF: If selected, transform the instance data to tf-idf values
+	if ($params->{'VALUETYPE'} eq 'TFIDFlog2') {
+		&tfidfInstanceData($instance_data, 'log2');
+		print FEATURESOUT 'Feature data converted to TF-IDF log 2<br>';
+	} elsif ($params->{'VALUETYPE'} eq 'TFIDFln') {
+		&tfidfInstanceData($instance_data, 'ln');
+		print FEATURESOUT 'Feature data converted to TF-IDF natural log<br>';
+	} elsif ($params->{'VALUETYPE'} eq 'TFIDFnolog') {
+		&tfidfInstanceData($instance_data, 'none');
+		print FEATURESOUT 'Feature data converted to TF-IDF no log<br>';
+	} elsif ($params->{'VALUETYPE'} eq 'rateper10k') {
+		&scaleDataRatePer10k($instance_data);
+		print FEATURESOUT 'Feature data converted to rate per 10k<br>';
+	}
+	
+	# L2 NORMALIZATION: If selected, do L2 normalization of the instances data
+	if ($params->{'NORMALIZATION'} eq 'L2') {
+		&normalizeInstanceData($instance_data);
+		print FEATURESOUT '<br>Feature data L2 normalized<br>';
+	}
+
+	print FEATURESOUT '</div>';
+	close FEATURESOUT;
+	 
+	&printOutFile($features_outfile);
+
+}
+
+sub tfidfInstanceData() {
+	
+	my $instance_data = $_[0];
+	my $log_type = $_[1];
+	
+	#print "TFIDF: log_type: $log_type<br>";
+	
+	my @instance_counts_per_feature_id = ();
+	my @feature_totals_per_instance_id = ();
+	
+	foreach my $instance_id (sort(keys(%$instance_data))) {
+		foreach my $feature_id (sort(keys(%{$instance_data->{$instance_id}}))) {
+			my $value = $instance_data->{$instance_id}{$feature_id};
+			$feature_totals_per_instance_id[$instance_id] += $value;
+			$instance_counts_per_feature_id[$feature_id]++;
+		}
+	}
+	
+	my $num_instances = scalar(@feature_totals_per_instance_id);
+	
+	foreach my $instance_id (sort(keys(%$instance_data))) {
+		foreach my $feature_id (sort(keys(%{$instance_data->{$instance_id}}))) {
+			my $value = $instance_data->{$instance_id}{$feature_id};
+			my $tf = $value / $feature_totals_per_instance_id[$instance_id];
+			my $df;
+			if ($log_type eq 'log2') {
+				$df = log_2($num_instances/$instance_counts_per_feature_id[$feature_id]);
+			} elsif ($log_type eq 'ln') {
+				$df = log($num_instances/$instance_counts_per_feature_id[$feature_id]);
+			} elsif ($log_type eq 'none') {
+				$df = $num_instances/$instance_counts_per_feature_id[$feature_id];
+			}
+			my $tfidf = $tf * $df;
+			if ($tfidf == 0) {
+				delete($instance_data->{$instance_id}{$feature_id});
+			} else {
+				$instance_data->{$instance_id}{$feature_id} = $tfidf;
+			}
+		#	print "instance_id: $instance_id feature_id: $feature_id value: $value feature totals: " . $feature_totals_per_instance_id[$instance_id] . " instance_counts: " . $instance_counts_per_feature_id[$feature_id];
+		#	print " log part: " . ($num_instances/$instance_counts_per_feature_id[$feature_id]) . " num_instances: $num_instances tf: $tf idf: $idf tf-idf: " . ($tf * $idf) . "<br>";
+		}
+	}
+}
+
+sub log_2() {
+	my $val = $_[0];
+	return log($val) / log(2);
+}
+
+################################################################################
+# sub formatDeletedNumber()
+################################################################################
+# When we are displaying a number of deleted elements, either features or 
+# instances, do we want to display a - before them, and do we want to display
+# 0 if 0 is the value, or just blank space? Or -0? I can't decide for sure
+# so with this function we can globally change it back later.
+#
+# Parameters:
+#
+#	$number - the number of items that were deleted
+#
+# Returns:
+#
+#	$number - the formatted value
+#
+################################################################################
+sub formatDeletedNumber() {
+	
+	my $number = $_[0];
+	
+	if ($number > 0) {
+		return '-' . $number;
+	} elsif ($number eq '0') {
+		return '0';
+	} else {
+		return $number;
+	}
+}
+
+
+################################################################################
+# sub setCVFolds
+################################################################################
+# Takes a number of cv_folds that was submitted on the form, and the number of
+# instances. Determines if there are enough instances to perform the desired 
+# number of runs. Returns the number of CV runs to be done.
+################################################################################
+sub setCVFolds() {
+
+	my $cvfolds = $_[0];
+	my $num_instances = $_[1];
+	
+	# Remove everything except numbers
+	$cv_folds =~ s/\D//g;
+	
+	if (! ($num_instances > 0)) {
+		die "The number of instances received by setCVFolds - $num_instances - was not more than 0.";
+	}
+	
+	# Default to 10 cross-validation folds
+	if ($cvfolds eq '' || $cvfolds < 0) {
+		$cvfolds = 10;
+	}
+	
+	if ($num_instances < $cvfolds) {
+		$cvfolds = $num_instances;
+	}
+	
+	return $cvfolds;
+}
+
+################################################################################
+# createCVFolds
+################################################################################
+# Create the %cvFolds object, which is an array with keys that are fold numbers.
+# The values of the array are arrays whose keys are class labels, whose values 
+# are arrays of instance_ids.
+################################################################################
+sub createCVFolds() {
+	
+	my $debug = 50;
+	
+	my $num_cvfolds = $_[0];
+	my $cvFolds = $_[1];
+	my $classes = $_[2];
+	my $instances_by_id = $_[3];
+	
+	my $num_instances = @{$instances_by_id};
+	my %num_holdouts = ();
+	my %randomized_instances = ();
+	my %class_max_holdouts_per_fold = ();
+	my %class_avg_holdouts_per_fold = ();
+	
+	my $avg_holdouts_per_fold = $num_instances / $num_cvfolds;
+	my $max_holdouts_per_fold = ceil($num_instances / $num_cvfolds);
+	my $holdout_ratio = $avg_holdouts_per_fold / $num_instances;
+		
+	my %all_instances = ();
+	my %randomized_instances = ();
+	
+	# Create a randomized array of instance_ids for each class
+	foreach my $class (sort(keys(%$classes))) {
+		$all_instances{$class} = keys(%{$classes->{$class}});
+		my @class_randomized_instances = keys(%{$classes->{$class}});
+		&randomizeArrayOrder(\@class_randomized_instances);
+		$randomized_instances{$class} = [ @class_randomized_instances ];		
+		undef(@class_randomized_instances);
+	}
+
+	# Initialize each CV fold as a full run -- we'll trim it later
+	for (my $fold_number = 1; $fold_number <= $num_cvfolds; $fold_number++) {
+		foreach my $class (sort(keys(%$classes))) {
+			foreach my $instance_id (sort(keys(%{$classes->{$class}}))) {
+				$cvFolds->{$fold_number}{$class}{$instance_id} = 1;
+			}
+		}
+	}
+
+	my $fold_number = 1;
+	foreach my $class (sort(keys(%$classes))) {
+		foreach my $holdout_instance_id (keys(%{$classes->{$class}})) {
+			delete($cvFolds->{$fold_number}{$class}{$holdout_instance_id});
+			$cvFolds->{$fold_number}{'HOLDOUTS'}{$holdout_instance_id} = 1;
+			$fold_number++;
+			if ($fold_number > $num_cvfolds) {
+				$fold_number = 1;
+			}
+		}
+	}
+}	
+
+
+################################################################################
+# sub randomizeArrayOrder
+################################################################################
+# Take a pointer to an array and randomizes the order of the elements in that
+# array.
+# 
+# Taken from: http://www.unix.org.ua/orelly/perl/cookbook/ch04_18.htm
+################################################################################
+sub randomizeArrayOrder {
+	my $array = shift;
+    my $i;
+    for ($i = @$array; --$i; ) {
+    	my $j = int rand ($i+1);
+        next if $i == $j;
+        @$array[$i,$j] = @$array[$j,$i];
+    }
+}
+
+################################################################################
+# formatScore - take a decimal and truncate to some reasonable length
+################################################################################
+sub formatScore {
+	my $number = $_[0];
+	return sprintf("%.4f", $number)
+}
+
+################################################################################
+# checkForErrors - someday we'll expand this to do robust error checking on user
+# input
+################################################################################
+sub checkForErrors() {
+	
+	my $params = $_[0];
+	
+	if ($params->{'TASK'} eq 'predict_on_unseen') {
+		if ($params->{'CLASSIFYON'} eq '') {
+			&throwError("To predict on unseen data, choose a field to classify on.");
+		}
+	}
+}
+
diff -Nuar philomine2/cgi-bin/philomine2.08142018.ok philomine2patched/cgi-bin/philomine2.08142018.ok
--- philomine2/cgi-bin/philomine2.08142018.ok	1969-12-31 18:00:00.000000000 -0600
+++ philomine2patched/cgi-bin/philomine2.08142018.ok	2018-08-13 19:09:23.264348804 -0500
@@ -0,0 +1,1165 @@
+#!/usr/bin/perl
+
+# DEBUGGING
+my $debug = 0;
+ 
+# MODULES
+use CGI;
+use URI::Escape;
+use POSIX qw(ceil floor);
+use IO::Tee;
+use Data::Dumper;
+
+# TODO what does this do?
+no strict "refs";
+
+# INCLUDES
+require "config.pl";
+require "instance_functions.pl";
+require "feature_functions.pl";
+require "feature_filter_functions.pl";
+require "description_functions.pl";
+require "utility_functions.pl";
+require "form_components/function_data.pl";
+require "/etc/philologic31/dbnames";
+require "/etc/philologic31/philologic31.cfg";
+
+# Query param state saved via CGI.pm
+my $state_filename = "/tmp/$$" . "_philomine_params.state";
+
+%params = ();
+# If ARVG contains something, we aren't being run as a CGI, but rather from the command line
+if ($ARGV[0] ne '') {
+	&prepareParamsFromState(\%params, $ARGV[0]);
+} else {
+
+	print "Content-type: text/html\n\n";
+
+	&prepareParams(\%params);
+	
+	if (exists($params{'OFFLINE'})) {
+		print "<html><body>Execute your run with this command:<br><br>&nbsp;&nbsp;&nbsp;&nbsp;";
+		print "perl " . $PHILOMINCGIPATH . "/philomine2 $state_filename";
+		print "</body></html>";
+		exit();
+	}
+}
+
+# RUNDIR
+&createRundir(\%params);
+
+# philominesubs.pl
+my $dbname = $params{'dbname'}; 
+require "$PHILODATADIR/databases/$dbname/lib/philominesubs.pl";
+
+# Archive the state in the rundir
+my $state_cmd = "cp $state_filename " . $params{'rundir'} . "/state/";
+$res = `$state_cmd`;
+ 
+
+# HTML OUTFILE -- ALLOUT is a global filehandle that printOutFile
+# write to (in addition to writing to STDOUT)
+$all_outfile = $params{'rundir'} . "/html/all.html";
+open ALLOUT, ">$all_outfile";
+
+# HEADER
+$header_outfile = $params{'rundir'} . "/html/header.html";
+open HEADOUT, ">$header_outfile";
+open HEADIN, "$PHILOMINHTMLDIR/philomine_header.html";
+while (my $line = <HEADIN>) {
+	print HEADOUT $line;
+}
+close HEADIN;
+close HEADOUT;
+&printOutFile($header_outfile);
+
+# CHECK
+&checkForErrors(\%params);
+# Process the submitted include or exclude features, if the user has submitted
+# any from checkboxes on the form on a previous mining run.
+&processFeatureLists(\%params);
+
+# ACCESS CONTROL
+# We now have a database to talk to and the database
+# specific parameters.  Let's see if we can run this search.
+if ($PhiloLogicAccesControl) {
+        $filetest = $SYSTEM_DIR . "/lib/security.ph";
+        if (! -e $filetest) {
+                $LINKDICT = 0;
+                print &mkTitle;
+                print "<p>\n<p>\n";
+                print "Cannot find required access control module for ";
+                print $dbname;
+                print ". Contact $ERRORCONTACT.";
+                print &kwicfooter;
+                exit (0);
+                }
+        require "security.ph";
+        if (!&security_check) {
+                $LINKDICT = 0;
+                print &mkTitle;
+                print "<p>\n<p>\n";
+                print $REJECT_MESSAGE;
+                print "<p>Requesting Computer Address: ";
+                if ($host) {
+                        print "$host ";
+                        }
+                if ($ip) {
+                        print " $ip";
+                        }
+                print "\n";
+                print &kwicfooter;
+                exit (0);
+                }
+        }
+
+# More variable setting....
+# TODO do we need this?
+$|=1;
+$ENV{'PATH'} = $SYSTEM_DIR . ":" . $PHILOCGIPATH . ":/bin:/usr/bin";
+$ENV{'SYSTEM_DIR'} = $SYSTEM_DIR;
+$parid = $$;
+
+
+
+# TODO does this work at all?
+if ($MINEMODE eq "SELECT") {
+
+	# TODO finish this up
+	# Use selected corpus mode -- there are two phases. First the user
+	# selects the corpora and then the mining is run. Let's see what phase
+	# we are in here. If there is anything in the c1 and c2selections 
+	# querystring parameters, then the selections have already been
+	# commited by the user. 
+	
+	# Has the user selected the corpora already?
+	if ($ENV{'QUERY_STRING'} =~ /c1selections=/ && $ENV{'QUERY_STRING'} =~ /c2selections=/) {
+		print "Selected!";
+		
+		# We need to 
+		
+	} else {
+
+		# We'll run the normal GetDocVectors routine, so that we'll only
+		# print out the documents that the user may have narrowed things
+		# down to by selecting some criteria on the previous form.
+		&GetDocVectors();
+		
+		print "<center><h2>Bibliography Corpus One</h2></center>";
+
+		# We want all the current URL parameters to get passed along to this
+		# page again when the user submits the form. Therefore, we print out
+		# hidden form fields for each current URL parameter. Is there a better way?
+		print "\n\n<form action='philomine2' method='GET'>\n\n"; 
+		
+		print &getHiddenQSFields($params);
+		
+		# Keep track of how many biblines have been printed, so we can get
+		# the philodocid out of the $c1docvector, which should contain the 
+		# same documents in the same order as the bibbuffers.
+		$c1bibcount = 0;
+	
+		foreach $bline (@c1bibbuffer) {
+			$philodocid = $c1docvector[$c1bibcount];
+			$c1bibcount++;
+					
+			print "<p>";
+			print '<input type="checkbox" name="c1selections" value="' . $philodocid . '">';
+			@r = split(/\t/, $bline);
+			$x = $r[$#r];
+			print &mkBiblio($bline);
+			print " wc=" . $countbydocid[$x] . " ";
+		}
+	                
+		print "<hr>";
+		print "<center><h2>Bibliography Corpus Two</h2></center>";
+	
+		$c2bibcount = 0;
+		foreach $bline (@c2bibbuffer) {
+			$philodocid = $c2docvector[$c2bibcount];
+			$c2bibcount++;
+	
+			print "<p>";
+			print '<input type="checkbox" name="c2selections" value="' . $philodocid . '">';
+			@r = split(/\t/, $bline);
+			$x = $r[$#r];
+			print &mkBiblio($bline);
+			print " wc=" . $countbydocid[$x] . " ";
+		}
+		
+		print "<hr>";
+		print "<input type='submit' name='Submit' value='Submit Corpora'></form>";
+		print &kwicfooter;
+		exit 0;
+	}
+}
+
+
+
+# FUNCTIONS
+%function_titles = ('RELRATE' => 'Differential Relative Word Frequencies', 
+					'MULTIBAYES' => 'Classifier: Multinominal Naive Bayes',
+					'DECISIONTREE' => 'Classifier: Decision Tree',
+					'WEKABAYES' => 'Classifier: Weka Naive Bayes',
+					'WEKAIG' => 'Information Gain (Weka)',
+					'WEKAJ48' => 'Decision Tree J48 (Weka)',
+					'WEKAMLP' => 'Multilayer Perceptron (Weka)',
+					'SVMLight' => 'Classifier: Support Vector Machine (SVM Light)',
+					'SVMLIGHTMULTIOVA' => 'Classifier: Support Vector Machine (SVM Light) Multiclass One-vs-All',
+					'SVMLIGHTMULTIOVO' => 'Classifier: Support Vector Machine (SVM Light) Multiclass One-vs-One',
+					'SVMLight' => 'Classifier: Support Vector Machine (SVM Light)',
+					'WEKASMO' => 'Classifier: Support Vector Machine (Weka SMO)',
+					'VECTORSPACE' => 'Classifier: Vector Space',
+					'CLUTO' => 'Clusterer: CLUTO',
+					'WRITEDATA' => 'Write Data');
+
+%function_includes = ('RELRATE' => 'perlrelativerate_functions.pl', 
+					'MULTIBAYES' => 'perlbayes_functions.pl',
+					'DECISIONTREE' => 'perldecisiontree_functions.pl',
+					'WEKABAYES' => 'wekabayes_functions.pl',
+					'WEKAIG' => 'wekaig_functions.pl',
+					'WEKAJ48' => 'wekaj48_functions.pl',
+					'WEKAMLP' => 'wekamlp_functions.pl',
+					'SVMLight' => 'svmlight_functions.pl',
+					'SVMLIGHTMULTIOVA' => 'svmlight_functions.pl',
+					'SVMLIGHTMULTIOVO' => 'svmlight_functions.pl',
+					'WEKASMO' => 'wekasmo_functions.pl',
+					'VECTORSPACE' => 'vectorspace_functions.pl',
+					'CLUTO' => 'cluto_functions.pl',
+					'WRITEDATA' => 'writedata_functions.pl');
+
+
+if (exists($params{'MINEFUN'}) && $params{'MINEFUN'} ne '') {
+	require $function_includes{$params{'MINEFUN'}};
+} else {
+	&throwError('Please choose an algorithm.');
+}
+
+# COMMAND
+if ($params{'MINEFUN'} eq 'RELRATE') {
+	&DiffRelativeRate(\%params);
+} elsif ($params{'MINEFUN'} eq 'MULTIBAYES') {
+	&MultiBayes(\%params);
+} elsif ($params{'MINEFUN'} eq 'DECISIONTREE') {
+	&DecisionTree(\%params);
+} elsif ($params{'MINEFUN'} eq 'WEKABAYES') {
+	&WekaBayes(\%params);
+} elsif ($params{'MINEFUN'} eq 'WEKAIG') {
+	&WekaIG(\%params);
+} elsif ($params{'MINEFUN'} eq 'WEKAJ48') {
+	&WekaJ48(\%params);
+} elsif ($params{'MINEFUN'} eq 'WEKAMLP') {
+	&WekaMLP(\%params);
+} elsif ($params{'MINEFUN'} eq 'SVMLight') {
+	&SVMLight(\%params);
+} elsif ($params{'MINEFUN'} eq 'SVMLIGHTMULTIOVA') {
+	&SVMLightMultiOVA(\%params);
+} elsif ($params{'MINEFUN'} eq 'SVMLIGHTMULTIOVO') {
+	&SVMLIGHTMULTIOVO(\%params);
+} elsif ($params{'MINEFUN'} eq 'WEKASMO') {
+	&WekaSMO(\%params);
+} elsif ($params{'MINEFUN'} eq 'VECTORSPACE') {
+	&VectorSpace(\%params);
+} elsif ($params{'MINEFUN'} eq 'CLUTO') {
+	&CLUTO(\%params);
+} elsif ($params{'MINEFUN'} eq 'WRITEDATA') {
+	&WriteData(\%params);
+}
+
+# FOOTER
+$footer_outfile = "$rundir/html/footer.html";
+open FOOTOUT, ">$footer_outfile";
+open FOOTIN, "$PHILOMINHTMLDIR/philomine_footer.html";
+while ($line = <FOOTIN>) {
+	print FOOTOUT $line;
+}
+close FOOTIN;
+close FOOTOUT;
+&printOutFile($footer_outfile);
+
+close ALLOUT;
+
+# If this was an offline run from the command line, print out a little something extra
+# to let them know where to look at the results online
+if (exists($params{'OFFLINE'})) {
+	print "\n\n\nLook for your results here:\n\n";
+	print $PHILOMINHTMLURL . "/runs/" . $params{'runname'} .  "/html/all.html\n\n";
+}
+
+# Unless otherwise specified on the form, DELETE the run directory
+if (! exists($params{'SAVERUN'})) {
+	my $cmd = "rm -rf " . $params{'rundir'};
+	my $res = `$cmd`;
+}
+
+################################################################################
+# End of main routine
+################################################################################
+
+################################################################################
+# sub WriteReQueryForm
+################################################################################
+# Purpose: Write out an opening form tag for re-running this 
+# run and curling the output to an outfile. Then, redirect this page to that
+# curled file once it is finished being downloaded.
+#
+# At the moment, there seem to be some problems with doing this on very, very
+# long runs (more than a couple hours).
+#
+################################################################################
+sub WriteReQueryForm {
+	local ($arg, $var, $value);
+        $thisformaction = "<form action=\"http://artflsrv02.uchicago.edu/cgi-bin/perseus31/philomine2/philomine?";
+        $thisformaction .= "\" target='rerun'>";
+        print $thisformaction;
+	foreach $arg (@argbuffer) {
+	        $arg =~ s/\%3A/:/g;
+                $arg =~ s/\%2C/,/g;
+       		$arg =~ s:\%2F:/:g;
+       		$arg =~ s:\%20: :g;
+                $arg =~ s/\%60//g;
+                $arg =~ m/(\s*)=/;
+                $arg =~ m/=(\s*)/;
+                ($var, $value) = split(/\s*=\s*/, $arg, 2);
+		if ($var eq "MINEFUN" ) {
+			$value = "MULTIBAYES";
+			}
+		if ($var eq "USERFEATURES") {
+			$donothing = "";
+			}
+		else {
+		    print "<input type=\"hidden\" name=\"" . $var . "\"";
+		    print " value=\"" . $value . "\">\n";
+			}
+		}
+return;
+}
+
+################################################################################
+# sub createRundir
+################################################################################
+# Purpose: create the directories needed for a philomine run
+# and assign a new $runname if the current one is already taken.
+################################################################################
+sub createRundir() {
+
+	my $params = $_[0];
+	
+	my $runname = $params->{'runname'};
+	my $newrunname = $params->{'runname'};
+
+	my $non_digits;
+	my $adddigit;
+
+	# If it ends in a number, we'll increment it
+	if ($runname =~ /^(.*?)(\d+)$/) {
+		$non_digits = $1;
+		$addigit = $2;
+	} else {
+		$non_digits = $runname;
+		$addigit = 1;
+	}
+
+	# Comment this bit out if you want to overwrite instead of 
+	# incrementing	
+	while (-e "$PHILOMINDIR/runs/$newrunname") {
+       $newrunname = $non_digits . $addigit;
+       $addigit++;
+	}
+	
+	$runname = $newrunname;
+
+	# The directory for this run
+	$rundir = $PHILOMINDIR . '/runs/' . $runname;
+
+	# If it already exists, destroy it
+	my $res = `rm -rf $rundir`;
+
+	# Create some directories to store the data.
+	$res = `mkdir -p $rundir/{arrays,html,docfiles,features,state}`;
+	if (exists($params->{'CSVOUTPUT'}) && exists($params->{'CSVOUTPUT'}) ne '') {
+		$res = `mkdir -p $rundir/csv`;	
+	}
+	
+	$params->{'runname'} = $runname;
+	$params->{'rundir'} = $rundir;
+}
+
+################################################################################
+# sub trimOutput($data)
+################################################################################
+# Purpose: We sometimes have really long lines that make for poor HTML
+# presentation. Let's trim them and leaves ellispes.
+################################################################################
+
+sub trimOutput() {
+
+	my $data = $_[0];
+
+	$data =~ s/^(.{130}).*$/\1&#8230;/mg;
+
+	return $data;
+}
+
+
+################################################################################
+# sub instanceLink
+################################################################################
+# Purpose: Create a link to the PhiloLogic display for an instance
+################################################################################
+sub instanceLink() {
+
+	my $debug = 0;
+
+	my $instance = $_[0];
+	my $dbname = $_[1];
+
+	# DOC level instance
+	if ($instance =~ /^\d*$/) {
+		$link = "$PHILOCGI/navigate.pl?$dbname.$instance";
+
+	# DOC level instance composed of multiple divs
+	} elsif ($instance =~ /,/) {
+		$instance =~ s/,/\+OR\+/g;
+		$link = "$PHILOCGI/search3t?dbname=$dbname&dgphilodivid=" . &uri_escape($instance);
+	
+	# DIV level instance
+	} elsif ($instance =~ /:/) {
+		$link = "$PHILOCGI/getobject.pl?c.$instance.$dbname";
+	}
+	
+	return $link;
+}
+	
+################################################################################
+# sub wordSearchLink
+################################################################################
+# Purpose: Create a link to search on a certain word
+################################################################################
+sub wordSearchLink() {
+
+	my $debug = 0;
+
+	my $params = $_[0];
+	my $word = $_[1];
+	my $linktext = $_[2];
+	my $corpus = $_[3];
+
+	# TODO to make this multi-db safe....
+
+	my $link = "<a href=\"". $PHILOSEARCH3T;
+	$link .= "?dbname=" . &uri_escape($params->{'dbname'});
+
+	# For bigrams and bilemmas, we'll do a proxy search with a distance of 2. This won't
+	# be perfect, but better than nothing.
+	if ($word =~ /_/) {
+		my $search_terms = $word;
+		$search_terms =~ s/_/ /g;
+		$link .= "&OUTPUT=conc&CONJUNCT=PROXY&DISTANCE=2";
+		$link .= "&word=" . &uri_escape($search_terms);
+	} else {
+		$link .= "&OUTPUT=conc&CONJUNCT=PHRASE";
+		$link .= "&word=" . &uri_escape($word);
+	}
+
+	&bugger($debug, "LINK Corpus $corpus div args: " . 	$params->{$corpus . '_div_args'} . "<br>");
+	
+	# We need to see if we are printing out a string that is the same as
+	# the c1multidoc, the c2multidoc, or the combined "all multidoc. If so,
+	# we'll pass a different paramter, multidocfile, that contains the location
+	# of the multidoc file that in turn contains the multidoc string.
+	
+	# We do this because the multidoc strings can be very long, and it generates
+	# an enormously unwieldy HTML file to have them encoded in every link.
+	# A hacked version of search3t knows how to dig out the multidoc file
+	# and get the bibliography from there.
+	
+	my $multidoc = "&multidocfile=" . $params->{'rundir'} . "/docfiles/$corpus";
+	
+	$link .= $multidoc . "\">" . $linktext . "</a>";
+	
+	# We don't want %20, we want +
+	$link =~ s/%20/\+/g;	
+
+	return $link;
+}
+
+################################################################################
+# sub allWordSearchLink - create a link to search for a word for all corpora
+################################################################################
+sub allWordSearchLink() {
+
+	my $params = $_[0];
+	my $corpora = $_[1];
+	my $word = $_[2];
+	my $id = $_[3];
+	my $class = $_[4];
+	
+	my $links = '<span id="linkedword_' . $class . $id . '" class="linkedword">' . $word;
+	$links .= ' <span id="wordlinks_' . $class . $id . '" class="wordlinks">';
+
+	foreach my $corpus (sort(keys(%$corpora))) {
+		$links .= ' ' . &wordSearchLink($params, $word, "[$corpus]", $corpus);
+	}
+	
+	$links .= ' ' . &wordSearchLink($params, $word, "[all]", 'all');
+	
+	$links .= '</span></span>';
+	
+	return $links;
+}
+
+
+################################################################################
+# sub getHiddenQSFields()
+################################################################################
+# Print out a hidden form field for each name value pair in the querystring
+# This is useful if you want to submit a new form to the same page, and retain
+# all of the current GET parameters.
+################################################################################
+sub getHiddenQSFields() {
+
+	my $params = $_[0];
+	
+	my $output = '';
+
+	foreach my $var (keys(%$params)) {
+		my $value = $params->{$var};
+		# Escape double quotes and backslashes
+		$value =~ s/\\/\\\\/g;
+		$value =~ s/"/\"/g;
+		$value =~ s/\+/ /g;
+		$output .= '<input type="hidden" name="' . $var . '" value="' . $value . "\">\n";		
+	}
+
+	return $output;
+}
+
+
+################################################################################
+# formLink - return a link to the CGI that draws up a form based on the 
+# parameters of this run
+################################################################################
+sub formLink() {
+
+	my $params = $_[0];
+
+	my $link;
+	my $qs;
+	
+	foreach my $var (keys(%$params)) {
+		my $value = $params->{$var};
+
+		# A literal + is a space
+		$value =~ s/\+/ /g;
+	
+		# URL encode the values, code taken from:
+		# http://support.internetconnection.net/CODE_LIBRARY/Perl_URL_Encode_and_Decode.shtml	
+		$value =~ s/([^A-Za-z0-9\-\.])/sprintf("%%%02X", ord($1))/seg;
+
+		$qs .= $var . '=' . $value . '&';
+	}
+	
+	$link = $PHILOMINECGIFORMURL . '?' . $qs . '&LINKEDFORM=yes';
+	return $link;
+}
+
+
+################################################################################
+# getVectorLength - return the length of the vector
+################################################################################
+sub getVectorLength() {
+	my $vector = $_[0];
+	my $length = 0;
+	foreach my $value (values(%$vector)) {
+		$length += $value**2;
+	}
+ 	return sqrt($length);
+}
+
+################################################################################
+# scaleVector - multiply every value in the vector by a value
+################################################################################
+sub scaleVector() {
+	my $vector = $_[0];
+	my $scalar = $_[1];
+	foreach $feature (keys(%$vector)) {
+#		print $vector->{$feature};
+		$vector->{$feature} = $vector->{$feature} * $scalar;
+#		print "\n$vector->{$feature}";
+	}
+}
+
+################################################################################
+# normalizeVector - perform an L2 noramlization on the vector, to unit length
+################################################################################
+sub normalizeVector() {
+	my $vector = $_[0];
+	my $length = &getVectorLength($vector);
+	if ($length != 0) {
+		&scaleVector($vector, 1/$length);
+	} else {
+		#print "Vector length 0... ";
+	}
+}
+
+################################################################################
+# normalizeInstanceData - perform an L2 noramlization on all data
+################################################################################
+sub normalizeInstanceData() {
+	my $debug = $debug;
+	my $instance_data = $_[0];
+	foreach my $instance_id (keys(%$instance_data)) {
+		&bugger($debug, "Normalizing instance_id: $instance_id<br>");
+		&normalizeVector($instance_data->{$instance_id});
+	}
+}	
+
+################################################################################
+# scaleDataRatePer10k - change instance data to rate per 10k
+################################################################################
+sub scaleDataRatePer10k() {
+
+	my $instance_data = $_[0];
+
+	foreach my $instance_id (keys(%$instance_data)) {
+		my $vector_size = 0;
+		foreach my $value (values(%{$instance_data->{$instance_id}})) {
+			$vector_size += $value;
+		}
+		my $scalar = 10000/$vector_size;
+		&scaleVector($instance_data->{$instance_id}, $scalar);
+	}
+}	
+	
+
+################################################################################
+# renumberInstances - after filtering instances, give them fresh IDs
+################################################################################
+sub renumberInstances() {
+
+	my $debug = 57;
+	
+	my $corpora = $_[0];
+	my $instances = $_[1];
+	my $all_ids_by_instance = $_[2];
+	my $instance_descriptors = $_[3];
+	my $classes_by_instance_id = $_[4];
+	
+	&bugger($debug, "renumbering, got corpora " . join(' ', sort(keys(%$corpora))). "<br>");
+
+	# We can't simply copy the array because in Perl nested hashes contain
+	# pointers to anonymous arrays, not the arrays themselves, so we resort
+	# to this, a per-instance clone of one array to another.
+
+	my %old_corpora = ();
+	foreach my $corpus (sort(keys(%$corpora))) {
+		$old_corpora{$corpus} = ();
+		foreach my $instance_id (keys(%{$corpora->{$corpus}})) {
+			$old_corpora{$corpus}{$instance_id} = $corpora->{$corpus}{$instance_id};
+		}
+	}
+	
+	my @old_instance_descriptors = @$instance_descriptors;
+	my @old_classes_by_instance_id = @$classes_by_instance_id;
+	my @old_instances = @$instances;
+	%$corpora = ();
+	@instances = ();
+	@instance_descriptors = ();
+	@classes_by_instance_id = ();
+	
+	foreach my $corpus (sort(keys(%old_corpora))) {
+		
+		foreach my $old_instance_id (sort {&philosort($old_instances[$a], $old_instances[$b])} keys(%{$old_corpora{$corpus}}) ) {
+			my $instance = $old_instances[$old_instance_id];
+			push(@$instances, $instance);
+			my $new_instance_id = $#{$instances};
+			$instance_descriptors->[$new_instance_id] = $old_instance_descriptors[$old_instance_id];
+			$classes_by_instance_id->[$new_instance_id] = $old_classes_by_instance_id[$old_instance_id];
+			$corpora->{$corpus}{$new_instance_id} = ();
+		}		
+	}
+	
+	%$all_ids_by_instance = ();
+	&turnArrayIntoHash($instances, $all_ids_by_instance);
+}
+
+
+################################################################################
+# buildCorpora - maine function to assemble the instance data and features
+################################################################################
+sub buildCorpora() {
+
+	my $debug = 50;
+
+	my $params = $_[0];
+	my $corpora = $_[1];
+	
+	my $minefields = $_[2];
+	my $function_dir = $_[3];
+	my $instances = $_[4];
+	my $features = $_[5];
+	my $instance_descriptors = $_[6];
+	my $classes_by_instance_id = $_[7];
+	my $instance_data = $_[8];
+	
+	# INSTANCES 
+	my $instances_outfile = $params->{'rundir'} . "/html/instances.html";
+	open INSTANCESOUT, ">$instances_outfile";	
+ 	print INSTANCESOUT "<div class='optiongroup'><h3>Instances</h3>";
+	print INSTANCESOUT "<span class='toggleswitch' id='toggleswitch_sql'>►SQL</span>";
+	print INSTANCESOUT "<div class='toggle startoff' id='sql'>";
+	
+	# GET INSTANCES for each corpus
+	foreach my $corpus (sort(keys(%$corpora))) {
+		my %instances = ();
+		my %classes_by_instance = ();
+		&getInstances($params, \%instances, $corpus, \%classes_by_instance, *INSTANCESOUT);
+
+		# Add the instances to the @instances array, find out their
+		# instance_id, then add the instance_id to the %corpora hash and the 
+		# instance_descriptors array.
+		while ( (my $instance, my $instance_descriptor) = each (%instances) ) {
+			push(@$instances, $instance);
+			my $instance_id = $#{$instances};
+			$instance_descriptors->[$instance_id] = $instance_descriptor;
+			$corpora->{$corpus}{$instance_id} = ();
+			$classes_by_instance_id->[$instance_id] = $classes_by_instance{$instance};
+		}		
+		undef(%classes_by_instance);
+		undef(%instances);
+	}
+
+	print INSTANCESOUT "</div>";
+
+	my %all_ids_by_instance = ();
+	&turnArrayIntoHash($instances, \%all_ids_by_instance);
+
+	# Summarize the instances for each corpus
+ 	print INSTANCESOUT '<table class="results"><tr><td></td>';
+	foreach my $corpus (sort(keys(%$corpora))) {
+	 	print INSTANCESOUT '<th>' . $corpus . '</th>';
+	}
+	print INSTANCESOUT '<th>All Corpora</th></tr>';
+	print INSTANCESOUT '<tr><th>Initial Instances</th>';
+	foreach my $corpus (sort(keys(%$corpora))) {
+		my $corpus_size = keys(%{$corpora->{$corpus}});
+	 	print INSTANCESOUT  '<td>' . $corpus_size . '</td>';
+	}
+ 	print INSTANCESOUT  '<td>' . @$instances . '</td></tr>';
+
+	# FILTER the instances
+	&filterInstances($params, $corpora, $instances, *INSTANCESOUT);
+
+	# Check to see if filtering has removed all of the instances from any corpus
+	foreach my $corpus (sort(keys(%$corpora))) {
+		if (scalar(keys(%{$corpora->{$corpus}})) == 0) {
+			&throwError("No instances are left after filtering for corpus $corpus. Please change your criteria and try again.");
+		}
+	}
+	
+	&renumberInstances($corpora, $instances, \%all_ids_by_instance, $instance_descriptors, $classes_by_instance_id);
+
+	# Balance the instances
+	if ($params->{'BALANCER'}) {
+	 	print INSTANCESOUT  &balanceCorpora($params, $corpora);
+		&renumberInstances($corpora, $instances, \%all_ids_by_instance, $instance_descriptors, $classes_by_instance_id);
+	}
+
+	print INSTANCESOUT '<tr><th>Final Instances</th>';
+	foreach my $corpus (sort(keys(%$corpora))) {
+		my $corpus_size = keys(%{$corpora->{$corpus}});
+	 	print INSTANCESOUT  '<td>' . $corpus_size . '</td>';
+	}
+ 	print INSTANCESOUT  '<td>' . @$instances . '</td></tr>';
+ 	print INSTANCESOUT '</table><br>';
+
+	# Randomize the corpus assignments of the instances for a random falsification
+	# test.
+	if ($params{'SHUFFLE'}) {
+#		print INSTANCESOUT  &randomizeInstanceCorpora($params, $corpora);
+		print INSTANCESOUT  &randomizeInstanceClasses($params, $corpora);
+	}
+	print INSTANCESOUT '</div>';
+	close INSTANCESOUT;
+	
+	&printOutFile($instances_outfile);
+
+	# DIV ARGS
+	# Are all the corpora div arguments the same? If so, we should set $params->{'all_div_args'}
+	# so that when we push searches to PhiloLogic, the div args are pushed for 'all'. If they
+	# differ between corpora, there's nothing we can do, because we can't tell PhiloLogic to use
+	# different div args for different documents, so we don't use any div args at all.
+	my $last_args = 'NONE'; 
+	my $args_differ = 0;
+	my $have_div_args = 0;
+	my $instance_type = '';
+	foreach my $corpus (sort(keys(%$corpora))) {
+		if ($last_args eq 'NONE') {
+			$last_args = $params->{$corpus . '_div_args'};
+		} else {
+			if ($last_args ne $params->{$corpus . '_div_args'}) {
+				$args_differ = 1;
+				last;
+			} else {
+				$last_args = $params->{$corpus . '_div_args'};
+			}
+		}
+		if ($params->{$corpus . '_div_args'} ne '') {
+			$have_div_args = 1;
+		}
+	}
+	if ($args_differ) {
+		$params->{'all_div_args'} = '';
+	} else {
+		$params->{'all_div_args'} = $last_args;
+	}
+	if ($params->{'INSTANCELEVEL'} eq 'div') {
+		$instance_type = 'div';
+	} elsif ($params->{'INSTANCELEVEL'} eq 'document' && $have_div_args) {
+		$instance_type = 'multidiv';
+	} else {
+		$instance_type = 'document';
+	}
+
+	############################################################################
+	# Features 
+	# Now that we have all the instances, we can get all the feature values for
+	# them.
+	############################################################################
+
+	my $features_outfile = $params->{'rundir'} . "/html/features.html";
+	open FEATURESOUT, ">$features_outfile";
+
+	print FEATURESOUT "<div class='optiongroup'><h3>Features</h3>";
+
+	# Make sure we have at least one featureset
+	my $found_a_featureset = 0;
+
+	foreach $featureset (@featuresets) {
+
+		if (exists($params->{'FEATURESET' . $featureset})) {
+
+			$found_a_featureset = 1;
+
+			print FEATURESOUT "Featureset: $featureset<br><br>";
+
+			my $featureset_dir = "$rundir/featuresets/$featureset";
+			my %instance_feature_values = ();
+			my %feature_instance_counts = ();
+			my %instance_feature_value_totals = ();
+	
+			&getAndFilterFeatures($params, $instances, \%all_ids_by_instance, \%instance_feature_values, \%feature_instance_counts, \%instance_feature_value_totals, $featureset, $featureset_dir, $instance_type, *FEATURESOUT);
+	
+			# Now that we have received back the features, we need to integrate them into
+			# the all_features arrays. If we are dealing with multiple feature sets, we
+			# need to make sure we only refer to them by $feature_id, or there could
+			# be collisions. Probably shouldn't allow featuresets to name-collide anyway,
+			# WEKA etc might not like it.
+
+			my $instance_id;
+			my $instance;
+			my $feature;
+			my $feature_id;
+
+			foreach $feature (keys(%feature_instance_counts)) {
+#				push(@$features, $feature);
+				push(@features, $feature);
+#				print $feature . "\n";
+#				$feature_id = $#{@$features};
+				$feature_id = $#features;
+#				print #feature_id . "\n";
+				$all_ids_by_feature->{$feature} = $feature_id;
+			}
+			
+			# Now that we have assigned this feature an id, store the value of this
+			# feature for each instance in the %instance_data array.
+			$feature_id = $all_ids_by_feature->{$feature};
+			my %seen_instances = ();
+			for (my $instance_id = 0; $instance_id < scalar(@$instances); $instance_id++) {
+				my $instance = $instances->[$instance_id];
+				
+				if (exists($seen_instances{$instance})) {
+				#	print "Seen $seen instance: $instance instance_id $instance_id other instanceid: " . $seen_instances{$instance} ." \<br>";
+					$instance_data->{$instance_id} = $instance_data->{$seen_instances{$instance}};
+				#	print "After adding: ". $instance_data->{$instance_id} . " from " . $instance_data->{$seen_instances{$instance}} . "<br>";
+				} else {				
+					$seen_instances{$instance} = $instance_id;
+					foreach $feature (keys(%{$instance_feature_values{$instance_id}})) {
+						$feature_id = $all_ids_by_feature->{$feature};
+						$instance_data->{$instance_id}{$feature_id} = $instance_feature_values{$instance_id}{$feature};
+					}
+				}
+			}
+#			print "[" . Dumper($all_ids_by_feature) . "]";
+
+			undef(%seen_instances);
+			undef(%instance_feature_values);
+		}
+	}
+	
+	# We have gone through each featureset, accumulated the features and assigned them
+	# an id, and store their values in the %all_feature_instance_values array.
+	# Now let's complete the %instance_data array by storing each value for each feature for
+	# each instance for each corpus.
+
+	if (! $found_a_featureset) {
+		&throwError("Please choose at least one feature set for this run.");
+	}
+
+	undef(%all_ids_by_feature);
+	undef(%seen_instances);
+		
+
+
+	print FEATURESOUT "<b>Total features:</b> " . scalar(@$features) . '<br>';
+
+	
+	# MULTIDOCFILE
+	# Write out the multidoc file, which contains all the philodocids for each corpus, 
+	# so we can pass around a reference to that file in URLs and not the whole darn
+	# list, which can get pretty massive (especially when we have to print it
+	# thousands of times on a single page).
+	&writeMultidocFiles($params, $corpora, $instances);
+
+	# TF-IDF: If selected, transform the instance data to tf-idf values
+	if ($params->{'VALUETYPE'} eq 'TFIDFlog2') {
+		&tfidfInstanceData($instance_data, 'log2');
+		print FEATURESOUT 'Feature data converted to TF-IDF log 2<br>';
+	} elsif ($params->{'VALUETYPE'} eq 'TFIDFln') {
+		&tfidfInstanceData($instance_data, 'ln');
+		print FEATURESOUT 'Feature data converted to TF-IDF natural log<br>';
+	} elsif ($params->{'VALUETYPE'} eq 'TFIDFnolog') {
+		&tfidfInstanceData($instance_data, 'none');
+		print FEATURESOUT 'Feature data converted to TF-IDF no log<br>';
+	} elsif ($params->{'VALUETYPE'} eq 'rateper10k') {
+		&scaleDataRatePer10k($instance_data);
+		print FEATURESOUT 'Feature data converted to rate per 10k<br>';
+	}
+	
+	# L2 NORMALIZATION: If selected, do L2 normalization of the instances data
+	if ($params->{'NORMALIZATION'} eq 'L2') {
+		&normalizeInstanceData($instance_data);
+		print FEATURESOUT '<br>Feature data L2 normalized<br>';
+	}
+
+	print FEATURESOUT '</div>';
+	close FEATURESOUT;
+	 
+	&printOutFile($features_outfile);
+
+}
+
+sub tfidfInstanceData() {
+	
+	my $instance_data = $_[0];
+	my $log_type = $_[1];
+	
+	#print "TFIDF: log_type: $log_type<br>";
+	
+	my @instance_counts_per_feature_id = ();
+	my @feature_totals_per_instance_id = ();
+	
+	foreach my $instance_id (sort(keys(%$instance_data))) {
+		foreach my $feature_id (sort(keys(%{$instance_data->{$instance_id}}))) {
+			my $value = $instance_data->{$instance_id}{$feature_id};
+			$feature_totals_per_instance_id[$instance_id] += $value;
+			$instance_counts_per_feature_id[$feature_id]++;
+		}
+	}
+	
+	my $num_instances = scalar(@feature_totals_per_instance_id);
+	
+	foreach my $instance_id (sort(keys(%$instance_data))) {
+		foreach my $feature_id (sort(keys(%{$instance_data->{$instance_id}}))) {
+			my $value = $instance_data->{$instance_id}{$feature_id};
+			my $tf = $value / $feature_totals_per_instance_id[$instance_id];
+			my $df;
+			if ($log_type eq 'log2') {
+				$df = log_2($num_instances/$instance_counts_per_feature_id[$feature_id]);
+			} elsif ($log_type eq 'ln') {
+				$df = log($num_instances/$instance_counts_per_feature_id[$feature_id]);
+			} elsif ($log_type eq 'none') {
+				$df = $num_instances/$instance_counts_per_feature_id[$feature_id];
+			}
+			my $tfidf = $tf * $df;
+			if ($tfidf == 0) {
+				delete($instance_data->{$instance_id}{$feature_id});
+			} else {
+				$instance_data->{$instance_id}{$feature_id} = $tfidf;
+			}
+		#	print "instance_id: $instance_id feature_id: $feature_id value: $value feature totals: " . $feature_totals_per_instance_id[$instance_id] . " instance_counts: " . $instance_counts_per_feature_id[$feature_id];
+		#	print " log part: " . ($num_instances/$instance_counts_per_feature_id[$feature_id]) . " num_instances: $num_instances tf: $tf idf: $idf tf-idf: " . ($tf * $idf) . "<br>";
+		}
+	}
+}
+
+sub log_2() {
+	my $val = $_[0];
+	return log($val) / log(2);
+}
+
+################################################################################
+# sub formatDeletedNumber()
+################################################################################
+# When we are displaying a number of deleted elements, either features or 
+# instances, do we want to display a - before them, and do we want to display
+# 0 if 0 is the value, or just blank space? Or -0? I can't decide for sure
+# so with this function we can globally change it back later.
+#
+# Parameters:
+#
+#	$number - the number of items that were deleted
+#
+# Returns:
+#
+#	$number - the formatted value
+#
+################################################################################
+sub formatDeletedNumber() {
+	
+	my $number = $_[0];
+	
+	if ($number > 0) {
+		return '-' . $number;
+	} elsif ($number eq '0') {
+		return '0';
+	} else {
+		return $number;
+	}
+}
+
+
+################################################################################
+# sub setCVFolds
+################################################################################
+# Takes a number of cv_folds that was submitted on the form, and the number of
+# instances. Determines if there are enough instances to perform the desired 
+# number of runs. Returns the number of CV runs to be done.
+################################################################################
+sub setCVFolds() {
+
+	my $cvfolds = $_[0];
+	my $num_instances = $_[1];
+	
+	# Remove everything except numbers
+	$cv_folds =~ s/\D//g;
+	
+	if (! ($num_instances > 0)) {
+		die "The number of instances received by setCVFolds - $num_instances - was not more than 0.";
+	}
+	
+	# Default to 10 cross-validation folds
+	if ($cvfolds eq '' || $cvfolds < 0) {
+		$cvfolds = 10;
+	}
+	
+	if ($num_instances < $cvfolds) {
+		$cvfolds = $num_instances;
+	}
+	
+	return $cvfolds;
+}
+
+################################################################################
+# createCVFolds
+################################################################################
+# Create the %cvFolds object, which is an array with keys that are fold numbers.
+# The values of the array are arrays whose keys are class labels, whose values 
+# are arrays of instance_ids.
+################################################################################
+sub createCVFolds() {
+	
+	my $debug = 50;
+	
+	my $num_cvfolds = $_[0];
+	my $cvFolds = $_[1];
+	my $classes = $_[2];
+	my $instances_by_id = $_[3];
+	
+	my $num_instances = @{$instances_by_id};
+	my %num_holdouts = ();
+	my %randomized_instances = ();
+	my %class_max_holdouts_per_fold = ();
+	my %class_avg_holdouts_per_fold = ();
+	
+	my $avg_holdouts_per_fold = $num_instances / $num_cvfolds;
+	my $max_holdouts_per_fold = ceil($num_instances / $num_cvfolds);
+	my $holdout_ratio = $avg_holdouts_per_fold / $num_instances;
+		
+	my %all_instances = ();
+	my %randomized_instances = ();
+	
+	# Create a randomized array of instance_ids for each class
+	foreach my $class (sort(keys(%$classes))) {
+		$all_instances{$class} = keys(%{$classes->{$class}});
+		my @class_randomized_instances = keys(%{$classes->{$class}});
+		&randomizeArrayOrder(\@class_randomized_instances);
+		$randomized_instances{$class} = [ @class_randomized_instances ];		
+		undef(@class_randomized_instances);
+	}
+
+	# Initialize each CV fold as a full run -- we'll trim it later
+	for (my $fold_number = 1; $fold_number <= $num_cvfolds; $fold_number++) {
+		foreach my $class (sort(keys(%$classes))) {
+			foreach my $instance_id (sort(keys(%{$classes->{$class}}))) {
+				$cvFolds->{$fold_number}{$class}{$instance_id} = 1;
+			}
+		}
+	}
+
+	my $fold_number = 1;
+	foreach my $class (sort(keys(%$classes))) {
+		foreach my $holdout_instance_id (keys(%{$classes->{$class}})) {
+			delete($cvFolds->{$fold_number}{$class}{$holdout_instance_id});
+			$cvFolds->{$fold_number}{'HOLDOUTS'}{$holdout_instance_id} = 1;
+			$fold_number++;
+			if ($fold_number > $num_cvfolds) {
+				$fold_number = 1;
+			}
+		}
+	}
+}	
+
+
+################################################################################
+# sub randomizeArrayOrder
+################################################################################
+# Take a pointer to an array and randomizes the order of the elements in that
+# array.
+# 
+# Taken from: http://www.unix.org.ua/orelly/perl/cookbook/ch04_18.htm
+################################################################################
+sub randomizeArrayOrder {
+	my $array = shift;
+    my $i;
+    for ($i = @$array; --$i; ) {
+    	my $j = int rand ($i+1);
+        next if $i == $j;
+        @$array[$i,$j] = @$array[$j,$i];
+    }
+}
+
+################################################################################
+# formatScore - take a decimal and truncate to some reasonable length
+################################################################################
+sub formatScore {
+	my $number = $_[0];
+	return sprintf("%.4f", $number)
+}
+
+################################################################################
+# checkForErrors - someday we'll expand this to do robust error checking on user
+# input
+################################################################################
+sub checkForErrors() {
+	
+	my $params = $_[0];
+	
+	if ($params->{'TASK'} eq 'predict_on_unseen') {
+		if ($params->{'CLASSIFYON'} eq '') {
+			&throwError("To predict on unseen data, choose a field to classify on.");
+		}
+	}
+}
+
diff -Nuar philomine2/cgi-bin/philomine.formtemplate.html philomine2patched/cgi-bin/philomine.formtemplate.html
--- philomine2/cgi-bin/philomine.formtemplate.html	2008-06-13 16:03:18.000000000 -0500
+++ philomine2patched/cgi-bin/philomine.formtemplate.html	2018-07-30 17:32:18.055404225 -0500
@@ -14,7 +14,7 @@
 
 <body>
 
-    <form action="XXXFORMACTIONXXX" id="mine_form">
+    <form action="XXXFORMACTIONXXX/philomine2" id="mine_form">
 
     <center>
         <h2>PhiloMine: Classification and Statistical Functions</h2>
diff -Nuar philomine2/cgi-bin/utility_functions.pl philomine2patched/cgi-bin/utility_functions.pl
--- philomine2/cgi-bin/utility_functions.pl	2008-06-13 16:03:17.000000000 -0500
+++ philomine2patched/cgi-bin/utility_functions.pl	2018-08-11 19:03:41.918839826 -0500
@@ -1,6 +1,6 @@
 # Want debugging only for a specific routine? Change this variable to whatever
 # you set $debug to in that routine. Usually should be 1.
-$debug_true_value = 99;
+$debug_true_value = 1;
 
 # Want every single debugging message to be displayed? If you only want some,
 # try setting the local $debug variable inside a specific block.
diff -Nuar philomine2/etc/philomine.cfg philomine2patched/etc/philomine.cfg
--- philomine2/etc/philomine.cfg	2008-06-16 12:10:38.000000000 -0500
+++ philomine2patched/etc/philomine.cfg	2018-07-31 16:40:58.378609890 -0500
@@ -3,54 +3,56 @@
 # for the particular machine environment.
 ################################################################################
 # Philositecfg is the location of the install dir for Philologic
-$PHILOSITECFG = "${prefix}/etc/philologic";
+$PHILOSITECFG = "${prefix}/etc/philologic31";
 
 # Philomindir
 # This is the project directory, where runs get stored. Must be writeable
 # by the www user. Need not be in web space.
-$PHILOMINDIR = '/PATH/TO/philomine2';
+$PHILOMINDIR = '/var/lib/philologic31/philomine2';
+#$PHILOMINDIR = '/var/www/artflsrv02/html/perseus31/';
 
 # Philomineurl -- the web location of the Philomine cgi-bin directory
-$PHILOMINCGIURL = 'http://YOURHOSTNAMEHERE/cgi-bin/philomine2/philomine2';
+$PHILOMINCGIURL = 'http://artflsrv02.uchicago.edu/cgi-bin/perseus31/philomine2';
 
 # The URL for the CGI form that creates a form based on the current query string
-$PHILOMINECGIFORMURL = 'http://YOURHOSTNAMEHERE/cgi-bin/philomine2/philomine.classification.pl';
+$PHILOMINECGIFORMURL = 'http://artflsrv02.uchicago.edu/cgi-bin/perseus31/philomine2/philomine.classification.pl';
 
 # Philomine cgi path (filesystem)
 # This is the filesystem path to your cgi-bin philomine directory
-$PHILOMINCGIPATH = '/Library/WebServer/CGI-Executables/philomine2';
+$PHILOMINCGIPATH = '/var/www/artflsrv02/cgi-bin/perseus31/philomine2';
 
 # Philomin html url
 # The URL of the non-cgi part of the philomine install. Javascript and CSS files are served
 # from this location. This may be set to be in a cgi-bin if you like, just make sure to put
 # the www files from the philomine2 tarball in there.
-$PHILOMINHTMLURL = 'http://YOURHOSTNAMEHERE/philomine2';
+$PHILOMINHTMLURL = 'http://artflsrv02.uchicago.edu/perseus31';
 
 # Philomin html dir
 # The filesystem path to the non-cgi web directory
-$PHILOMINHTMLDIR = '/Library/WebServer/Documents/philomine2';
+$PHILOMINHTMLDIR = '/var/www/artflsrv02/html/perseus31';
 
 # The path to svm_light
-$SVMLIGHTDIR = '/svm_light';
+$SVMLIGHTDIR = '/usr/local/philomine2/svm_light';
 
 # The database stuff for Philomine
 $MYSQLDB = 'philologic';
 $MYSQLUSER = 'philologic';
-$MYSQLPASS = 'YOURDBPASSWORD';
-$MYSQLCMD = '/sw/bin/mysql';
+$MYSQLPASS = 'martini';
+$MYSQLCMD = '/usr/bin/mysql';
 
 # Weka path... needs to be added to CLASSPATH before running Weka java commands
-$WEKAPATH = '/weka-3-4-11/weka.jar';
+$WEKAPATH = '/usr/local/philomine2/weka-3-4-11/weka.jar';
 
 # How many MBs to give weka? Can be overridden on the search form.
 $WEKAMEMORY = '2000m';
 
 # GraphViz is a graph-drawing application. We need to know its path if we use it.
-$GRAPHVIZPATH = '/Applications/Graphviz.app/Contents/MacOS';
+#$GRAPHVIZPATH = '/Applications/Graphviz.app/Contents/MacOS';
+$GRAPHVIZPATH = '';
 
 # CLUTO clustering engine path
-$VCLUSTERPATH = '/cluto-2.1.2/Darwin-i386';
+$VCLUSTERPATH = '/usr/local/philomine2/cluto-2.1.1/Linux';
 
 # AGREP path
-$AGREPPATH = '/opt/local/bin/agrep';
+$AGREPPATH = '/usr/bin/agrep';
 ################################################################################
diff -Nuar philomine2/form_components/algorithm_options/MULTIBAYES.pl philomine2patched/form_components/algorithm_options/MULTIBAYES.pl
--- philomine2/form_components/algorithm_options/MULTIBAYES.pl	1969-12-31 18:00:00.000000000 -0600
+++ philomine2patched/form_components/algorithm_options/MULTIBAYES.pl	2018-07-28 16:46:40.917340666 -0500
@@ -0,0 +1,3 @@
+print 'Foo';
+
+1;
\ No newline at end of file
diff -Nuar philomine2/form_components/form_functions.pl philomine2patched/form_components/form_functions.pl
--- philomine2/form_components/form_functions.pl	1969-12-31 18:00:00.000000000 -0600
+++ philomine2patched/form_components/form_functions.pl	2018-07-30 19:23:21.220967984 -0500
@@ -0,0 +1,486 @@
+#!/usr/bin/perl
+
+sub getFormComponent() {
+
+	my $debug = 0;
+
+	my $params = $_[0];
+	my $component = $_[1];
+	
+	my $output = '';
+	
+	if ($debug) {$output .= "Form component: $component params: $params task: " . $params->{'TASK'} . "<br>";}
+	
+	if ($component eq 'corpus') {
+		my $corpus_id = $params->{'corpus_id'};
+		$params->{'c' . $corpus_id . '_dbname' } = $params->{'dbname'};
+		$output = &corpusSettings($params, $corpus_id, 0);
+	} elsif ($component eq 'corpora') {
+		$output .= &corporaSettings($params);
+	} elsif ($component eq 'algorithm_options') {
+		$output = &algorithmOptions($params);
+	} elsif ($component eq 'task_options') {
+		$output = &taskOptions($params);
+	} elsif ($component eq 'task_select') {
+		$output = &taskSelect($params);
+	}
+	
+	$output = &setFormFields($params, $output);
+
+	return $output;
+}
+
+sub corporaSettings() {
+
+	my $debug = 99;
+
+	my $params = $_[0];
+	
+	my $output = '<table>';
+
+	if ($debug) {$output .= "coporaSettings: Task: " . $params->{'TASK'}. "<br>";}
+
+	if ( ($params->{"TASK"} eq 'binary_classification') || ($params->{"TASK"} eq 'statistics') ) {
+		for (my $corpus_id = 0; $corpus_id < 2; $corpus_id++) {
+			my $corpus_name = 'c' . ($corpus_id + 1);
+			$params->{'c' . ($corpus_id + 1) . '_name'} = $corpus_name;
+			$output .= '<td><div id="c' . ($corpus_id + 1). '_corpus">' . &corpusSettings($params, ($corpus_id +1), 0, 0) . '</div></td>';
+		}
+	} elsif ($params->{"TASK"} eq 'predict_on_unseen') {
+
+		$params->{'c1_name'} = 'c1';
+		$output .= '<td><div id="c1_corpus">Training Corpus<br>';
+		$output .= &corpusSettings($params, 1, 0) . '</div></td>';
+
+		$params->{'c2_name'} = 'c2';
+		$output .= '<td><div id="c2_corpus">Prediction Corpus<br>' . &corpusSettings($params, 2, 0) . '</div></td>';
+
+	} elsif ($params->{"TASK"} eq 'cluster' || $params->{"TASK"} eq 'writedata') {
+
+			$params->{'c1_name'} = 'c1';
+			$output .= '<td><div id="c1_corpus">Corpus<br>';
+			$output .= &corpusSettings($params, 1, 0) . '</div></td>';
+
+	} elsif ($params->{"TASK"} eq 'vectorspace_search' || $params->{"TASK"} eq 'vectorspace_knn') {
+
+		$params->{'c1_name'} = 'c1';
+		$output .= '<td><div id="c1_corpus">Search Space Corpus<br>';
+		$output .= &corpusSettings($params, 1, 0) . '</div></td>';
+
+		$params->{'c2_name'} = 'c2';
+		$output .= '<td><div id="c2_corpus">Query Corpus<br>' . &corpusSettings($params, 2, 0) . '</div></td>';
+
+	}
+	
+	$output .= '</tr></table>';
+	
+	return $output;
+}
+
+
+
+sub corpusSettings() {
+	
+	my $debug = 99;
+
+	my $params = $_[0];
+	my $corpus_id = $_[1];
+	my $allow_custom_names = $_[2];
+
+	my $dbname = $params->{'c' . $corpus_id . '_dbname'};
+
+	my $output = '';
+
+	$output .= "<table>";
+	
+	$output .= "<tr><th><label for=\"c" . $corpus_id . "_name\">Corpus Name:</label></td>";
+
+	my $corpus_name = '';
+	if ($params->{"c" . $corpus_id . "_name"} eq '') {
+		$corpus_name = "c" . $corpus_id;
+	} else {
+		$corpus_name = $params->{"c" . $corpus_id . "_name"};
+	}
+	
+	if ($allow_custom_names) {
+		$output .= "<td><input type=\"text\" name=\"c" . $corpus_id . "_name\" id=\"c" . $corpus_id . "_name\" value=\"" . $corpus_name . "\"></td>";
+	} else {
+		$output .= "<td><input type=\"hidden\" name=\"c" . $corpus_id . "_name\" id=\"c" . $corpus_id . "_name\" value=\"" . $corpus_name . "\">$corpus_name</td>";
+	}
+	$output .= "</tr>";
+	$output .= "<tr><th class=\"row\"><label for=\"c" . $corpus_id . "_dbname\">Database:</label></th>";
+	$output .= '<td>' . &dbnameSelect($params, $corpus_id) . '</td>';
+	
+	if ($dbname ne '' && $dbname ne 'undefined') {
+		$output .= &corpusFields($params, $corpus_id);
+	}
+
+	$output .= "</table>";	
+
+	return $output;
+}
+
+sub corpusFields() {
+
+	my $params = $_[0];
+	my $corpus_id = $_[1];
+
+	my $dbname = $params->{'c' . $corpus_id . '_dbname'};
+		
+	require "$PHILODATADIR/databases/$dbname/lib/philominesubs.pl";
+	
+	my $output= '';
+
+	$output .= '<tr><th colspan="2">Document</tr></tr>';
+
+	foreach my $field (keys(%minefields)) {
+		$output .= '<tr>';
+		$output .= '<td class="row"><label for="c' . $corpus_id . '_' . $field . '">' . $minefields{$field} . '</label></td>';
+		$output .= '<td><input name="c' . $corpus_id . '_' . $field . '" id="c' . $corpus_id . '_' . $field . '" value="' . $params->{'c' . $corpus_id . '_' . $field} . '"></td>';
+    	$output .= '<tr>';
+	}
+
+	if (keys(%subminefields) > 0) {
+		$output .= '<tr><th colspan="2">Div</tr></tr>';
+	}
+
+	foreach my $field (keys(%subminefields)) {
+		$output .= '<tr>';
+		$output .= '<td class="row"><label for="c' . $corpus_id . '_' . $field . '">' . $subminefields{$field} . '</label></td>';
+		$output .= '<td><input name="c' . $corpus_id . '_' . $field . '" id="c' . $corpus_id . '_' . $field . '" value="' . $params->{'c' . $corpus_id . '_' . $field} . '"></td>';
+    	$output .= '<tr>';
+	}
+
+	return $output;
+
+}
+
+sub algorithmOptions() {
+
+	$params = $_[0];
+
+	my $output = $algorithm_form_options{$params->{'MINEFUN'}};
+
+	return $output;
+}
+
+sub greyedOut() {
+	
+	my $blurb = $_[0];
+	
+	my $text = "<span class=\"greyed_out\">$blurb</span>";
+	
+	return $text;
+}
+
+sub taskSelect() {
+	
+	my $debug = 99;
+	
+	my $params = $_[0];
+	
+	my $output = '';
+	
+	&bugger($debug, "Minefun: " . $params->{'MINEFUN'});
+	&bugger($debug, "Scalar: " . scalar(@{$tasks{$params->{'MINEFUN'}}}) . "<br>");
+	
+	if ($params->{'MINEFUN'} eq '') {
+		$output .= &greyedOut('(Select an algorithm first)');
+	} else {
+	
+		if (scalar(@{$algorithm_tasks{$params->{'MINEFUN'}}}) == 1) {
+			$output .= $task_names{$algorithm_tasks{$params->{'MINEFUN'}}[0]} . '<input type="hidden" name="TASK" id="TASK" value="' . $algorithm_tasks{$params->{'MINEFUN'}}[0] . '">';
+		} else {
+			$output .= '<select name="TASK" id="TASK">' . "\n";
+	
+			foreach my $task (@{$algorithm_tasks{$params->{'MINEFUN'}}}) {
+			
+				my $selected_string = '';
+		
+				if ($params->{'TASK'} eq $task) {
+					$selected_string = " selected";
+				} else {
+					$selected_string = '';
+				}
+
+				$output .= "<option value=\"$task\"$selected_string>" . $task_names{$task} . "</option>\n";
+			
+			}
+			$output .= '</select>';
+		}
+	}
+	
+	return $output;
+}
+
+sub taskOptions() {
+	
+	my $debug = 0;
+
+	my $params = $_[0];
+
+	my $output = '';
+
+	$highlight = '<input type="checkbox" name="HIGHLIGHT_INCORRECT" id="HIGHLIGHT_INCORRECT"XXXHIGHLIGHT_INCORRECTXXX><label for="HIGHLIGHT_INCORRECT">Highlight incorrect instances</label>';
+
+	if ( ($params->{'TASK'} eq 'predict_on_unseen' || $params->{"TASK"} eq 'vectorspace_knn') && $params->{'dbname'} ne '' && $params->{'dbname'} ne 'undefined') {
+		$output .= 'Classify on: ' . &classifyOnSelect($params, $params->{'dbname'});
+		$output .= '<br>' . $highlight;
+	}
+	
+	if ($params->{"TASK"} eq 'binary_classification') {
+		$output .= $highlight;
+	}
+	if ($params->{"TASK"} eq 'vectorspace_knn') {
+		$output .= '<br>using
+					<input type="text" size="5" name="VECTORSPACEK" id="VECTORSPACEK" value="' . $params->{'VECTORSPACEK'} . '">
+					<label for="VECTORSPACEK">nearest neighbors</label><br>
+					<input type="checkbox" name="KNN_COUNTS" id="KNN_COUNTS"XXXKNN_COUNTSXXX>
+					<label for="KNN_COUNTS">Counts</label> 
+					<input type="checkbox" name="KNN_WEIGHTED_COUNTS" id="KNN_WEIGHTED_COUNTS"XXXKNN_WEIGHTED_COUNTSXXX>
+					<label for="KNN_WEIGHTED_COUNTS">Weighted Counts</label> 
+					<input type="checkbox" name="KNN_DP" id="KNN_DP"XXXKNN_DPXXX>
+					<label for="KNN_DP">DP</label> 
+					<input type="checkbox" name="KNN_DP_SQUARED" id="KNN_DP_SQUARED"XXXKNN_DP_SQUAREDXXX>
+					<label for="KNN_DP_SQUARED">DP Squared</label>
+					<input type="checkbox" name="KNN_DP_CUBED" id="KNN_DP_CUBED"XXXKNN_DP_CUBEDXXX>
+					<label for="KNN_DP_CUBED">DP Cubed</label>
+					';
+	}
+	
+	if ($params->{"TASK"} eq 'vectorspace_search') {
+		my $threshold_checked = '';
+		my $fixednumber_checked = '';
+		if ($params->{"VECTORSPACEDISPLAY"} eq 'threshold') {
+			$threshold_checked = ' checked';
+		}
+		if ($params->{"VECTORSPACEDISPLAY"} eq 'fixednumber') {
+			$fixednumber_checked = ' checked';
+		}
+
+		$output .= '<input name="VECTORSPACEDISPLAY" type="radio" value="threshold" id="VECTORSPACEDISPLAYthreshold"' . $threshold_checked . '>
+					<label for="VECTORSPACEDISPLAY">Show </label>
+					<input type="text" size="10" name="VECTORSPACETHRESHOLD" id="VECTORSPACETHRESHOLD" value="' . $params->{'VECTORSPACETHRESHOLD'} . '">
+					<label for="VECTORSPACETHRESHOLD">score or above</label><br>
+
+					<input name="VECTORSPACEDISPLAY" type="radio" value="fixednumber" id="VECTORSPACEDISPLAYfixednumber"' . $fixednumber_checked . '>
+					<label for="VECTORSPACEDISPLAY">Show </label>
+					<input type="text" size="10" name="VECTORSPACENUMDISP" id="VECTORSPACENUMDISP" value="' . $params->{'VECTORSPACENUMDISP'} . '">
+					<label for="VECTORSPACENUMDISP">similar instances</label>';
+	} 
+	
+	return $output;
+}
+
+
+sub classifyOnSelect() {
+	
+	my $debug = 2;
+	
+	my $params = $_[0];
+	my $dbname = $_[1];
+	
+	my $output = '<select name="CLASSIFYON" id="CLASSIFYON" <option value="">Select a field...</option>' . "\n";
+	
+	require "$PHILODATADIR/databases/$dbname/lib/philominesubs.pl";
+
+	my $selected_string = '';
+	foreach my $field ( keys(%minefields), keys(%subminefields) ) {		
+		if ($field eq $params->{'CLASSIFYON'}) {
+			$selected_string = " selected";
+		} else {
+			$selected_string = '';
+		}
+
+		$output .= '<option value="' . $field . '"' . $selected_string . '>' . $field . '</option>';
+	}
+
+	$output .= '</select>';
+
+	return $output;
+}
+
+
+sub dbnameSelect() {
+	
+	my $debug = 59;
+	
+	my $params = $_[0];
+	my $corpus_id = $_[1];
+	
+	my $dbname = $params->{'c' . $corpus_id . '_dbname'};
+	
+	&bugger($debug, "DBNAME: $dbname<br>");
+	
+	my $output = '<select name="c' . $corpus_id . '_dbname" id="c' . $corpus_id . '_dbname" class="dbnameselect"><option value="">Select...</option>' . "\n";
+	
+	# Go through the PhiloLogic install directory and print a select
+	# option for each database that has a philominesubs.pl in /lib
+
+	&bugger($debug, "PHILODATADIR: $PHILODATADIR<br>");
+
+	opendir(DIR, "$PHILODATADIR/databases");
+#	opendir(DIR, "/var/lib/philologic31/databases");
+	my @databases = grep(/^[^\.]/, readdir(DIR));
+	closedir(DIR);
+
+	foreach $db (@databases) {
+
+		my $selected_string = '';
+		
+		if (-e "$PHILODATADIR/databases/$db/lib/philominesubs.pl") {
+#		if (-f '/var/lib/philologic/Makefile') {
+			&bugger($debug, "databases: $PHILODATADIR/databases/$db/lib/philominesubs.pl<br>");
+			if ($db eq $dbname) {
+				$selected_string = " selected";
+			} else {
+				$selected_string = '';
+			}
+
+			$output .= "<option value=\"$db\"$selected_string>$db</option>\n";
+			
+		}
+
+	}
+	
+	$output .= '</select>';
+
+	# TODO make this unecessary -- Just for now, fake the dbanme
+	#$output .= "<input type=\"hidden\" name=\"dbname\" value=\"" . $dbname . "\">";
+
+	return $output;
+}
+
+sub selectFromQuery() {	
+	
+	$debug = 99;
+	
+	my $dbh = $_[0];
+	my $sql = $_[1];
+	my $name = $_[2];
+	
+	my $result = $dbh->prepare($sql);
+	$result->execute;
+	
+	while (@data = $result->fetchrow_array()) {
+    }	
+}
+
+sub algorithmSelect () {
+
+	my $params = $_[0];
+
+	my $function_select = '<select name="MINEFUN" id="MINEFUN">';
+	$function_select .= '<option value="">Choose an Algorithm...</option>';
+	$function_select .= '<option value="">Perl</option>';
+
+	while ((my $internal, my $human) = each %perl_functions) {
+		my $select = '';
+		if ($params->{'MINEFUN'} eq $internal) {
+			$select = " selected";
+		}
+		$function_select .= "<option value=\"$internal\"$select>&nbsp;&nbsp;&nbsp;$human</option>";
+	}
+
+	$function_select .= '<option value="">Weka</option>';
+	while ((my $internal, my $human) = each %weka_functions) {
+		my $select = '';
+		if ($params->{'MINEFUN'} eq $internal) {
+			$select = " selected";
+		}
+		$function_select .= "<option value=\"$internal\"$select>&nbsp;&nbsp;&nbsp;$human</option>";
+	}
+
+	$function_select .= '<option value="">Compiled</option>';
+	while ((my $internal, my $human) = each %compiled_functions) {
+		my $select = '';
+		if ($params->{'MINEFUN'} eq $internal) {
+			$select = " selected";
+		}
+		$function_select .= "<option value=\"$internal\"$select>&nbsp;&nbsp;&nbsp;$human</option>";
+	}
+
+	my $select = '';
+	if ($params->{'MINEFUN'} eq 'WRITEDATA') {
+		$select = " selected";
+	}
+
+	$function_select .= "<option value=\"WRITEDATA\"$select>Write Data</option>";
+
+	$function_select .= "</select>";
+
+	return $function_select;
+}
+
+
+sub setFormFields() {
+	
+	my $params = $_[0];
+	my $form = $_[1];
+	
+	# For the text fields, we need merely replace XXXFIELDNAMEXXX with the value in
+	# the hash.
+	foreach $field (@textfields) {
+		$target = 'XXX' . $field . 'XXX';
+
+		if (exists $params->{$field}) {
+			$replacement = $params->{$field};
+		} else {
+			$replacement = '';
+		}
+
+		$form =~ s/$target/$replacement/;
+	}
+
+	# For the checkboxes, if they exist in the params, set them checked. Else,
+	# remove the XXXFIELDXXX string.
+
+	foreach $field (@checkboxes) {
+		$target = 'XXX' . $field . 'XXX';
+
+		if (exists $params->{$field}) {
+			$replacement = " checked";
+		} else {
+			$replacement = '';
+		}
+
+		$form =~ s/$target/$replacement/;
+	}
+
+	# For the selects, we need to concatenated the field and value and replace that
+	# selected="selected"
+
+	foreach $field (@selects) {
+		$target = 'XXX' . $field . $params->{$field} . 'XXX';
+
+		$replacement = " selected";
+
+		$form =~ s/$target/$replacement/;
+	}
+
+	# For the radio buttons, replace field + value with checked
+
+	foreach $field (@radios) {
+		$target = 'XXX' . $field . $params->{$field} . 'XXX';
+
+		if (exists $params->{$field}) {
+			$replacement = " checked";
+		} else {
+			$replacement = '';
+		}
+
+		$form =~ s/$target/$replacement/;
+	}
+
+	# Now let's remove all the remaining XXXBLAHBLAHXXX, because those are 
+	# no longer needed... maybe there wouldn't even be any there at this point.
+
+	$form =~ s/XXX\S+XXX//g;
+	
+	return $form;
+	
+}
+
+
+
+1;
diff -Nuar philomine2/form_components/form.html philomine2patched/form_components/form.html
--- philomine2/form_components/form.html	1969-12-31 18:00:00.000000000 -0600
+++ philomine2patched/form_components/form.html	2018-07-28 16:46:40.904340641 -0500
@@ -0,0 +1,201 @@
+<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
+<html>
+
+<head>
+    <meta http-equiv="content-type" content="text/html; charset=utf-8">
+
+	<style media="all" type="text/css">@import "/philomine2/philomine.css";</style>
+	<script src="/philomine2/scripts/philomine.js"></script>
+
+
+    <title>Philomine: Classification and Statistical Functions</title>
+</head>
+
+<body>
+
+    <form action="XXXFORMACTIONXXX">
+
+    <center>
+        <strong>PhiloMine: Classification and Statistical Functions</strong><br><br>
+		<input value="Submit" type="submit"> <input id="resetbutton" value="Clear" type="reset">
+    </center>
+
+	<div class="optiongroup">
+        <h3>Run Settings</h3>
+        <label for="runname">Runname</label> <input name="runname" id="runname" value="XXXrunnameXXX"> <input type="checkbox" name="savedrun" id="savedrun" value="yes"XXXsavedrunXXX><label for="savedrun">Save run</label>
+		<input name="SHUFFLE" value="ON" id="SHUFFLE" type="checkbox"XXXSHUFFLEXXX> <label for="SHUFFLE">Random Falsification</label>
+
+	</div>
+	
+	<div class="optiongroup">	
+        <h3>Corpora Settings</h3>
+		<label for="dbname">Dbname</label> <input name="dbname" id="dbname" value="XXXdbnameXXX"><br>
+        <table>
+            <tr>
+                <td>
+                    <table>
+                        <tr>
+                            <th>&nbsp;</th>
+                            <th>Corpus One</th>
+                            <th>Corpus Two</th>
+                        </tr>
+                        <tr>
+                            <th class="row">Author</th>
+                            <td><input name="c1author" size="25" value="XXXc1authorXXX"></td>
+                            <td><input name="c2author" size="25" value="XXXc2authorXXX"></td>
+                        </tr>
+                        <tr>
+                            <th class="row">Date</th>
+                            <td><input name="c1date" size="25" value="XXXc1dateXXX"></td>
+                            <td><input name="c2date" size="25" value="XXXc2dateXXX"></td>
+                        </tr>
+                        <tr>
+                            <th class="row">Gender</th>
+                            <td><input name="c1gender" size="25" value="XXXc1genderXXX"></td>
+                            <td><input name="c2gender" size="25" value="XXXc2genderXXX"></td>
+                        </tr>
+                        <tr>
+                            <th class="row">Genre</th>
+                            <td><input name="c1genre" size="25" value="XXXc1genreXXX"></td>
+                            <td><input name="c2genre" size="25" value="XXXc2genreXXX"></td>
+                        </tr>
+                    </table>
+                </td>
+                
+                <td>
+                	<input name="MINEMODE" type="radio" value="NOSELECT" id="MINEMODENOSELECT"XXXMINEMODENOSELECTXXX>
+                	<label for="MINEMODENOSELECT">No select</label>
+                	<input id="MINEMODESELECT" name="MINEMODE" type="radio" value="SELECT"XXXMINEMODESELECTXXX>
+                	<label for="MINEMODESELECT">select from bibliography</label><br><br>
+					<label for="MINFEATURESTOTALPERINSTANCE">Minimum Word Count per document:</label> <input name="MINFEATURESTOTALPERINSTANCE" id="MINFEATURESTOTALPERINSTANCE" size="6" value="XXXMINFEATURESTOTALPERINSTANCEXXX"><br><br>
+					<label for="MAXFEATURESTOTALPERINSTANCE">Maximum Word Count per document:</label> <input name="MAXFEATURESTOTALPERINSTANCE" id="MAXFEATURESTOTALPERINSTANCE" size="6" value="XXXMAXFEATURESTOTALPERINSTANCEXXX"><br><br>
+    	            <input name="BALANCER" id="BALANCER" type="checkbox" value="ON"XXXBALANCERXXX> <label for="BALANCER">Balance instances</label> (random selection)<br>
+				</td>
+            </tr>
+        </table>
+	</div>
+
+	<div class="optiongroup">
+        <h3>Functions</h3>
+		<div id="functions_holder"></div>
+	</div>
+
+	<div class="optiongroup">
+
+        <h3>Feature Settings</h3>
+
+			Feature sets:
+			<input name="FEATURESETSURFACE" id="FEATURESETSURFACE" type="checkbox" value="ON"XXXFEATURESETSURFACEXXX>
+			<label for="FEATURESETSURFACE">Surface</label>
+
+			<input name="FEATURESETLEMMA" id="FEATURESETLEMMA" type="checkbox" value="ON"XXXFEATURESETLEMMAXXX>
+			<label for="FEATURESETLEMMA">Lemma</label>
+
+			<input name="FEATURESETBIGRAM" id="FEATURESETBIGRAM" type="checkbox" value="ON"XXXFEATURESETBIGRAMXXX>
+			<label for="FEATURESETBIGRAM">Bigram</label>
+
+			<input name="FEATURESETTRIGRAM" id="FEATURESETTRIGRAM" type="checkbox" value="ON"XXXFEATURESETTRIGRAMXXX>
+			<label for="FEATURESETTRIGRAM">Trigram</label>
+
+			<input name="FEATURESETBILEMMA" id="FEATURESETBILEMMA" type="checkbox" value="ON"XXXFEATURESETBILEMMAXXX>
+			<label for="FEATURESETBILEMMA">Bi-lemma</label>
+
+			<input name="FEATURESETTRILEMMA" id="FEATURESETTRILEMMA" type="checkbox" value="ON"XXXFEATURESETTRILEMMAXXX>
+			<label for="FEATURESETTRILEMMA">Tri-lemma</label>
+
+			<br>
+
+			<label for="TFIDF">TF-IDF</label>			
+			<input name="TFIDF" id="TFIDF" type="checkbox" value="ON"XXXTFIDFXXX>
+			
+			<br>
+
+
+            <label for="MNBFEATLIMIT">Feature Display Limit</label> <input name="FEATUREDISPLAYLIMIT" id="FEATUREDISPLAYLIMIT" size="5" value="XXXFEATUREDISPLAYLIMITXXX"><br><br>
+
+			Limit features to those occurring: <br>
+			&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
+
+  			<input name="INSTANCESPERFEATURELOWER" id="INSTANCESPERFEATURELOWER" type="checkbox" value="ON"XXXINSTANCESPERFEATURELOWERXXX>
+			<label for="INSTANCESPERFEATURELOWERVALUE">in at least</label>
+
+			<input type="text" name="INSTANCESPERFEATURELOWERVALUE" id="INSTANCESPERFEATURELOWERVALUE" value="XXXINSTANCESPERFEATURELOWERVALUEXXX">
+			
+			<select name="INSTANCESPERFEATURELOWERTYPE" id="INSTANCESPERFEATURELOWERTYPE">
+				<option value="percent"XXXINSTANCESPERFEATURELOWERTYPEpercentXXX>% of all instances</option>
+				<option value="count"XXXINSTANCESPERFEATURELOWERTYPEcountXXX>total instances</option>			
+			</select>
+
+			and
+		
+  			<input name="INSTANCESPERFEATUREUPPER" id="INSTANCESPERFEATUREUPPER" type="checkbox" value="ON"XXXINSTANCESPERFEATUREUPPERXXX>
+			<label for="INSTANCESPERFEATUREUPPERVALUE">in at most</label>
+
+			<input type="text" name="INSTANCESPERFEATUREUPPERVALUE" id="INSTANCESPERFEATUREUPPERVALUE" value="XXXINSTANCESPERFEATUREUPPERVALUEXXX">
+			
+			<select name="INSTANCESPERFEATUREUPPERTYPE" id="INSTANCESPERFEATUREUPPERTYPE">
+				<option value="percent"XXXINSTANCESPERFEATUREUPPERTYPEpercentXXX>% of all instances</option>
+				<option value="count"XXXINSTANCESPERFEATUREUPPERTYPEcountXXX>total instances</option>			
+			</select>
+			
+
+			<br>
+			&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	
+  			<input name="FEATURESPERINSTANCELOWER" id="FEATURESPERINSTANCELOWER" type="checkbox" value="ON"XXXFEATURESPERINSTANCELOWERXXX>
+			<label for="FEATURESPERINSTANCELOWERVALUE">at least</label>
+
+			<input type="text" name="FEATURESPERINSTANCELOWERVALUE" id="FEATURESPERINSTANCELOWERVALUE" value="XXXFEATURESPERINSTANCELOWERVALUEXXX">
+
+			<select name="FEATURESPERINSTANCELOWERTYPE" id="FEATURESPERINSTANCELOWERTYPE">
+				<option value="count"XXXFEATURESPERINSTANCELOWERTYPEcountXXX>times</option>
+				<option value="perthousand"XXXFEATURESPERINSTANCELOWERTYPEperthousandXXX>times per thousand</option> 
+			</select> in a given instance
+
+			and
+		
+  			<input name="FEATURESPERINSTANCEUPPER" id="FEATURESPERINSTANCEUPPER" type="checkbox" value="ON"XXXFEATURESPERINSTANCEUPPERXXX>
+			<label for="FEATURESPERINSTANCEUPPERVALUE">at most</label>
+
+			<input type="text" name="FEATURESPERINSTANCEUPPERVALUE" id="FEATURESPERINSTANCEUPPERVALUE" value="XXXFEATURESPERINSTANCEUPPERVALUEXXX">
+			
+			<select name="FEATURESPERINSTANCEUPPERTYPE" id="FEATURESPERINSTANCEUPPERTYPE">
+				<option value="count"XXXFEATURESPERINSTANCEUPPERTYPEcountXXX>times</option>
+				<option value="perthousand"XXXFEATURESPERINSTANCEUPPERTYPEperthousandXXX>times per thousand</option>
+			</select> in a given instance
+
+	<br><br>
+
+	<table width="95%">
+		<tr>
+
+			<td>
+				<label for="EXCLUDEFEATURES">Input Features to <strong>EXCLUDE</strong></label> from classification separated by spaces,
+				<br>using full regular expressions:<br>
+				Choose file: XXXEXCLUDEFEATURELISTFILESELECTORXXX or enter below
+	        	<textarea name="EXCLUDEFEATURES" id="EXCLUDEFEATURES" cols="50" rows="5">XXXEXCLUDEFEATURESXXX</textarea><br>
+				Eg: <tt>sand horace victor denis jules maxime richelieu</tt>
+			</td>
+			
+			<td>
+				<label for="INCLUDEFEATURES">Input Features to <strong>INCLUDE</strong></label> for classification separated by spaces,
+				<br>using full regular expressions:<br> 
+				Choose file: XXXINCLUDEFEATURELISTFILESELECTORXXX or enter below
+				<textarea name="INCLUDEFEATURES" id="INCLUDEFEATURES" cols="50" rows="5">XXXINCLUDEFEATURESXXX</textarea><br>
+				Note that you will need to select a fairly sizeable list for effective classifications.<br>
+			</td>
+		</tr>
+	</table>
+	
+	</div>
+
+
+
+    <center>
+    	<input value="Submit" type="submit"> <input id="resetbutton2" value="Clear" type="reset"><br><br>
+		<a href="http://philologic.uchicago.edu/powered"><img style="border: 0pt none ;" src="/philologic/philopowered.png" alt="Powered by PhiloLogic"></a>
+	</center>
+
+	</form>
+
+</body>
+</html>
diff -Nuar philomine2/form_components/function_data.pl philomine2patched/form_components/function_data.pl
--- philomine2/form_components/function_data.pl	1969-12-31 18:00:00.000000000 -0600
+++ philomine2patched/form_components/function_data.pl	2018-07-28 16:46:40.889340615 -0500
@@ -0,0 +1,214 @@
+# FORM DATA
+@textfields = ("runname",
+			"dbname", 
+			"c1_author", 
+			"c2_author", 
+			"c1_date", 
+			"c2_date", 
+			"c1_gender", 
+			"c2_gender", 
+			"c1_genre", 
+			"c2_genre", 
+			"c1_dgdivtype", 
+			"c2_dgdivtype", 
+			"MINFEATURESTOTALPERINSTANCE", 
+			"MAXFEATURESTOTALPERINSTANCE", 
+			"WEKAUSERMEMORY", 
+			"SVMC", 
+			"NUM_CLUSTERS", 
+			"FEATUREDISPLAYLIMIT", 
+			"FREQLOWER", 
+			"FREQUPPER", 
+			"EXCLUDEFEATURES", 
+			"INCLUDEFEATURES", 
+			"WEKAJ48C", 
+			"WEKAJ48M", 
+			"WEKASMO", 
+			"WORDDOCCOUNTLOWER", 
+			"WORDDOCCOUNTUPPER", 
+			"INSTANCESPERFEATUREUPPERVALUE", 
+			"INSTANCESPERFEATURELOWERVALUE", 
+			"FEATURESPERINSTANCEUPPERVALUE", 
+			"FEATURESPERINSTANCELOWERVALUE", 
+			"CVFOLDS", 
+			"VECTORSPACETHRESHOLD", 
+			"VECTORSPACENUMDISP", 
+			'VECTORSPACEK', 
+			'VECTORSPACEK');
+
+@checkboxes = ("SAVERUN", 
+			"SHUFFLE", 
+			"BALANCER",
+			"PERLGRAPHICTREE", 
+			"J48GRAPHICTREE", 
+			"INSTANCESPERFEATUREUPPER", 
+			"INSTANCESPERFEATURELOWER", 
+			"LOWERDODOCFREQLIM", 
+			"UPPERDODOCFREQLIM", 
+			"FEATURESPERINSTANCEUPPER", 
+			"FEATURESPERINSTANCELOWER", 
+			"FEATURESETSURFACE", 
+			"FEATURESETLEMMA", 
+			"FEATURESETBIGRAM", 
+			"FEATURESETBILEMMA", 
+			'VECTORSPACEKNN',
+			'OFFLINE',
+			'CSVOUTPUT',
+			'DISPLAYGRAPHICTREE',
+			'KNN_COUNTS',
+			'KNN_WEIGHTED_COUNTS',
+			'KNN_DP',
+			'KNN_DP_SQUARED',
+			'KNN_DP_CUBED',
+			'HIGHLIGHT_INCORRECT'
+			);
+			
+@selects = ("WORDDOCRATELOWER", 
+			"WORDDOCRATEUPPER", 
+			"FEATURESPERINSTANCEUPPERTYPE", 
+			"FEATURESPERINSTANCELOWERTYPE", 
+			"INSTANCESPERFEATURELOWERTYPE", 
+			"INSTANCESPERFEATUREUPPERTYPE", 
+			'VECTORSPACECLASS',
+			'L2');
+
+@radios = ("MINEFUN", 
+		"MINEMODE", 
+		"VECTORSPACEDISPLAY", 
+		"INSTANCELEVEL",
+		"VALUETYPE",
+		"NORMALIZATION");
+
+# DEFAULTS
+%defaults = ('CVFOLDS' => '10',
+ 			'runname' => 'test',
+ 			'FEATUREDISPLAYLIMIT' => '20',
+			'VECTORSPACETHRESHOLD' => '0.7', 
+			'VECTORSPACENUMDISP' => 5, 
+			'VECTORSPACEDISPLAY' => 'threshold', 
+			'VECTORSPACEK' => 5, 
+			'VECTORSPACECLASS' => 'gender', 
+			'VECTORSPACEKNN' => 'on', 
+			'INSTANCELEVEL' => 'document',
+			'VALUETYPE' => 'counts',
+			'NORMALIZATION' => 'none',
+			'FEATURESPERINSTANCEUPPERTYPE' => 'percent', 
+			'FEATURESPERINSTANCELOWERTYPE' => 'percent',
+			'INSTANCESPERFEATURELOWERVALUE' => 5,
+			'INSTANCESPERFEATUREUPPERVALUE' => 75
+			);
+
+sub setParamsDefaults() {
+
+	my $params = $_[0];
+	my $defaults = $_[1];
+
+	foreach my $field (keys(%$defaults)) {
+		if (! exists($params->{$field})) {
+			$params->{$field} = $defaults->{$field};
+		}	
+	}
+
+
+	# To avoid setting defaults when we have a linked form from a previous run,
+	# skip setting defaults for KNN score options if any are checked.
+	unless (exists($params->{'KNN_COUNTS'}) ||
+	 		exists($params->{'KNN_WEIGHTED_COUNTS'}) || 
+			exists($params->{'KNN_DP'}) ||
+			exists($params->{'KNN_DP_SQUARED'}) ||
+			exists($params->{'KNN_DP_CUBED'})) {
+				
+		$params{'KNN_COUNTS'} = 'on';
+		$params{'KNN_WEIGHTED_COUNTS'} = 'on';
+		$params{'KNN_DP'} = 'on';
+	}
+	
+	# Similar situation with the feature limits checkboxes -- make sure we
+	# don't have any MINEFUN set before we turn these on so that we don't
+	# erase some previously set values
+	
+	unless (exists($params->{'MINEFUN'})) {
+		$params{'INSTANCESPERFEATURELOWER'} = 'on';
+		$params{'INSTANCESPERFEATUREUPPER'} = 'on';
+	}
+	
+	if (! ( exists($params->{"FEATURESETSURFACE"}) || 
+			exists($params->{"FEATURESETLEMMA"}) || 
+			exists($params->{"FEATURESETSURFACE"}) || 
+			exists($params->{"FEATURESETBIGRAM"}) || 
+			exists($params->{"FEATURESETBILEMMA"}) ) ) {
+		$params->{"FEATURESETSURFACE"} = "ON";
+	}
+
+}
+
+# FUNCTIONS
+%functions = ('RELRATE' => 'Differential Relative Rates', 
+				'MULTIBAYES' => 'Multinominal Naive Bayesian', 
+				'DECISIONTREE' => 'Decision Tree', 
+				'VECTORSPACE' => 'Vector Space',
+				'WEKAIG' => 'Weka Information Gain', 
+				'WEKABAYES' => 'Weka Naive Bayes', 
+				'WEKASMO' => 'Weka SMO SVM', 
+				'WEKAMLP' => 'Weka Multilayer Perceptron', 
+				'WEKAJ48' => 'Weka J48 Decision Tree',
+				'SVMLight' => 'SVMLight', 
+				'CLUTO' => 'CLUTO',
+				'WRITEDATA' => 'Write Data');
+
+%perl_functions = ('RELRATE' => 'Differential Relative Rates', 
+				'MULTIBAYES' => 'Multinominal Naive Bayesian', 
+				'DECISIONTREE' => 'Decision Tree', 
+				'VECTORSPACE' => 'Vector Space');
+
+%weka_functions = ('WEKAIG' => 'Information Gain', 
+				'WEKABAYES' => 'Naive Bayes', 
+				'WEKASMO' => 'SMO SVM', 
+				'WEKAMLP' => 'Multilayer Perceptron', 
+				'WEKAJ48' => 'J48 Decision Tree');
+
+%compiled_functions = ('SVMLight' => 'SVMLight', 
+				'CLUTO' => 'CLUTO');
+
+# TASKS
+%algorithm_tasks = ('RELRATE' => ['statistics'],
+			'MULTIBAYES' => ['binary_classification', 'predict_on_unseen'],
+			'DECISIONTREE' => ['binary_classification', 'predict_on_unseen'], 
+			'VECTORSPACE' => ['vectorspace_search', 'vectorspace_knn'],
+			'WEKAIG' => ['statistics'],
+			'WEKABAYES' => ['binary_classification', 'predict_on_unseen'],
+			'WEKASMO' => ['binary_classification', 'predict_on_unseen'],
+			'WEKAMLP' => ['binary_classification', 'predict_on_unseen'],
+			'WEKAJ48' => ['binary_classification'],
+			'SVMLight' => ['binary_classification'],
+			'CLUTO' => ['cluster'],
+			'WRITEDATA' => ['writedata']);
+
+%task_names = ('binary_classification' => 'Binary Classification',
+			'statistics' => 'Statistical Analysis',
+			'cluster' => 'Clustering',
+			'predict_on_unseen' => 'Train and Classify Unknowns',
+			'vectorspace_search' => 'Search',
+			'vectorspace_knn' => 'Classify via KNN',
+			'writedata' => 'Write Data');
+
+$graphic_tree_option = '<input type="checkbox" name="DISPLAYGRAPHICTREE" value="true" id="DISPLAYGRAPHICTREE"XXXDISPLAYGRAPHICTREEXXX><label for="DISPLAYGRAPHICTREE">Generate Graphic Tree</label>';
+$svmc_option = '<label for="SVMC">C: </label><input type="text" size="10" name="SVMC" id="SVMC" value="XXXSVMCXXX">';
+$num_clusters_option = '<label for="NUM_CLUSTERS"># Clusters</label> <input type="text" size="10" name="NUM_CLUSTERS" id="NUM_CLUSTERS" value="XXXNUM_CLUSTERSXXX">';
+$vector_space_options = '';
+
+%algorithm_form_options = ('RELRATE' => '',
+			'MULTIBAYES' => '',
+			'DECISIONTREE' => $graphic_tree_option,
+			'VECTORSPACE' => $vector_space_options,
+			'WEKAIG' => '',
+			'WEKABAYES' => '',
+			'WEKASMO' => '',
+			'WEKAMLP' => '',
+			'WEKAJ48' => $graphic_tree_option,
+			'SVMLight' => $svmc_option,
+			'CLUTO' => $num_clusters_option);
+
+
+
+1;
\ No newline at end of file
diff -Nuar philomine2/form_components/get_part.pl philomine2patched/form_components/get_part.pl
--- philomine2/form_components/get_part.pl	1969-12-31 18:00:00.000000000 -0600
+++ philomine2patched/form_components/get_part.pl	2018-07-30 16:14:43.124276924 -0500
@@ -0,0 +1,27 @@
+#!/usr/bin/perl
+
+require "../config.pl";
+require "../utility_functions.pl";
+require "form_functions.pl";
+require "function_data.pl";
+
+use CGI qw/:standard/;;
+%params = ();
+&prepareParams(\%params);
+&setParamsDefaults(\%params, \%defaults);
+
+my $debug = 59;
+
+print header;
+
+
+if ($debug eq $debug_true_value) {
+	while( my ($k, $v) = each %params ) {
+        print "Param: $k, value: $v\n<br>";
+    }
+}
+
+my $form_component = &getFormComponent(\%params, $params{'component'});
+
+print $form_component;
+
diff -Nuar philomine2/new_philologic_parts/Greek-xml-sgmlloader31.pl philomine2patched/new_philologic_parts/Greek-xml-sgmlloader31.pl
--- philomine2/new_philologic_parts/Greek-xml-sgmlloader31.pl	1969-12-31 18:00:00.000000000 -0600
+++ philomine2patched/new_philologic_parts/Greek-xml-sgmlloader31.pl	2018-07-27 13:57:35.444166032 -0500
@@ -0,0 +1,2388 @@
+#!/usr/bin/perl
+use DBI;
+# $Id: xml-sgmlloader.plin,v 2.1 2004/08/23 21:45:03 o Exp $
+# -----------------------------------------------------------------------
+# philologic31 2.8 -- TEI XML/SGML Full-text database engine
+# Copyright (C) 2004 University of Chicago
+# 
+# This program is free software; you can redistribute it and/or modify
+# it under the terms of the Affero General Public License as published by
+# Affero, Inc.; either version 1 of the License, or (at your option)
+# any later version.
+# 
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# Affero General Public License for more details.
+# 
+# You should have received a copy of the Affero General Public License
+# along with this program; if not, write to Affero, Inc.,
+# 510 Third Street, Suite 225, San Francisco, CA 94107 USA.
+
+# TEI XML and SGML loader.  It appears work properly on selected XML 
+# and SGML files.  Reads a list of generated object numbers, file names 
+# and sizes  Outputs raw index and additional data files.  I need to
+# describe this.  Some assembly required.  See Notes to Self at the
+# end of this script for things to do/change.
+# Last Modified: MVO March 28 2005.
+#
+# ======================= Table of Subroutines ======================
+# taghandler:         Main Tag processing function.
+# getdivhead:         Looks for <head...> under divs.
+# wordhandler:        Main Word processing function.
+# docharents:         Replace non-letter character entities.
+# havelowerdiv:       Check to see if there is an immediate subdiv.
+# makesqlsubdivrecord: prints a tabdelimited subdiv (paragraph block)
+# makesqlrecord:      Dump tab delimited object table (not done).
+# extractopenclosedata: Gets div table data in opener and closer
+# fixopenclose:       Runs standard conversions for opener/closer info
+# readdivopenclose:   A very simple parser get get opener/closer info
+# charents2utf8:      Convert Character Entities to UTF8.
+# moreentsinword:     Convert more character entities for indexing.
+# areyoupropname:     Check for upper case.  Should tag proper names.
+# lowercaseify:       Convert index word to lower case
+# up2low:             Convert Unicode to lower case.
+# inwordtagdel:       Replace in words tags with spanning character "_"
+# tagempt:               -- a helper for inwordtagdel
+# TagWordDel:         Replace tags and word patterns with " "
+# JoinHyphenWords:    Replace hyphen pattens with spanning character "_"
+# makerefidtable:     Generate cross reference table for document
+# AbbrevExpand:       Replace <abbr tags with letters and spanning char "_"
+# addtowordcount      Build the associative array for the word count
+# dumpthisdoccount:   Dumps document word count hash to a file.
+# DeleteUnicodeWordBreakers  replaces UTF byte sequences with space.
+# textloadpresets:    If I can't find textload.cfg, use these.
+# getthisxpath:       Get current XPATH ... experimental
+# ====================================================================
+# ================= Get ARGS for loader configurations ===============
+# ====================================================================
+# See if I can get the textloader.cfg file in the main PhiloLogic
+# directory.  If not, I'll use the defaults installed in this 
+# script.  
+${prefix} = "" unless ${prefix};
+$file = "${prefix}/etc/philologic31/philologic31.cfg";  
+# read in config files
+unless ($return = do $file) {
+	print STDERR "Could not find: philologic31.cfg\n";
+}
+
+$textloadcfg = $PHILOBUILDDIR . "/textload.cfg";
+if (-e $textloadcfg) {
+	print STDERR "Using configuration in $textloadcfg\n";
+	do $textloadcfg;
+	if (!$ReadTextLoadCfg) {
+		print STDERR "ERROR: May not have read all of $textloadcfg
+                              ... using presets.\n";
+		&textloadpresets();
+		}
+	}
+else {
+	print STDERR "Count not find $textloadcfg ... using presets.\n";
+	&textloadpresets();
+	}
+
+print STDERR "Characters in Words = ";
+print STDERR $CHARSINWORD;
+print STDERR "\n";
+print STDERR "Characters Excluded from Words (Char not indexed)= ";
+print STDERR $CHARSNOTTOINDEX ;
+print STDERR "\n";
+
+# This can be no more than 235 bytes.  I'm setting it smaller here
+# just to be safe.  This should also be set in textload.cfg and the
+# presets below.  Just bein' paranoid.
+if (!$LONGWORDLIMIT) {
+	$LONGWORDLIMIT = 128;
+	}
+
+# ================ End ARGS from loader configuration  ==============
+
+# ================= General Arguments and Preliminaries =============
+# These file names are required by other components of the Philo
+# loader or system.  Do not change them.
+$NEWPAGEMARKFILE = "newpagemarks.raw";
+$SQLDIVFILE = "divindex.raw";
+$SQLSUBDIVFILE = "subdivindex.raw";
+$COUNTBYDOC = "countbydocid";
+$REFIDTABLEFN = "ref2idtable";
+if ($genworddocfreq) {
+	$WORDDOCFREQDIR = "wordfreqdoc";
+	if (-d $WORDDOCFREQDIR) {
+		print STDERR "Found $WORDDOCFREQDIR \n";
+	}
+	else {
+		mkdir $WORDDOCFREQDIR;
+		print STDERR "Made Dir: $WORDDOCFREQDIR \n";
+	}
+}
+
+		
+
+$LENSHIM = 0; # Don't ask.
+
+# Read in a file from argv having the DOCID and then the
+# filename.  This is generated.  You can run a debugging routine
+# to output words, tags and the raw index
+
+$temp = $ARGV[0];
+if ($temp =~ /-debug/i) {
+    $debug = 1;
+    $textfile = $ARGV[1];
+}
+else {
+    $textfile = $ARGV[0];
+}
+$dbfile = "/var/www/artflsrv02/cgi-bin/perseus/GreekLexicon16.db";
+
+
+# Open a couple of additional files.
+# Page marks always....
+open (PAGEMARKFILE, ">> $NEWPAGEMARKFILE");
+
+# We want total counts by document this is simply 
+# docid \t count of total words in the document.
+
+open (DOCWORDTOTAL, ">> $COUNTBYDOC");
+
+# Div index only when set.
+if ($printsqldivtable) {
+	open (DIVINDEXFILE, ">> $SQLDIVFILE");
+	}
+
+# SubDiv index only when set.
+if ($printsqlsubdivtable) {
+	open (SUBDIVINDEXFILE, ">> $SQLSUBDIVFILE");
+	}
+
+
+# Open the ref2idtable file handle  
+if ($BUILDREFIDTABLE) {
+        open (REFIDTABLE, ">> $REFIDTABLEFN");
+        }
+
+# ======================================================================
+# ==================== The Main Loop ===================================
+# ======================================================================
+
+# Read in the list of files.  I should check for this.
+
+chomp($textfile);
+open FILEINTXT, "$textfile" or die "Couldn't fine $textfile\n";
+$morphdb = DBI->connect("DBI:SQLite:dbname=$dbfile", '', '', {PrintError, 1}) or die "Couldn't connect to DB:$dbfile\n";
+if ($morphdb->err() ) {
+    die "$DBI::errstr\n"; 
+}
+print STDERR $morphdb->tables;
+#$morphdb->do("set names utf8;");
+#$morphdb->do("set character set utf8;");
+#$morphdb->do("set character_set_connection=utf8;");
+while ($pfline = <FILEINTXT>) {
+   @plainline = split (/ /, $pfline);
+   $docid = $plainline[0];
+   $filename = $plainline[1];
+   $filename =~ s/\n//;
+
+# Initializing for each document.
+   $thewholething = "";
+   $inthetext = 0;
+
+# Let the user know you are loading this offender
+   print STDERR "Loading $docid ===> $filename... \n";
+
+# Put the whole XML document as a string ... this works reasonably
+# quickly even for 20MB documents.  Again, I should check for the
+# file and possibly also check to see if it has a few vital things,
+# like a couple of valid tags, otherwise the loader fails.
+
+   $gotadiv = 0;
+   $gotafront = 0;
+   $gotopenclose = 0;
+   $gotaparagraph = 0;
+   open (THEXMLFILE, $filename) or die "Couldn't open $filename\n"; 
+   while (<THEXMLFILE>) {
+	if (/<div/i) {
+		$gotadiv += 1;
+		$gotaparagraph = 0;
+		}
+
+        if (/<p>/i || /<p /i) {
+                $gotaparagraph += 1;
+                }
+
+	if (!$gotopenclose) {                 # Check for opener/closer
+		if (/<opener/i) {             # Why parse for it later if you
+			$gotopenclose = 1;    # don't have any in the doc?
+			}
+		if (/<closer/i) {
+			$gotopenclose = 1;
+			}
+		}
+
+	if (/<front/i) {
+		$gotafront += 1;
+		}
+	if (/<\/front/) {
+	   	$gotadiv = 0;
+		}
+	$thewholething .= $_;
+	}
+   close (THEXMLFILE);
+
+# First pass, print page objects and byte offsets.  Print out an
+# initial page object if you don't have any.  I should probably
+# put this in the page tag handler, but I still need to check
+# for an initial page tag, so leave it for now.  
+
+   $gotpage = 0;
+   while ($thewholething =~ m/(<pb)/gi) {
+	$gotpage = 1;
+	$thepagetag = $1;
+	$startbyte = pos($thewholething) - length($thepagetag); 
+	print "page $docid $startbyte\n";
+	}
+   if (!$gotpage) {
+        print "page $docid 0\n";
+        }
+   $currentpagetag = "na";
+
+# Print the initial structure which covers the information at the
+# beginning of the file, which we are not indexing, until we get to
+# a <front, <body, or <div (and <HyperDiv).
+
+   print "p1 $docid 0 0\n";
+   print "t1 $docid 0 -1 0\n";
+   print "p2 $docid 0 -1 0\n";
+   print "t2 $docid 0 -1 -1 0\n";
+   print "p3 $docid 0 -1 -1 0\n";
+   print "t3 $docid 0 -1 -1 -1 0\n";
+
+   $DIV1 = 0;
+   $DIV2 = -1;
+   $DIV3 = -1;
+   $docpgobject = 0;
+   $contextdivlevel = 0;
+
+# In case we have notes or other objects that did not close
+# in the previous document, initialize these.
+   $NODEEPEROBJECTS = 0;
+   $INANOTE = 0;
+
+#  Replace  DOS <CR> characters with spaces since they can 
+#  give us all kinds of difficulties.
+   $thewholething =~ s/\015/ /g;
+
+# Now, we're going to split the tags out with newlines and put it all in 
+# a list.  This splits words on tags and will do so for words with 
+# inline tags, such as italics or superscripts.  So, before we do this,
+# let's check to see if we would run a couple of general fixes to
+# the the $wholething.
+
+# Join Hyphenated words.  It performs the required changes to 
+# $thewholething.
+
+if ($joinshywords) {
+	    &JoinHyphenWords;
+	}
+
+# Replace newlines with spaces.  Remember that we have seen lots of
+# tags with newlines, which can make a mess of things.
+
+   $thewholething =~ s/\n/ /g;
+
+# If set, run the Abbreviation Expander here, since these are tags
+# and words.  
+   if ($abbrevexpand) {
+       $thewholething =~ s/(<abbr[^>]*>\&[^;]*;<\/abbr>)/&AbbrevExpand($1)/gie;
+       }
+
+# Call the inword tag delete function if the switch is on.  This reads
+# the global $thewholething
+   if ($tagexception) {
+            &inwordtagdel();
+       }
+
+# Call the tag and word delete function if the switch is on.  This reads
+# the global $thewholething
+   if ($ignoretagswords) {
+            &TagWordDel();
+       }
+     
+# Add newlines to the beginning and end of all tags 
+   $thewholething =~ s/</\n</g;
+   $thewholething =~ s/>/>\n/g;
+# Split it into a list on newlines.
+   @INSTREAM = split(/\n/, $thewholething);  
+   $thewholething = ""; 
+
+#                  And finally, generate the index.
+# Read the list by lines ... distinguishing between tags and words
+# and keeping track of bytes read in, so you do to a taghandler
+# or a word handler.
+
+   $bytesreadin = 0;
+   $inlinecount = 0;
+   $totalwordsindoc = 0;
+   %wordtaginfo = ();
+   foreach $inline (@INSTREAM) {
+#
+#  Let's start indexing words and objects at either the <text
+#  of the <docbody tag.  We can add more.
+
+		if ($inline =~ /<text>/i || $inline =~ /<text /i) {
+			$inthetext = 1;
+		}
+		if ($inline =~ /<docbody/i) {
+			$inthetext = 1;
+		}
+# This is debugging code: print what's going in after preprocessing.
+		if ($debug) {
+			print "$inline\n";
+		}
+# End of debugging code
+
+		$inlinecount += 1;
+		if ($inline =~ /^</) {
+			$bytesreadin = $bytesreadin + length($inline);
+			if ($DUMPXPATHS) {
+				&getthisxpath($inline);
+			}
+			&taghandler($inline)
+		}
+		else {
+			&wordhandler($inline);
+			$bytesreadin = $bytesreadin + length($inline);
+		}
+	} 
+
+#   Print out the total word count per document here
+	print DOCWORDTOTAL "$docid\t$totalwordsindoc\n";  
+#   Print out word count for this document
+	if ($genworddocfreq) {
+		&dumpthisdoccount();
+	}
+}
+
+# ======================== END OF THE MAIN LOOP =========================
+
+# =======================================================================
+# ============================== SUBROUTINES ============================
+# =======================================================================
+
+# =======================================================================
+# Subroutine: taghandler
+# This is used to track the objects
+# and output structural and navigation raw index data such as:
+# p1 1 3 9309
+# t1 PHASE FIRST 1 3 -1 9309
+# parag 1 3 1 0 0 9420
+# sent 1 3 1 0 0 0 9420
+# parag and sent do not always have to be these, but can also
+# be linegroups and lines, etc.  These are objects below divs.
+# I should also check for explicit sentence tags <sent> but
+# we have never actually seen a database that has these.  We
+# HAVE build some ourselves.  Do we need more object levels?  Yes.
+# Philo 3....  Also, we will probably want an type in word.
+#
+# See the notes below regarding tags so far
+# =================================================================
+
+sub taghandler() { 
+local ($thetag);
+$thetag = $_[0];
+
+if ($inthetext) {
+
+# Are we in a text tag in a quote <q> so we can tell if were
+# should disregard <div tags inside.  This is a setable argument
+# on top.
+
+        if ($thetag =~ /<text/i && $intextquote) {
+                $inquotetexttag = 1;
+                }
+        if ($thetag =~ /<\/text/i ) {
+                $inquotetexttag = 0;
+                }
+# are we in a quote?
+        if ($thetag =~ /<q[ >]/i ) {
+                $intextquote = 1;
+                }
+        if ($thetag =~ /<\/q>/i ) {
+                $intextquote = 0;
+                }
+
+# PARAGRAPHS: needs to check for paragraphs with attributes
+#             should also check if in a linegroup and do nothing if so.
+
+	if ($thetag =~ /<p>/i || $thetag =~ /<p /i) {
+            $dothispara = 1;
+	    if ($INANOTE) {
+		$dothispara = 0;
+		}
+	    if ($NODEEPEROBJECTS) {
+		$dothispara = 0;
+		}
+	    if ($dothispara) {
+		  $paracount += 1;
+		  $PARA += 1;
+		  $SENT = 0;
+		  $WORD = -1;
+		  $parabyte = $bytesreadin - (length($thetag) + $LENSHIM);
+		  print "parag $docid $DIV1 $DIV2 $DIV3 $PARA $parabyte\n";
+		  print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $parabyte\n";
+		}
+	    }
+
+# NOTES -- treat as para objects and set flag to not set paras in notes.
+# Currently treating them as distinct paragraphs.  Let's do this only
+# when the Note has a ID= statement, since these will be linked from
+# other statements, etc.  
+	if ($thetag =~ /<note /i) {
+	   if ($thetag =~ / id=/i) {
+             $paracount += 1;
+             $PARA += 1;
+             $SENT = 0;
+             $WORD = -1;
+             $parabyte = $bytesreadin - (length($thetag) + $LENSHIM);
+             print "parag $docid $DIV1 $DIV2 $DIV3 $PARA $parabyte\n";
+             print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $parabyte\n";
+	     $INANOTE = 1;
+                if ($printsqlsubdivtable) {
+                        &makesqlsubdivrecord($thetag);
+                        }
+
+	   }
+        }
+
+	if ($thetag =~ /<\/note/i && $INANOTE > 0) {
+                $paracount += 1;
+                $PARA += 1;
+                $SENT = 0;
+                $WORD = -1;
+                $parabyte = $bytesreadin - (length($thetag) + $LENSHIM);
+                print "parag $docid $DIV1 $DIV2 $DIV3 $PARA $parabyte\n";
+                print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $parabyte\n";
+		$INANOTE = 0;
+		}
+
+# EPIGRAPH: treat as para objects
+        if ($thetag =~ /<epigraph/i) {
+                $paracount += 1;
+                $PARA += 1;
+                $SENT = 0;
+                $WORD = -1;
+                $parabyte = $bytesreadin - (length($thetag) + $LENSHIM);
+                print "parag $docid $DIV1 $DIV2 $DIV3 $PARA $parabyte\n";
+                print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $parabyte\n";
+                if ($printsqlsubdivtable) {
+                        &makesqlsubdivrecord($thetag);
+                        }
+		$NODEEPEROBJECTS = 1;
+                }
+	
+# END EPIGRAPH: these always often trailing objects ....
+        if ($thetag =~ /<\/epigraph/i) {
+                $paracount += 1;
+                $PARA += 1;
+                $SENT = 0;
+                $WORD = -1;
+                $parabyte = $bytesreadin - (length($thetag) + $LENSHIM);
+                print "parag $docid $DIV1 $DIV2 $DIV3 $PARA $parabyte\n";
+                print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $parabyte\n";
+#               if ($printsqlsubdivtable) {
+#                        &makesqlsubdivrecord($thetag);
+#                        }
+                $NODEEPEROBJECTS = 0;
+                }
+
+
+# LIST: treat as para objects
+        if ($thetag =~ /<list/i  && $NODEEPEROBJECTS < 1) {
+                $paracount += 1;
+                $PARA += 1;
+                $SENT = 0;
+                $WORD = -1;
+                $parabyte = $bytesreadin - (length($thetag) + $LENSHIM);
+                print "parag $docid $DIV1 $DIV2 $DIV3 $PARA $parabyte\n";
+                print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $parabyte\n";
+                if ($printsqlsubdivtable) {
+                        &makesqlsubdivrecord($thetag);
+                        }
+                }
+
+# ========================= SPEECH BREAKS ==============================
+# SPEECH BREAKS: treat them as para objects 
+        if ($thetag =~ /<sp /i || $thetag =~ /<sp>/i) {
+                $paracount += 1;
+                $PARA += 1;
+                $SENT = 0;
+                $WORD = -1;
+                $parabyte = $bytesreadin - (length($thetag) + $LENSHIM);
+                print "parag $docid $DIV1 $DIV2 $DIV3 $PARA $parabyte\n";
+                print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $parabyte\n";
+                if ($printsqlsubdivtable) {
+                        &makesqlsubdivrecord($thetag);
+                        }
+		$NODEEPEROBJECTS = 1;
+                }
+
+# END: SPEECH BREAKS: treat them as para objects
+        if ($thetag =~ /<\/sp /i || $thetag =~ /<\/sp>/i) {
+		$NODEEPEROBJECTS = 0;
+		}
+
+# ========================= ARGUMENT BREAKS ==============================
+# ARGUMENT BREAKS: treat them as para objects
+        if ($thetag =~ /<argument /i || $thetag =~ /<argument>/i) {
+                $paracount += 1;
+                $PARA += 1;
+                $SENT = 0;
+                $WORD = -1;
+                $parabyte = $bytesreadin - (length($thetag) + $LENSHIM);
+                print "parag $docid $DIV1 $DIV2 $DIV3 $PARA $parabyte\n";
+                print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $parabyte\n";
+                if ($printsqlsubdivtable) {
+                        &makesqlsubdivrecord($thetag);
+                        }
+                $NODEEPEROBJECTS = 1;
+                }
+
+# END: ARGUMENT BREAKS: treat them as para objects
+        if ($thetag =~ /<\/argument /i || $thetag =~ /<\/argument>/i) {
+                $NODEEPEROBJECTS = 0;
+                }
+
+# ========================= OPENER BREAKS ==============================
+# OPENER BREAKS: treat them as para objects
+        if ($thetag =~ /<opener /i || $thetag =~ /<opener>/i) {
+                $paracount += 1;
+                $PARA += 1;
+                $SENT = 0;
+                $WORD = -1;
+                $parabyte = $bytesreadin - (length($thetag) + $LENSHIM);
+                print "parag $docid $DIV1 $DIV2 $DIV3 $PARA $parabyte\n";
+                print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $parabyte\n";
+                if ($printsqlsubdivtable) {
+                        &makesqlsubdivrecord($thetag);
+                        }
+                $NODEEPEROBJECTS = 1;
+                }
+
+# END: OPENER BREAKS: treat them as para objects
+        if ($thetag =~ /<\/opener /i || $thetag =~ /<\/opener>/i) {
+                $NODEEPEROBJECTS = 0;
+                }
+
+# ========================= CLOSER BREAKS ==============================
+# CLOSER BREAKS: treat them as para objects
+        if ($thetag =~ /<closer /i || $thetag =~ /<closer>/i) {
+                $paracount += 1;
+                $PARA += 1;
+                $SENT = 0;
+                $WORD = -1;
+                $parabyte = $bytesreadin - (length($thetag) + $LENSHIM);
+                print "parag $docid $DIV1 $DIV2 $DIV3 $PARA $parabyte\n";
+                print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $parabyte\n";
+                if ($printsqlsubdivtable) {
+                        &makesqlsubdivrecord($thetag);
+                        }
+                $NODEEPEROBJECTS = 1;
+                }
+
+# END: CLOSER BREAKS: treat them as para objects
+        if ($thetag =~ /<\/closer /i || $thetag =~ /<\/closer>/i) {
+                $NODEEPEROBJECTS = 0;
+                }
+
+
+# =========================  STAGE DIRECTIONS ===========================
+# STAGE DIRECTIONS: treat them as para objects
+        if ($thetag =~ /<stage/i && $NODEEPEROBJECTS < 1) {
+                $paracount += 1;
+                $PARA += 1;
+                $SENT = 0;
+                $WORD = -1;
+                $parabyte = $bytesreadin - (length($thetag) + $LENSHIM);
+                print "parag $docid $DIV1 $DIV2 $DIV3 $PARA $parabyte\n";
+                print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $parabyte\n";
+                if ($printsqlsubdivtable) {
+                        &makesqlsubdivrecord($thetag);
+                        }
+                }
+
+# =========================  CAST LIST ===================================
+# CAST LIST: treat them as para objects
+        if ($thetag =~ /<castlist/i) {
+                $paracount += 1;
+                $PARA += 1;
+                $SENT = 0;
+                $WORD = -1;
+                $parabyte = $bytesreadin - (length($thetag) + $LENSHIM);
+                print "parag $docid $DIV1 $DIV2 $DIV3 $PARA $parabyte\n";
+                print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $parabyte\n";
+                if ($printsqlsubdivtable) {
+                        &makesqlsubdivrecord($thetag);
+                        }
+                }
+
+# PAGE BREAKS: this updates the currentpagetag or sets it to "na"
+#              if not found.  Note I assume n="[sometag]".  
+#              Also note that I am adding the pagetag to the output
+#              in order to split them out to replace the late function
+#              for doc in `cat plain.files | awk '{print $2"/"$3}'`; \
+#              do extpgmarks $doc; done > pagemarks.tmp
+#              echo '?????' | cat - pagemarks.tmp | sort -u > pagemarks
+
+
+	if ($thetag =~ /<pb/i) {
+		$temppagetag = $thetag;
+                $temppagetag =~ s/n="([^"]*)"/$1/i;
+		$currentpagetag = $1;
+		$currentpagetag =~ s/  */\_/g;
+		$currentpagetag =~ s/\-/\_/g;
+		$currentpagetag =~ tr/A-Z/a-z/;
+		if (!$currentpagetag) {
+			$currentpagetag = "na";
+			}
+		if ($debug) {
+			print "pgtag $currentpagetag\n";
+			}
+		print PAGEMARKFILE "$currentpagetag\n";
+		$docpgobject += 1;
+		}
+
+# LINE GROUP TAGS: treat linegroups same a paragraphs, set or unset the global
+#                  variable INLINEGROUP.
+
+	if ($thetag =~ /<lg/i  && $NODEEPEROBJECTS < 1) {
+                $paracount += 1;
+                $PARA += 1;
+                $SENT = 0;
+                $WORD = -1;
+		if ($lngrpbreaksent) {
+			$INLINEGROUP = 1;
+		}
+                $parabyte = $bytesreadin - (length($thetag) + $LENSHIM);
+                print "parag $docid $DIV1 $DIV2 $DIV3 $PARA $parabyte\n";
+                print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $parabyte\n";
+		if ($printsqlsubdivtable) {
+			&makesqlsubdivrecord($thetag);
+			}
+                }
+
+        if ($thetag =~ /<\/lg/i) {
+		$INLINEGROUP = 0;
+		}
+
+# END LINE TAG: use this to break "sentences" if INLINEGROUP.  This is
+#               if to set searching in line groups to lines rather than
+#               sentences.  
+
+	if ($thetag =~ /<\/l>/i) {
+	  if ($INLINEGROUP && $lngrpbreaksent) {
+            if ($WORD > 2 ) {
+              $SENT += 1;
+              $WORD = -1;
+              $sentbyte = $bytesreadin - (length($thetag) + $LENSHIM);
+              print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $sentbyte\n";
+              }
+	    }
+	  }
+			
+
+# SENTENCE TAG: <s> </s>.  We have never seen a sample of these
+# but let's add the required code to note the beginning of a new
+# sentence and to turn off automatic sentence tagging
+        if ($thetag =~ /<s>/i) {
+	    $SENT += 1;
+	    $WORD = -1;
+            $sentbyte = $bytesreadin - (length($thetag) + $LENSHIM);
+            print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $sentbyte\n";
+	    $INTAGGEDSENT = 1;
+	    }
+        if ($thetag =~ /<\/s>/i) {
+	    $INTAGGEDSENT = 0;
+	    }
+
+# DOCBODY: this is for MEP.  We will change them here to a <div1 for
+#          the time being.  Note that I am replacing with the correct
+#          number of bytes to keep the offsets right -- kludge.
+	if ($thetag =~ /<docbody/i) {
+	   $thetag =~ s/<docbody/<div1   /i;
+	   }
+
+# FRONT: Treat <front as a <div and set <divs in front as being
+#        one div level deeper.  
+
+         if ($thetag =~ /<front[> ]/i) {
+	      $XX = "-1";     # Don't ask  :-)   Probably don't need it.
+              $DIV1 += 1;
+              $DIV2 = -1;
+              $DIV3 = -1;
+              $PARA = -1;
+              $SENT = -1;
+              $WORD = -1;
+              $DIVLOC = $DIV1 . ":" . $DIV2 . ":" . $DIV3;
+              $divbyte = $bytesreadin - (length($thetag) + $LENSHIM);
+              print "p1 $docid $DIV1 $divbyte\n";
+              print "t1 Front Matter $docid $DIV1 $XX $divbyte\n";
+              if ($printsqldivtable) {
+		   $DIVHEAD = "Front Matter";
+                   $currentdivphiloid = $docid . ":" . $DIV1;
+                   &makesqlrecord($currentdivphiloid, $thetag);
+                   }
+              $testlowerdiv =  &havelowerdiv();
+              if (!$testlowerdiv) {
+                  print "p2 $docid $DIV1 $XX $divbyte\n";
+                  print "t2 $docid $DIV1 $XX $XX $divbyte\n";
+                  print "p3 $docid $DIV1 $XX $XX $divbyte\n";
+                  print "t3 $docid $DIV1 $XX $XX $XX $divbyte\n";
+                  $DIV2 = 0;
+                  }
+	      $INFRONTMATTER = 1; 
+	      $contextdivlevel = 1;
+         }
+
+         if ($thetag =~ /<\/front/i) {
+	      $INFRONTMATTER = 0; 
+	      $contextdivlevel = 0;
+	 }
+
+# BODY TAG: Let's set it as a <div object if we have no divs in the
+#           document.  These tend to carry on as FRONTMATTER.  Don't 
+#           have to check for lower divs, etc.
+
+	if ($thetag =~ /<body/i && !$gotadiv) {
+              $XX = "-1";     # Don't ask  :-)   Probably don't need it.
+              $DIV1 += 1;
+              $DIV2 = -1;
+              $DIV3 = -1;
+              $PARA = -1;
+              $SENT = -1;
+              $WORD = -1;
+              $DIVLOC = $DIV1 . ":" . $DIV2 . ":" . $DIV3;
+              $divbyte = $bytesreadin - (length($thetag) + $LENSHIM);
+              print "p1 $docid $DIV1 $divbyte\n";
+              $DIVHEAD = &getdivhead;
+	      if ($DIVHEAD =~ /\[NA\]/i) {
+			$DIVHEAD = "Document Body";
+			}
+              print "t1 $DIVHEAD $docid $DIV1 $XX $divbyte\n";
+              if ($printsqldivtable) {
+                   $currentdivphiloid = $docid . ":" . $DIV1;
+                   &makesqlrecord($currentdivphiloid, $thetag);
+                   }
+               print "p2 $docid $DIV1 $XX $divbyte\n";
+               print "t2 $docid $DIV1 $XX $XX $divbyte\n";
+               print "p3 $docid $DIV1 $XX $XX $divbyte\n";
+               print "t3 $docid $DIV1 $XX $XX $XX $divbyte\n";
+               $DIV2 = 0;
+              $contextdivlevel = 1;
+         }
+
+# HyperDiv: This is a Brown WWP construct.  It is defined as:
+#       a place to put a number of different kinds of information 
+#       which are related to the body of the text but do not appear 
+#       directly within its flow, for instance footnotes, acrostics, 
+#       and castlist information which is not printed in the text but 
+#       is required to provide IDREFs for the who attribute on <speaker>.
+# We are going to treat these a <div1, but not output a DIVHEAD, so 
+# these should not appear in TOCs.  For now, call it "[HyperDiv]"
+
+         if ($thetag =~ /<hyperdiv/i) {
+              $XX = "-1";     # Don't ask  :-)   Probably don't need it.
+              $DIV1 += 1;
+              $DIV2 = -1;
+              $DIV3 = -1;
+              $PARA = -1;
+              $SENT = -1;
+              $WORD = -1;
+              $DIVLOC = $DIV1 . ":" . $DIV2 . ":" . $DIV3;
+              $divbyte = $bytesreadin - (length($thetag) + $LENSHIM);
+              print "p1 $docid $DIV1 $divbyte\n";
+	      $DIVHEAD = "[HyperDiv]";
+              print "t1 $DIVHEAD $docid $DIV1 $XX $divbyte\n";
+	      $DIVHEAD = "[HyperDiv]";
+              if ($printsqldivtable) {
+                   $currentdivphiloid = $docid . ":" . $DIV1;
+                   &makesqlrecord($currentdivphiloid, $thetag);
+                   }
+               print "p2 $docid $DIV1 $XX $divbyte\n";
+               print "t2 $docid $DIV1 $XX $XX $divbyte\n";
+               print "p3 $docid $DIV1 $XX $XX $divbyte\n";
+               print "t3 $docid $DIV1 $XX $XX $XX $divbyte\n";
+               $DIV2 = 0;
+              $contextdivlevel = 1;
+         }
+
+
+# DIV TAGS: set division levels and print out div info.  A couple of
+#           assumptions:  I assume divs are numbered 1,2,3.  
+#           I output <head> info where I find it.  This could also
+#           be modified to output a structured table record with
+#           div type, and other attributes, along with the Philoid
+#           and head for searching under document levels.
+	if ($thetag =~ /<w([^>]+)>/i) {
+		%wordtaginfo = ();
+		while ($thetag =~ /([^ ]+?)="([^\"]+?)"/g) {
+			my $attr = $1;
+			my $value = $2;
+			if ($attr = "id") {
+		#		print STDERR "looking up word ID $value\n";
+				my $parsequery = $morphdb->prepare("select * from tokens, parses where tokens.tokenid = parses.tokenid and tokens.tokenid = \"$value\";");
+
+				my $bestparse;
+                                $parsequery->execute();
+                                while (my $parse = $parsequery->fetchrow_hashref() ) {
+					if ($parse->{"prob"} > $bestparse->{"prob"}) {
+						$bestparse = $parse;
+					}
+				}
+				if (my $lexid = $bestparse->{"lex"}) {
+					my $lex = $morphdb->selectrow_hashref("select * from Lexicon where lexid=$lexid;");
+					$wordtaginfo{"lemma"} = $lex->{"lemma"};
+					$wordtaginfo{"pos"} = $lex->{"code"};
+				}
+				else {
+					$wordtaginfo{"lemma"} = $bestparse->{"lemma"};
+					$wordtaginfo{"pos"} = $bestparse->{"code"};
+				}
+				
+			}
+			
+			else {$wordtaginfo{$attr} = $value;}
+		}
+		
+	}
+	if ($thetag =~ /<\/div/i) {
+		$contextdivlevel = $contextdivlevel - 1;
+		$NODEEPEROBJECTS = 0;
+		}
+		
+        if ($thetag =~ /<div/i) {
+
+		$contextdivlevel += 1;
+		if ($contextdivlevel > 3) {
+			$contextdivlevel = 3;
+			}
+
+		if ($contextdivlevel < 1) {
+			$contextdivlevel = 1;
+			}
+
+		$XX = "-1";     # Don't ask  :-)  Probably don't need it.
+                $newdiv = $thetag;
+                $newdiv =~ m/<div(.)/i;
+		$newdivlevel = $1;
+		if ($debug) {
+			print "DIVLEVEL = $newdivlevel \n";
+			}
+
+
+
+# If it is an unnumbered DIV, let's get the level from the
+# context.  Maybe I should just do this for everything.  
+	 	if ($newdivlevel eq ">") {
+			$newdivlevel = $contextdivlevel;
+			}
+	 	if ($newdivlevel eq " ") {
+			$newdivlevel = $contextdivlevel;
+			}
+	 	if ($newdivlevel eq "0") {
+			$newdivlevel = $contextdivlevel;
+			}
+
+# Ignore div0 if instructed.
+		if ($ignoredivzero && $newdivlevel eq "0") {
+			$newdivlevel = 99;
+			}
+
+# <FRONT will be the top level div, so let's use context divlevel
+		if ($INFRONTMATTER) {
+			$newdivlevel = $contextdivlevel;
+			}
+
+# This is to ignore divs inside of internal text tags.  Setable
+# from configuration.  But we will bump the para and sent args
+
+		if ($ignoredivsinsubtext && $inquotetexttag) {
+		   $newdivlevel = 99;
+                   $paracount += 1;
+                   $PARA += 1;
+                   $SENT = 0;
+                   $WORD = -1;
+                   $parabyte = $bytesreadin - (length($thetag) + $LENSHIM);
+                   print "parag $docid $DIV1 $DIV2 $DIV3 $PARA $parabyte\n";
+                  print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $parabyte\n";
+		}
+
+
+		if ($debug) {
+			print "DIVLEVEL1 = $newdivlevel \n";
+			}
+
+# And then process the divs at the appropriate level.  We're trying
+# to keep the numbered divs if possible.
+
+		if ($newdivlevel eq "1") {
+		  $DIV1 += 1;
+		  $DIV2 = -1;
+		  $DIV3 = -1;
+		  $PARA = -1;
+		  $SENT = -1;
+		  $WORD = -1;
+		  $DIVLOC = $DIV1 . ":" . $DIV2 . ":" . $DIV3;
+		  $divbyte = $bytesreadin - (length($thetag) + $LENSHIM);
+   		  print "p1 $docid $DIV1 $divbyte\n";
+		  $DIVHEAD = &getdivhead;
+   		  print "t1 $DIVHEAD $docid $DIV1 $XX $divbyte\n";
+		  if ($printsqldivtable) {
+			$currentdivphiloid = $docid . ":" . $DIV1;
+		        &makesqlrecord($currentdivphiloid, $thetag);
+			}
+		  $testlowerdiv =  &havelowerdiv();
+		  if (!$testlowerdiv) {
+                      print "p2 $docid $DIV1 $XX $divbyte\n";
+                      print "t2 $docid $DIV1 $XX $XX $divbyte\n";
+                      print "p3 $docid $DIV1 $XX $XX $divbyte\n";
+                      print "t3 $docid $DIV1 $XX $XX $XX $divbyte\n";
+		      $DIV2 = 0;   # MARCHHACK was 0
+		  }
+                }
+
+                if ($newdivlevel eq "2") {
+                  $DIV2 += 1;
+                  $DIV3 = -1;
+                  $PARA = -1;
+                  $SENT = -1;
+                  $WORD = -1;
+                  $DIVLOC = $DIV1 . ":" . $DIV2 . ":" . $DIV3;
+                  $divbyte = $bytesreadin - (length($thetag) + $LENSHIM);
+                  print "p2 $docid $DIV1 $DIV2 $divbyte\n";
+		  $DIVHEAD = &getdivhead;
+                  print "t2 $DIVHEAD $docid $DIV1 $DIV2 $XX $divbyte\n";
+                  if ($printsqldivtable) {
+                        $currentdivphiloid = $docid . ":" . $DIV1 . ":" . $DIV2;
+                        &makesqlrecord($currentdivphiloid, $thetag);
+                        }
+                  $testlowerdiv =  &havelowerdiv();
+                  if (!$testlowerdiv) {
+                      print "p3 $docid $DIV1 $DIV2 $XX $divbyte\n";
+                      print "t3 $docid $DIV1 $DIV2 $XX $XX $divbyte\n";
+		      $DIV3 = 0;  # MARCHHACK was 0
+		  }
+
+                }
+                if ($newdivlevel eq "3") {
+                  $DIV3 += 1;
+                  $PARA = -1;
+                  $SENT = -1;
+		  $WORD = -1;
+                  $DIVLOC = $DIV1 . ":" . $DIV2 . ":" . $DIV3;
+                  $divbyte = $bytesreadin - (length($thetag) + $LENSHIM);
+                  print "p3 $docid $DIV1 $DIV2 $DIV3 $divbyte\n";
+		  $DIVHEAD = &getdivhead;
+                  print "t3 $DIVHEAD $docid $DIV1 $DIV2 $DIV3 $XX $divbyte\n";
+		  if ($printsqldivtable) {
+                        $currentdivphiloid = $docid . ":" . $DIV1 . ":" . $DIV2;
+			$currentdivphiloid .= ":" . $DIV3;
+                        &makesqlrecord($currentdivphiloid, $thetag);
+                        }
+
+
+                }
+
+# This is for EEBO documents with NO subdiv objects ... so I add a
+# para and sent object for the first time I see a <div.  It is a hack
+                if (!$gotaparagraph) {
+                 $gotaparagraph = 1;
+                 $paracount += 1;
+                 $PARA += 1;
+                 $SENT = 0;
+                 $WORD = -1;
+                 $parabyte = $bytesreadin - (length($thetag) + $LENSHIM);
+                 print "parag $docid $DIV1 $DIV2 $DIV3 $PARA $parabyte\n";
+                 print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $parabyte\n";
+
+                 }
+	    }
+
+# Any object that has an id will get registered in the reference table.
+# See below.
+	   if ($BUILDREFIDTABLE) {
+		if ($thetag =~ / id=/i) {
+		&makerefidtable($thetag);
+		}
+	   }
+
+      }
+
+}
+
+# =================================================================
+# Subroutine: getdivhead looks for a <head> within 5 lines of
+# a div ... and returns it to be output as a t[1-3] for our
+# table of contents/document navigation.  This is one of the BAD things
+# about not using a REAL SGML/XML parser.  Note that we could
+# also output this, with structural data, to be loaded in an
+# SQL table 
+#
+# This does not work for cases where you have the header info
+# in the <div tag, such as id="Some Title" (c.f. Cyrus).  All
+# perfectly legal, of course.
+#
+# You can also have multiple <head>s.  I should probably look for
+# these as well.
+# =================================================================
+
+sub getdivhead() {
+local ($temphead, $DIVHEAD, $lookahead, $nextline, $readmore, $x, $i);
+local ($getheadcount);
+$getheadcount = $GetMultipleDivHeads;
+$lookahead = $inlinecount;
+$readmore = 0;
+$i = 0;
+$x = 0;
+while (!$readmore && $i < $HEADLOOKLINES) {
+	$lookahead += 1;
+	$nextline = $INSTREAM[$lookahead];
+	$i++;
+	$nextline =~ s/<head\/>//i;
+        if ($nextline =~ /<div/i || $nextline =~ /<\/div/i ) {  
+                $i = $HEADLOOKLINES + 1;     # Don't go past an open or
+                $readmore = 0;               # close <div.
+                }
+	if ($nextline =~ /<head/i) {
+    		$readmore = 1;
+		}
+        if ($readmore) {
+             while ($readmore) {
+                 $lookahead += 1;
+                 $x++;
+                 $nextline = $INSTREAM[$lookahead];
+                 if ($nextline =~ /<\/head>/i) {
+                      $readmore = 0;
+                      if ($getheadcount) {
+                           $i = 2;
+                           $getheadcount = $getheadcount - 1;
+		           }
+                      else {
+			   $i = $HEADLOOKLINES + 1;
+                           }
+                      } 
+                 elsif ($x > 10) {    # Overflow trap in case you miss </head
+                      $readmore = 0;
+                      $i = $HEADLOOKLINES + 1;
+                      } 
+                 else {
+                      $DIVHEAD .= $nextline . " ";
+                      }
+                 }
+            }
+      }
+
+
+if ($DIVHEAD) {
+	$DIVHEAD = &docharents($DIVHEAD);
+	$DIVHEAD = &charents2utf8($DIVHEAD);
+	$DIVHEAD = &moreentsinword($DIVHEAD);
+	$DIVHEAD =~ s/\n<[^>]*>\n//g;
+	$DIVHEAD =~ s/\n//g;
+	$DIVHEAD =~ s/_//g;
+	$DIVHEAD =~ s/\t/ /g;
+	$DIVHEAD =~ s/  */ /g;
+	$DIVHEAD =~ s/^  *//;
+	$DIVHEAD =~ s/  *$//;
+	}
+elsif ($thetag =~ /type=/i) {
+   	$temphead = $thetag;
+   	$temphead =~ s/type="([^"]*)"//i;
+   	$temphead1 = $1;
+   	if ($temphead =~ s/n="([0-9]+)"//i) {
+   		$temphead1 .= " $1";
+   	}
+	$temphead1 = &charents2utf8($temphead1);
+  	$DIVHEAD = "[" . $temphead1 . "]";
+	}
+else {
+	$DIVHEAD = "[NA]";
+	}
+
+if ($DIVHEAD eq "[>]" || $DIVHEAD eq "[<]") {
+	        $DIVHEAD = "[NA]";
+        }
+return $DIVHEAD;
+}
+
+
+# =================================================================
+# Subroutine: wordhandler.  This needs to be split up.  It
+# takes an artbitrary string or words between two tags and
+# splits them into words and prints the raw index entry for
+# each one such as:
+#
+# word superficial 1 2 0 0 5 0 7 8616 2
+# word comprehension 1 2 0 0 5 0 8 8628 2
+#
+# It also identifies sentence breaks.  I am not checking for
+# existing sentence tags, but could and conditionalize it.
+# Also note that it does not check for sentences inside of
+# linegroups ... which are typically broken on lines.
+#
+# I am not currently handling ";" at the end of words because
+# of confusion with character ents.  Easily fixed.
+# =================================================================
+
+sub wordhandler() {
+
+local ($bunchofwords, $wordlist, $currentpos, $incount, $thenextword);
+local ($nextincount, $isyousent);
+$bunchofwords = $_[0];
+
+# We don't like many character entities, so let's change them
+# into spaces to get a clean break.
+if ($bunchofwords =~ /\&[a-zA-Z0-9\#][a-zA-Z0-9]*;/) {
+	$bunchofwords = &docharents($bunchofwords);
+	}
+# Now, we also know that there are Unicode characters which 
+# we normally want to break words.  Often, these are Microsoft characters
+# like the curly quotes. These are set in textload.cfg
+# in @UnicodeWordBreakers. 
+if ($HaveUnicodeWordBreakers) {
+        $bunchofwords = &DeleteUnicodeWordBreakers($bunchofwords);
+	}
+# Now, here's something you did not think of: Brown WWP: M&sup-r;
+# You are going to split words, on hyphens just below.  That would 
+# be a mess.  So a little exception handler which we will convert
+# to the supp(.) for indexing.
+	if ($bunchofwords =~ /&sup-/i) {
+		$bunchofwords =~ s/\&sup-([a-z0-9]);/&supp$1;/gi;
+		}
+
+# we're splitting the line of words into distinct words
+# separated by "\n"
+$bunchofwords =~ s/($CHARSINWORD)/\n$1\n/g;
+
+if ($breakapost) {
+	$bunchofwords =~ s/\'/\'\n/g;
+	}
+$bunchofwords =~ s/\n\n*/\n/g;
+@wordlist = split(/\n/, $bunchofwords);
+$currentpos = $bytesreadin;
+$incount = 0;
+if ($inthetext) {
+   foreach $theword (@wordlist) {	
+   $lword = length($theword);
+   $incount += 1;
+#
+# Keep track of your bytes since this is where you are getting
+# the byte offsets for words.
+#
+   $currentpos += length($theword);
+#
+#  Do we have a word?  At least one of these characters.
+#
+   if ($theword =~ /[A-Za-z0-9\177-\377]/) {
+	$thelastword = $theword;
+	$posthisword = $currentpos - length($theword);
+# Set your byte position now, since you will be modifying the
+# word you are sending to the index after this.
+	$filebyte =  $posthisword;
+# Convert ents to utf-8
+	if ($theword =~ /\&/) {
+		$theword = &charents2utf8($theword);
+		}
+# Convert other ents to things....
+	if ($theword =~ /\&/) {
+		$theword = &moreentsinword($theword);
+		}
+# You may have some semi-colons...
+	if ($theword =~ /;$/) {
+		if ($theword =~ /\&/) {
+			$runasubroutine = 1;  # Need to write this subr...
+		}
+		else {
+		$theword =~ s/;$//;
+		}
+	}
+        $WORD += 1;
+
+# Get rid of certain characters that don't break words, but don't index.
+# These are defined in textload.cfg or below by default.
+      if ($CHARSNOTTOINDEX) {
+           $theword =~ s/($CHARSNOTTOINDEX)//g;
+        }
+
+# Call a subroutine to distinguish between words beginning with an
+# upper case and lower case character.  This USED to be a proper
+# name split in ARTFL, but we don't see many databases with proper
+# names tagged.  
+
+      if ($taguppercasewords) {
+      	$theword = &areyoupropname($theword);
+      }
+
+# And then swtich everything to lower case
+      $theword = &lowercaseify($theword);
+
+# If you have tag exemptions and you have some of the replacement
+# characters "_", then delete them from the index entry.  I've put
+# in both options, just in case.  I'm on the fence about this at the
+# moment since I have "_" in characters to match above.
+      if ($tagexception && $theword =~ /\_/) {
+		$theword =~ s/\_//g;
+	}
+      if (!$tagexception && $theword =~ /\_/) {
+		$theword =~ s/\_//g;
+	}
+
+# Check to see if the word is longer than we want.  More than 235
+# characters appear to cause problems in the indexer.  Truncate
+# to the limit as set in textload.cfg
+      if (length($theword) > $LONGWORDLIMIT) {
+	print STDERR "LONG WORD:" . $theword . "\nTruncating for index...\n";
+        $theword = substr($theword,0,$LONGWORDLIMIT);
+	}		
+
+# And then print the word raw index entry.....
+  	printf "%s %s %d %d %d %d %d %d %d %d %s\n", "word", $theword, $docid, $DIV1, $DIV2, $DIV3, $PARA, $SENT, $WORD, $filebyte, $currentpagetag ;
+  	if ($wordtaginfo{"lemma"}) {    
+      	printf "%s %s %d %d %d %d %d %d %d %d %s\n", "word", "lemma:$wordtaginfo{lemma}", $docid, $DIV1, $DIV2, $DIV3, $PARA, $SENT, $WORD, $filebyte, $currentpagetag ;
+    }
+    if ($wordtaginfo{"pos"}) {
+    	printf "%s %s %d %d %d %d %d %d %d %d %s\n", "word", "pos:$wordtaginfo{pos}", $docid, $DIV1, $DIV2, $DIV3, $PARA, $SENT, $WORD, $filebyte, $currentpagetag ;
+    }
+    if ($wordtaginfo{"lemma"} & $wordtaginfo{"pos"}) {
+    	printf "%s %s %d %d %d %d %d %d %d %d %s\n", "word","lemma:$wordtaginfo{lemma};pos:$wordtaginfo{pos}", $docid, $DIV1, $DIV2, $DIV3, $PARA, $SENT, $WORD, $filebyte, $currentpagetag ;
+    }
+	%wordtaginfo = ();
+
+    $totalwordsindoc += 1;
+	
+	if ($genworddocfreq) {                 # If we are counting words
+		&addtowordcount($theword);     # add this one.
+		}
+    }
+
+    
+#
+#  If we are not in a line group, then let's check for a sentence.
+#  This is pretty rough and ready, since I would need to take
+#  Unicode uppercase, character entities uppercase, and so on.
+#  Keep it simple, since we use this only to bound searches.
+#  I am checking to make sure that we have at least a couple
+#  of words in the previous sentence.
+#  Your mileage may vary.  Should all databases be tagged with
+#  sentences?  Sure, but......
+#
+   elsif (!$INLINEGROUP && !$INTAGGEDSENT) {
+ 
+#  Always break on ! and ? 
+
+    if ($theword =~ /[\!\?]/) {
+	  if ($WORD > 2 ) {
+              $SENT += 1;
+              $WORD = -1;
+              $sentbyte = $currentpos;
+              print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $sentbyte\n";
+	     }
+          }
+#  Periods are messy.  Let's try by length of previous word and
+#  capital letters to avoid hitting abbreviations.
+
+    elsif ($theword =~ /(\.)|(\xc2\xb7)|(\xce\x87)/) {
+	  $isyousent = 1;
+	  $nextincount = $incount + 1;
+	  $thenextword = $wordlist[$nextincount];
+	 if (length($thelastword) < 3) {
+		if ($thelastword =~ /[A-Z0-9]/) {
+		    $isyousent = 0;
+		    }
+		}
+#  Periods in numbers don't break sentences.
+
+	  if ($thenextword =~ /^[a-z0-9]/) {
+		$isyousent = 0;
+		} 
+
+#  Probably want a few more rules ... but for the time being....
+#  Let's check and output if we have a sent.
+
+	  if ($isyousent) { 
+	     if ($WORD > 2 ) {
+	        $SENT += 1;
+          	$WORD = -1;
+                $sentbyte = $currentpos;
+                print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $sentbyte\n";
+		}
+	     }
+	 }
+      }
+
+    }
+  }	
+}
+
+# That many closing } suggests to me that this baby needs to be
+# broken up.
+
+
+# =================================================================
+# Subroutine: docharents replaces a selected set of SGML character
+# ents with spaces in order to keep the byte count right.  We would
+# want to read a list of character ents that should NOT be considered
+# valid for including in words or, more likely, a list of VALID
+# characters from a general table.
+# =================================================================
+sub docharents {
+local ($bunchofwords);
+$bunchofwords = $_[0];
+
+if ($breakapost) {
+     $bunchofwords =~ s/\&apos;/\'     /gi;
+     }
+
+$bunchofwords =~ s/(\&space;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&mdash;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&nbsp;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&para;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&sect;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&ast;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&commat;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&ldquo;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&laquo;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&rdquo;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&raquo;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&lsquo;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&rsquo;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&quot;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&sup[0-9]*;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&mdash;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&amp;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&deg;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&ndash;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&copy;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&gt;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&lt;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&frac[0-9]*;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&pound;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&colon;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&hyphen;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&dash;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&excl;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&dagger;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&ddagger;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&times;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&blank;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&dollar;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&cent;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&verbar;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&quest;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&hellip;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&percnt;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&middot;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&plusmn;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&sqrt;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&sol;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&sdash;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&equals;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&ornament;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&rule;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&prime;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&rsqb;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&lsqb;)/" " x length($1)/gie;
+# EEBO specials
+$bunchofwords =~ s/(\&punc;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&cross;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&diamond;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&lpunctel;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&lsemicol;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&plus;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&minus;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&ounce;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&rindx;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&lindx;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&leaf;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&radic;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&dram;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&sun;)/" " x length($1)/gie;
+
+# $bunchofwords =~ s/(\&shy;)/" " x length($1)/gie;
+
+return ($bunchofwords);
+}
+
+# =================================================================
+# Subroutine: havelowerdiv looks ahead in the input stream to
+# see if we have a div immediately following the current tag.  
+# =================================================================
+
+sub havelowerdiv() {
+local ($lowerdiv, $lookahead, $nextline, $readmore, $i);
+$lookahead = $inlinecount;
+$i = 0;
+while (!$lowerdiv && $i < $LOOKHOWFAR) {
+        $lookahead += 1;
+        $nextline = $INSTREAM[$lookahead];
+        $i++;
+        if ($nextline =~ /<div/i) {
+                $lowerdiv = 1;
+                }
+    }
+return $lowerdiv;
+}
+
+# =================================================================
+# Subroutine: makesqlsubdivrecord prints a tabdelimited subdiv 
+# (paragraph block) level record for each type.... of subdiv.
+sub makesqlsubdivrecord() {
+local ($thedivtag, $philoid, $therecord);
+$thedivtag = $_[0];
+$thedivtag =~ s/\t//g;
+$philoid = $docid .":". $DIV1 .":". $DIV2 .":". $DIV3 .":". $PARA;
+$therecord = $philoid . "\t";
+
+$divinfo = "";
+$thedivtag =~ m/<([a-z0-9]*)[ >]/i;
+$divinfo = $1;
+
+if (!$divinfo) {
+	$divinfo = "SUBDIVTAGERROR: $thedivtag";
+	}
+$therecord .= $divinfo . "\t";
+
+$divinfo = "";
+if ($thedivtag =~ / type="([^"]*)"/i) {
+        $thedivtag =~ s/ type="([^"]*)"//i;
+        $divinfo = $1;
+	$divinfo = &charents2utf8($divinfo); 
+        }
+$therecord .= $divinfo . "\t";
+
+$divinfo = "";
+if ($thedivtag =~ / n="([^"]*)"/i) {
+        $thedivtag =~ s/ n="([^"]*)"//i;
+        $divinfo = $1;
+        }
+$therecord .= $divinfo . "\t";
+
+$divinfo = "";
+if ($thedivtag =~ / id="([^"]*)"/i) {
+        $thedivtag =~ s/ id="([^"]*)"//i;
+        $divinfo = $1;
+        }
+$therecord .= $divinfo . "\t";
+
+$divinfo = "";
+if ($thedivtag =~ / who="([^"]*)"/i) {
+        $thedivtag =~ s/ who="([^"]*)"//i;
+        $divinfo = $1;
+	$divinfo = &charents2utf8($divinfo);
+        }
+$therecord .= $divinfo . "\t";
+
+$divinfo = "";
+if ($thedivtag =~ / lang="([^"]*)"/i) {
+        $thedivtag =~ s/ lang="([^"]*)"//i;
+        $divinfo = $1;
+        }
+$therecord .= $divinfo . "\t";
+
+if ($DUMPXPATHS) {
+	$therecord .= $thecurrentxpath . "\t";
+	}
+else {
+	$therecord .= "\t";
+}
+
+#  $therecord .= $thedivtag . "\t";
+
+$therecord .= $docid . "\n";
+if ($debug) {
+        print "SQLSUBDIV\t" . $therecord;
+        }
+print SUBDIVINDEXFILE "$therecord";
+}
+
+	
+
+# =================================================================
+# Subroutine: makesqlrecord prints a tabdelimited div level record
+# for each div containing the title info, type, n, id, etc. with the
+# philologic31 div ID and a field open for an XPATH address.  To
+# be used for div object searching.
+# Question: should I walk thru all <div attributes and build this
+# as part of the table?  Each valid attribute would be slotted in
+# a specific field.
+# =================================================================
+
+sub makesqlrecord() {
+local ($thedivtag, $philoid, $therecord, $divinfo, $thisdivtype);
+local ($thisopenclose);
+$philoid = $_[0]; 
+$thedivtag = $_[1]; 
+
+if ($debug) {
+	print "SQLDIVTAG: $thedivtag \n";
+	}
+
+$therecord = $philoid . "\t";
+if ($thedivtag =~ /<front/i && !$DIVHEAD) {
+	$therecord .= "Front Matter\t";
+	}
+else {
+	$therecord .= $DIVHEAD . "\t";
+}
+# Extract standard stuff, set it in fields.
+$thedivtag =~ s/\t//g;
+$divinfo = "";
+
+if ($thedivtag =~ /<front/i) {
+	$thisdivtype = "front";
+}
+
+if ($thedivtag =~ / type="([^"]*)"/i) {
+	$thedivtag =~ s/ type="([^"]*)"//i;
+	$divinfo = $1;
+	$thisdivtype = $divinfo;
+	$thisdivtype =~ tr/A-Z/a-z/;
+	$thisdivtype = &charents2utf8($thisdivtype);
+	}
+$therecord .= $thisdivtype . "\t";
+
+$divinfo = "";
+if ($thedivtag =~ / lang="([^"]*)"/i) {
+        $thedivtag =~ s/ lang="([^"]*)"//i;
+        $divinfo = $1;
+        }
+$therecord .= $divinfo . "\t";
+
+$divinfo = "";
+if ($thedivtag =~ / n="([^"]*)"/i) {
+        $thedivtag =~ s/ n="([^"]*)"//i;
+        $divinfo = $1;
+        }
+$therecord .= $divinfo . "\t";
+
+$divinfo = "";
+if ($thedivtag =~ / id="([^"]*)"/i) {
+        $thedivtag =~ s/ id="([^"]*)"//i;
+        $divinfo = $1;
+        }
+$therecord .= $divinfo . "\t";
+
+# New extensions: these are to be read ahead and parsed
+# assuming opener/closer in the div..... 
+
+$divocauthor = "";
+$divocdateline = "";
+$divocplacename = "";
+$divocsalutation = "";
+$divocclassification = "";
+$divocpartofspeech = "";
+
+if ($GetDivOpenClose && $gotopenclose) {
+	if ($thedivtag =~ /<div/i) {
+		$thisopenclose = &readdivopenclose($thisdivtype, $thedivtag);
+		}
+	if ($thisopenclose) {
+		&extractopenclosedata($thisopenclose);
+		}
+	}
+
+$therecord .= $divocauthor . "\t";
+$therecord .= $divocdateline . "\t";
+$therecord .= $divocplacename . "\t";
+$therecord .= $divocsalutation . "\t";
+$therecord .= $divocclassification . "\t";
+$therecord .= $divocpartofspeech . "\t";
+
+if ($DUMPXPATHS) {
+        $therecord .= $thecurrentxpath . "\t";
+        }
+else {
+        $therecord .= "\t";
+}
+
+$therecord .= $docid;
+$therecord .= "\n";
+if ($debug) {
+	print "SQLDIV\t" . $therecord;
+	}
+print DIVINDEXFILE "$therecord";
+
+}
+
+# =================================================================
+# Subroutine: extractopenclosedata, using a very simple parser, this
+#             extracts data from div level opener and closers to
+#             populate fields in the divindex table.
+# BUG: Do I need to pop a field after an </ field?????
+# =================================================================
+sub extractopenclosedata() {
+	local ($oc, $creek, $stream, $line, $thisopenclosedata, $ofinterest);
+	local ($n, $pat, $selector, $t);
+	$oc = $_[0];
+	@ofinterest =("dateline", "salute", "signed", "author", "date");
+	$oc =~ s/\n\n*/\n/g;
+	@creek = split(/\n/, $oc);
+	foreach $line (@creek) {
+		if ($line =~ /^<[a-z]/i) {
+			foreach	$n (@ofinterest) {
+				$pat = "<" . $n . "[ >]";
+				if ($line =~ /$pat/i) {
+					$selector = $n;
+				}
+			}
+		}
+		elsif ($line =~ /^<\//) {
+			$selector = "other";
+			$donothing = 0;
+			}
+		else {
+			$thisopenclosedata{$selector} .= $line . " ";
+		}
+	}
+
+        $divocdateline = $thisopenclosedata{"dateline"};
+	delete $thisopenclosedata{"dateline"};
+	if ($divocdateline) {
+		$divocdateline = &fixopenclose($divocdateline);
+		}
+	$t = $thisopenclosedata{"date"};
+	delete $thisopenclosedata{"date"};
+	if ($t) {
+		$t = &fixopenclose($t);
+		$divocdateline .= " " . $t;
+		}
+        $divocauthor = $thisopenclosedata{"signed"};
+	delete $thisopenclosedata{"signed"};
+	if ($divocauthor) {
+		$divocauthor = &fixopenclose($divocauthor);
+		}
+	if (!$divocauthor) {
+        	$divocauthor = $thisopenclosedata{"author"};
+		delete $thisopenclosedata{"author"};
+		if ($divocauthor) {
+			$divocauthor = &fixopenclose($divocauthor);
+			}
+		} 
+
+        $divocsalutation = $thisopenclosedata{"salute"};
+	delete $thisopenclosedata{"salute"};
+	if ($divocsalutation) {
+		$divocsalutation = &fixopenclose($divocsalutation);
+		}
+
+}
+
+# =================================================================
+# Subroutine: fixopenclose, runs standard conversions for the info
+#             found in div opener and closer structures.
+# =================================================================
+sub fixopenclose() {
+	local ($tofix);
+	$tofix = $_[0];
+	$tofix = &docharents($tofix);
+        $tofix = &charents2utf8($tofix);
+        $tofix = &moreentsinword($tofix);
+        $tofix =~ s/<[^>]*>/ /g;
+        $tofix =~ s/\n/ /g;
+        $tofix =~ s/_//g;
+        $tofix =~ s/\t/ /g;
+        $tofix =~ s/  */ /g;
+        $tofix =~ s/^  *//;
+        $tofix =~ s/  *$//;
+return ($tofix);
+}
+
+# =================================================================
+# Subroutine: readdivopenclose, using a very simple parser, this
+#             this reads ahead from div to get opener and closer 
+#             data.  I really shold reimplement this and the get
+#             head data into a single function using the poor man's
+#             parser, which could also be used for generating XPATHS.
+#             This would, of course, be limited to XML docs.
+# =================================================================
+sub readdivopenclose() {
+	local ($tag, $type, $linein, $readahead, $endtag, $x, $readmore);
+	local ($ttag, $y, $opener, $closer, $inopener, $incloser, $looplimit);
+	local ($rtn);
+	$looplimit = 10000;
+	$type = $_[0];
+	$ttag = $_[1];
+	$ttag =~ m/<([A-Za-z]*)/i;
+	$tag = "<" . $1;
+	$endtag = $tag;
+	$endtag =~ s/</<\//;
+	$readmore = 1;
+	$x = $inlinecount;
+	while ($readmore && $y < $looplimit) {
+		$x++;
+		$y++;
+		$readahead = $INSTREAM[$x]; 
+
+		if ($readahead =~ /<q[ >]/i) {
+			$readmore = 0;
+			}
+                if ($readahead =~ /<text/i) {
+			$readmore = 0;
+			}
+                if ($readahead =~ /<body/i) {
+			$readmore = 0;
+			}
+
+		if ($readahead =~ /$endtag/i || $readahead =~ /$tag/i) {
+			$readmore = 0;
+			}
+		if ($readahead =~ /<opener/i) {
+			$inopener++;
+			}
+		if ($readahead =~ /<\/opener/i) {
+                        $opener .= $readahead . "\n";
+                        $inopener = 0;
+                	}
+		if ($inopener) {
+			$opener .= $readahead . "\n";
+			}
+		if ($readahead =~ /<closer/i) {
+			$incloser++;
+			}
+		if ($readahead =~ /<\/closer/i) {
+                        $closer .= $readahead . "\n";
+                        $incloser = 0;
+                	}
+		if ($incloser) {
+			$closer .= $readahead . "\n";
+			}
+		
+		}
+	if ($opener) {
+		$rtn = $opener . "\n";
+		}
+	if ($closer) {
+		$rtn .= $closer . "\n";
+		}
+return $rtn;
+}
+	
+# =================================================================
+# Subroutine: charents2utf8 converts ISO-LATIN-1 character entities in
+# index words to UTF-8 for standard word index search consistency.  
+# This is for SGML data sets and XML that have character ents rather
+# than UTF-8 characters.  Should really come from a table
+# =================================================================
+
+sub charents2utf8 () {
+     local ($theword); 
+     $theword = $_[0];
+     if (!$flattenligatures) {
+           $theword =~ s/\&AElig;/\xc3\x86/g; 
+           $theword =~ s/\&szlig;/\xc3\x9F/g;
+           $theword =~ s/\&aelig;/\xc3\xA6/g;
+	   }
+     $theword =~ s/\&Agrave;/\xc3\x80/g; 
+     $theword =~ s/\&Aacute;/\xc3\x81/g; 
+     $theword =~ s/\&Acirc;/\xc3\x82/g;
+     $theword =~ s/\&Atilde;/\xc3\x83/g;
+     $theword =~ s/\&Auml;/\xc3\x84/g;
+     $theword =~ s/\&Aring;/\xc3\x85/g;
+     $theword =~ s/\&Ccedil;/\xc3\x87/g;
+     $theword =~ s/\&Egrave;/\xc3\x88/g;
+     $theword =~ s/\&Eacute;/\xc3\x89/g;
+     $theword =~ s/\&Ecirc;/\xc3\x8A/g;
+     $theword =~ s/\&Euml;/\xc3\x8B/g;
+     $theword =~ s/\&Igrave;/\xc3\x8C/g;
+     $theword =~ s/\&Iacute;/\xc3\x8D/g;
+     $theword =~ s/\&Icirc;/\xc3\x8E/g;
+     $theword =~ s/\&Iuml;/\xc3\x8F/g;
+     $theword =~ s/\&ETH;/\xc3\x90/g;
+     $theword =~ s/\&Ntilde;/\xc3\x91/g;
+     $theword =~ s/\&Ograve;/\xc3\x92/g;
+     $theword =~ s/\&Oacute;/\xc3\x93/g;
+     $theword =~ s/\&Ocirc;/\xc3\x94/g;
+     $theword =~ s/\&Otilde;/\xc3\x95/g;
+     $theword =~ s/\&Ouml;/\xc3\x96/g;
+     $theword =~ s/\&#215;/\xc3\x97/g; # MULTIPLICATION SIGN
+     $theword =~ s/\&Oslash;/\xc3\x98/g;
+     $theword =~ s/\&Ugrave;/\xc3\x99/g;
+     $theword =~ s/\&Uacute;/\xc3\x9A/g;
+     $theword =~ s/\&Ucirc;/\xc3\x9B/g;
+     $theword =~ s/\&Uuml;/\xc3\x9C/g;
+     $theword =~ s/\&Yacute;/\xc3\x9D/g;
+     $theword =~ s/\&THORN;/\xc3\x9E/g;
+     $theword =~ s/\&agrave;/\xc3\xA0/g;
+     $theword =~ s/\&aacute;/\xc3\xA1/g;
+     $theword =~ s/\&acirc;/\xc3\xA2/g;
+     $theword =~ s/\&atilde;/\xc3\xA3/g;
+     $theword =~ s/\&auml;/\xc3\xA4/g;
+     $theword =~ s/\&aring;/\xc3\xA5/g;
+     $theword =~ s/\&ccedil;/\xc3\xA7/g;
+     $theword =~ s/\&egrave;/\xc3\xA8/g;
+     $theword =~ s/\&eacute;/\xc3\xA9/g;
+     $theword =~ s/\&ecirc;/\xc3\xAA/g;
+     $theword =~ s/\&euml;/\xc3\xAB/g;
+     $theword =~ s/\&igrave;/\xc3\xAC/g;
+     $theword =~ s/\&iacute;/\xc3\xAD/g;
+     $theword =~ s/\&icirc;/\xc3\xAE/g;
+     $theword =~ s/\&iuml;/\xc3\xAF/g;
+     $theword =~ s/\&eth;/\xc3\xB0/g;
+     $theword =~ s/\&ntilde;/\xc3\xB1/g;
+     $theword =~ s/\&ograve;/\xc3\xB2/g;
+     $theword =~ s/\&oacute;/\xc3\xB3/g;
+     $theword =~ s/\&ocirc;/\xc3\xB4/g;
+     $theword =~ s/\&otilde;/\xc3\xB5/g;
+     $theword =~ s/\&ouml;/\xc3\xB6/g;
+     $theword =~ s/\&#247;/\xc3\xB7/g;   #  DIVISION SIGN
+     $theword =~ s/\&oslash;/\xc3\xB8/g;
+     $theword =~ s/\&ugrave;/\xc3\xB9/g;
+     $theword =~ s/\&uacute;/\xc3\xBA/g;
+     $theword =~ s/\&ucirc;/\xc3\xBB/g;
+     $theword =~ s/\&uuml;/\xc3\xBC/g;
+     $theword =~ s/\&yacute;/\xc3\xBD/g;
+     $theword =~ s/\&thorn;/\xc3\xBE/g;
+     $theword =~ s/\&yuml;/\xc3\xBF/g;
+# Greek Entities for HTML4 and Chadwock Healey -- Charles Cooney
+    $theword =~ s/\&agr;/\xce\xb1/g;
+    $theword =~ s/\&alpha;/\xce\xb1/g;
+    $theword =~ s/\&bgr;/\xce\xb2/g;
+    $theword =~ s/\&beta;/\xce\xb2/g;
+    $theword =~ s/\&ggr;/\xce\xb3/g;
+    $theword =~ s/\&gamma;/\xce\xb3/g;
+    $theword =~ s/\&dgr;/\xce\xb4/g;
+    $theword =~ s/\&delta;/\xce\xb4/g;
+    $theword =~ s/\&egr;/\xce\xb5/g;
+    $theword =~ s/\&epsilon;/\xce\xb5/g;
+    $theword =~ s/\&zgr;/\xce\xb6/g;
+    $theword =~ s/\&zeta;/\xce\xb6/g;
+    $theword =~ s/\&eegr;/\xce\xb7/g;
+    $theword =~ s/\&eta;/\xce\xb7/g;
+    $theword =~ s/\&thgr;/\xce\xb8/g;
+    $theword =~ s/\&theta;/\xce\xb8/g;
+    $theword =~ s/\&igr;/\xce\xb9/g;
+    $theword =~ s/\&iota;/\xce\xb9/g;
+    $theword =~ s/\&kgr;/\xce\xba/g;
+    $theword =~ s/\&kappa;/\xce\xba/g;
+    $theword =~ s/\&lgr;/\xce\xbb/g;
+    $theword =~ s/\&lambda;/\xce\xbb/g;
+    $theword =~ s/\&mgr;/\xce\xbc/g;
+    $theword =~ s/\&mu;/\xce\xbc/g;
+    $theword =~ s/\&ngr;/\xce\xbd/g;
+    $theword =~ s/\&nu;/\xce\xbd/g;
+    $theword =~ s/\&xgr;/\xce\xbe/g;
+    $theword =~ s/\&xi;/\xce\xbe/g;
+    $theword =~ s/\&ogr;/\xce\xbf/g;
+    $theword =~ s/\&omicron;/\xce\xbf/g;
+    $theword =~ s/\&pgr;/\xcf\x80/g;
+    $theword =~ s/\&pi;/\xcf\x80/g;
+    $theword =~ s/\&rgr;/\xcf\x81/g;
+    $theword =~ s/\&rho;/\xcf\x81/g;
+    $theword =~ s/\&sfgr;/\xcf\x82/g;
+    $theword =~ s/\&sigmaf;/\xcf\x82/g;
+    $theword =~ s/\&sgr;/\xcf\x83/g;
+    $theword =~ s/\&sigma;/\xcf\x83/g;
+    $theword =~ s/\&tgr;/\xcf\x84/g;
+    $theword =~ s/\&tau;/\xcf\x84/g;
+    $theword =~ s/\&ugr;/\xcf\x85/g;
+    $theword =~ s/\&upsilon;/\xcf\x85/g;
+    $theword =~ s/\&phgr;/\xcf\x86/g;
+    $theword =~ s/\&phi;/\xcf\x86/g;
+    $theword =~ s/\&khgr;/\xcf\x87/g;
+    $theword =~ s/\&chi;/\xcf\x87/g;
+    $theword =~ s/\&psgr;/\xcf\x88/g;
+    $theword =~ s/\&psi;/\xcf\x88/g;
+    $theword =~ s/\&ohgr;/\xcf\x89/g;
+    $theword =~ s/\&omega;/\xcf\x89/g;
+    $theword =~ s/\&Agr;/\xce\x91/g;
+    $theword =~ s/\&Alpha;/\xce\x91/g;
+    $theword =~ s/\&Bgr;/\xce\x92/g;
+    $theword =~ s/\&Beta;/\xce\x92/g;
+    $theword =~ s/\&Ggr;/\xce\x93/g;
+    $theword =~ s/\&Gamma;/\xce\x93/g;
+    $theword =~ s/\&Dgr;/\xce\x94/g;
+    $theword =~ s/\&Delta;/\xce\x94/g;
+    $theword =~ s/\&Egr;/\xce\x95/g;
+    $theword =~ s/\&Epsilon;/\xce\x95/g;
+    $theword =~ s/\&Zgr;/\xce\x96/g;
+    $theword =~ s/\&Zeta;/\xce\x96/g;
+    $theword =~ s/\&EEgr;/\xce\x97/g;
+    $theword =~ s/\&Eta;/\xce\x97/g;
+    $theword =~ s/\&THgr;/\xce\x98/g;
+    $theword =~ s/\&Theta;/\xce\x98/g;
+    $theword =~ s/\&Igr;/\xce\x99/g;
+    $theword =~ s/\&Iota;/\xce\x99/g;
+    $theword =~ s/\&Kgr;/\xce\x9a/g;
+    $theword =~ s/\&Kappa;/\xce\x9a/g;
+    $theword =~ s/\&Lgr;/\xce\x9b/g;
+    $theword =~ s/\&Lambda;/\xce\x9b/g;
+    $theword =~ s/\&Mgr;/\xce\x9c/g;
+    $theword =~ s/\&Mu;/\xce\x9c/g;
+    $theword =~ s/\&Ngr;/\xce\x9d/g;
+    $theword =~ s/\&Nu;/\xce\x9d/g;
+    $theword =~ s/\&Xgr;/\xce\x9e/g;
+    $theword =~ s/\&Xi;/\xce\x9e/g;
+    $theword =~ s/\&Ogr;/\xce\x9f/g;
+    $theword =~ s/\&Omicron;/\xce\x9f/g;
+    $theword =~ s/\&Pgr;/\xce\xa0/g;
+    $theword =~ s/\&Pi;/\xce\xa0/g;
+    $theword =~ s/\&Rgr;/\xce\xa1/g;
+    $theword =~ s/\&Rho;/\xce\xa1/g;
+    $theword =~ s/\&Sgr;/\xce\xa3/g;
+    $theword =~ s/\&Sigma;/\xce\xa3/g;
+    $theword =~ s/\&Tgr;/\xce\xa4/g;
+    $theword =~ s/\&Tau;/\xce\xa4/g;
+    $theword =~ s/\&Ugr;/\xce\xa5/g;
+    $theword =~ s/\&Upsilon;/\xce\xa5/g;
+    $theword =~ s/\&PHgr;/\xce\xa6/g;
+    $theword =~ s/\&Phi;/\xce\xa6/g;
+    $theword =~ s/\&KHgr;/\xce\xa7/g;
+    $theword =~ s/\&Chi;/\xce\xa7/g;
+    $theword =~ s/\&PSgr;/\xce\xa8/g;
+    $theword =~ s/\&Psi;/\xce\xa8/g;
+    $theword =~ s/\&OHgr;/\xce\xa9/g;
+    $theword =~ s/\&Omega;/\xce\xa9/g;
+
+
+return $theword;
+
+}
+
+# =================================================================
+# Subroutine: moreentsinword handles character entities in
+# index words.  There should not be many of these.         
+# =================================================================
+
+sub moreentsinword() {
+local ($theword);
+     $theword = $_[0];
+     $theword =~ s/\&apos;/\'/gi;
+     $theword =~ s/\&s;/s/gi;
+     $theword =~ s/\&([A-Za-z])macr;/$1/gi;
+     $theword =~ s/\&inverted([a-zA-Z0-9]);/$1/gi;  # WWP &invertedu; etc.
+     $theword =~ s/\&supp([a-z0-9]);/$1/gi;         # WWP &sup-.;
+     if ($flattenligatures) {
+	$theword =~ s/\&([A-Za-z][A-Za-z])lig;/$1/gi;
+	}
+return $theword;
+}
+
+# =================================================================
+# Subroutine: areyoupropname identifies upper case characters.  This
+# could be modified to tag only proper names if we ever see a database
+# with these. This is selected from an option set at the top.  Should
+# work for Latin Characters.  
+# =================================================================
+
+sub areyoupropname() {
+local ($theword);
+     $theword = $_[0];
+#     $theword =~ s/^(\p{IsUpper})/\256$1/g;
+     $theword =~ s/^([A-Z])/\256$1/;
+     $theword =~ s/^(\xc3[\x80-\x9E])/\256$1/;
+return ($theword);
+}
+
+# =================================================================
+# Subroutine: lowercaseify   translate the index entry word to
+# lowercase characters.  Recall the we have the proper name tag "\256".  
+# Need to handle this for all Unicode. 
+# =================================================================
+
+sub lowercaseify() {
+local ($theword);
+     $theword = $_[0];
+     $theword =~ tr/A-Z/a-z/;
+#     $theword =~ s/(\p{IsUpper})/\l$1/g;
+     $theword =~ s/\xc3([\x80-\x9E])/&up2low($1)/ge;
+return ($theword);
+}
+
+sub up2low() {
+local ($onechar, $rtn);
+      $onechar = $_[0];
+      $onechar =~ tr/\x80-\x9E/\xA0-\xBE/;
+      $rtn = "\xc3" . $onechar;
+return $rtn;
+}
+
+# =================================================================
+# Subroutine: inwordtagdel  An experimental inword tag spanner.  
+# For selected tags between letters, this replaces the tag with "_" 
+# (in order to keep the byte count).  This is to allow indexing of
+# words broken by tags.  
+# =================================================================
+sub inwordtagdel() {
+    local ($e);
+    foreach $e (@listofexempttags) {
+       $thewholething =~ s/([A-Za-z;])($e)([A-Za-z&])/&tagempt($1,$2,$3)/gie; 
+    }
+}
+
+sub tagempt() {
+    local ($let1, $thetag, $let2, $rtn);
+    $let1 = $_[0];
+    $thetag = $_[1];
+    $let2 = $_[2];
+    $thetag =~ s/(<[^>]*>)/"_" x length($1)/gie;
+    $rtn = $let1 . $thetag . $let2;
+    return $rtn;
+} 
+
+# =================================================================
+# Subroutine: TagWordDel 
+# Delete tag data endtag set specified in the list @listoignore.
+# Replace with string of " "in order to keep the byte count.  This is 
+# selection of things to NOT to index.
+# =================================================================
+sub TagWordDel() {      
+    local ($e);             
+    foreach $e (@listtoignore) {
+       $thewholething =~ s/($e)/" " x length($1)/gie;
+    }
+}
+
+# =================================================================
+# Subroutine: JoinHyphenWords
+# =================================================================
+sub JoinHyphenWords() {
+       $thewholething =~ s/(\&shy;[\n \t]*<lb\/>)/"_" x length($1)/gie;
+       $thewholething =~ s/(\&shy;[\n \t]*)/"_" x length($1)/gie;
+}
+
+
+# =================================================================
+# Subroutine: makerefidtable
+# Build table for handling <REFs and elements with IDs such as
+# <PB ID="p397" N="397">
+# <NOTE ID="norton-dreamnote12" PLACE="foot">
+# <REF REND="align(right)" TARGET="pf42">
+# <note id="n3" place="foot" anchored="yes" target="ref3">
+# <ref id="ref3" target="n3" targOrder="U">
+# Filehandle = REFIDTABLE
+# =================================================================
+sub makerefidtable () {
+    local ($thetag, $tagtype, $theid, $thetarget, $therecord);
+    $thetag = $_[0];
+    $thetag =~ s/<([a-zA-Z]*)//i;
+    $tagtype = $1;
+    $thetag =~ s/ id="([^"]*)"//i;
+    $theid = $1;
+    if ($theid) {
+	$therecord = $docid . "\t";
+    	$therecord .= $theid . "\t";
+    	$therecord .= $tagtype . "\t";
+# Current paragraph, which will be a note.
+	$therecord .= $DIV1 . ":" . $DIV2 . ":" . $DIV3 . ":" . $PARA . "\t";
+# Page object ... I should check this
+	$therecord .= $docpgobject . "\t";
+# And let's give them a DIV to aim at.  
+	$therecord .= $DIV1 . ":" . $DIV2 . ":" . $DIV3 . "\t";
+	$therecord .= "\n";
+	}
+    print REFIDTABLE $therecord;
+}
+
+# =================================================================
+# Subroutine: AbbrevExpand  <abbr expan="en">&emacr;</abbr>
+# =================================================================
+sub AbbrevExpand {
+	local ($rtn, $theabbrev, $p, $x, $y, $n, $abbrevcopy, $underchars);
+	$theabbrev = $_[0];
+	$abbrevcopy = $theabbrev;
+	$theabbrev =~ s/ expan="([^"]*)"//i;
+	$x = $1;
+	if ($x) {
+		$y = length($abbrevcopy);
+		$n = length($x);
+		$p = $y - $n;
+		$underchars = "_" x $p;
+		$rtn = $x . $underchars;
+		}
+	else {
+		$rtn = $abbrevcopy;
+		}
+return $rtn;
+}
+
+# =================================================================
+# Subroutine: addtowordcount  Build the associative array for the
+# word count.  It's here just in case I need to add things.  This
+# is the word as INDEXED.    
+# =================================================================
+sub addtowordcount {
+	local ($theword);
+	$theword = $_[0];
+	$THISDOCWORDCOUNT{$theword}++;
+	}
+# =================================================================
+# Subroutine: dumpthisdoccount  Write out the associative array of the
+# word count for this document.  This dumps the file into a directory
+# in work/$WORDDOCFREQDIR/ called $docid (our standard convention).
+# These will need to be copied to the target directory on installation.
+# Maybe I should just dump these right to the target directory.  Post
+# processing will be required.  I could put these scripts in the
+# directory and leave a README.  Not a standard Philo function at
+# this point.
+# DUMPS: word freq docid\n  
+# (docid since these will be merged for later processing.  Yes, I 
+# could use the filename, but I'm a wimp.
+# =================================================================
+sub dumpthisdoccount {
+	local($dirandfile, $docword, $wordfreq, $x, $y);
+	$dirandfile = $WORDDOCFREQDIR . "/" . $docid . ".rawfreq";
+	open(THISDOCCOUNT, ">$dirandfile");
+	foreach $docword (sort keys(%THISDOCWORDCOUNT)) {
+	  $x++;
+	  print THISDOCCOUNT "$docword $THISDOCWORDCOUNT{$docword} $docid\n";
+	  $y += $THISDOCWORDCOUNT{$docword};
+	  delete $THISDOCWORDCOUNT{$docword};
+	  }
+	print THISDOCCOUNT "ZZZ:TYPECOUNT $x\n";
+	print THISDOCCOUNT "ZZZ:TOKENCOUNT $y\n";
+	close (THISDOCCOUNT);
+}	
+
+# =================================================================
+# Subroutine: DeleteUnicodeWordBreakers ... replace UTF byte sequences
+#             with spaces before breaking into words.  This list is 
+#             set in textload.cfg and called only when 
+#             $HaveUnicodeWordBreakers is set.  This may be dangerous
+#             because you may find places where deleting this range
+#             breaks real characters.
+sub DeleteUnicodeWordBreakers {
+	local ($x, $line);
+	$line = $_[0];
+	foreach $x (@UnicodeWordBreakers) {
+		$line =~ s/($x)/" " x length($1)/gie;
+		}
+return $line;
+
+}
+
+# =================================================================
+# Subroutine: textloadpresets, if I can't find textload.cfg, I will
+#             use these presets.
+#             Set 1 = ON   0 = OFF.  Other values vary.  
+# This is hopefully a failsafe and should never be consulted
+#  =================================================================
+sub textloadpresets {
+# --------------------- Set Apostrophe Break ------------------------
+# Set to 1 to break words on apostrophe.  Probably 0 for
+# English, 1 for French.  Your milage may vary.
+$breakapost = 0;  
+
+# ------------------------ Define Word Pattern ----------------------
+# What word pattern do you want to use?  This is important.
+# We will want to add optional characters like {[]} for MSS 
+# notation and then set a function to delete these for the index 
+# in order to search across them.  [Note, leave "_" in the
+# second pattern to handle tags in words, etc., see below]
+$CHARSINWORD = "[\&A-Za-z0-9\177-\377][\&A-Za-z0-9\177-\377\_\'ʼ;]*";
+
+# ------------- Define Characters to Exclude from Index words -------
+# Leading to a second list, characters which can be in words
+# but you don't want to index.  I have not implemented this yet.  
+# Need an example.
+$CHARSNOTTOINDEX = "\[\{\]\}";
+
+# ------------------------ Dump Object Table ------------------------
+# SQL div table set, which dumps out a tab delimited line
+# of div level info, philo id, etc.  See below.  Leave this on.
+$printsqldivtable = 1;
+
+# ------------------------ Dump SubDiv Object Table -----------------
+# SQL div table set, which dumps out a tab delimited line
+# of subdiv level info, philo id, etc.  Experimental.  The idea is
+# to generate a table of para level objects, like stage directions
+# and the like in order to search these.  See below.  Leave this on.
+$printsqlsubdivtable = 1;
+
+# ------------------------ Generate Document Word Counts ------------
+# Turn this on to generate a document word count.  This will be
+# used in future for the PhiloLogic frequency package, giving
+# users word counts for documents, and possibly for z-score statistical
+# analysis.
+$genworddocfreq = 1;
+
+# ----------------------- Tag Upper Case Characters -----------------
+# Tag upper case.  This used to be for proper names, but we have
+# used it to tag upper case.   Leave it off unless you really need it.
+# Should be expanded to handle <name tags.
+$taguppercasewords = 0;
+
+# ---------------------- Treat Lines as Sentences --------------------
+# In linegroups, break sentence objects on <l and turn off
+# automatic sentence recognition.  Normally off.
+$lngrpbreaksent = 0;
+
+# ---------------------- Flatten Ligatures for Indexing --------------
+# Convert SGML ligatures to base characters for indexing.  
+# &oelig; = oe.  Leave this on.  At one point we should think
+# Unicode, but who knows if this is important.
+$flattenligatures = 1;
+
+# --------------------- Ignore recursive text divs -------------------
+# Ignore divs in internal texts.  This is for constructs which
+# quoted <q objects as new <text objects.  I have to admit
+# that recursive arguments make sense at a certain level, but 
+# violate my notion of documentary structures.  Recursion is a
+# great programming technique, but as a data representation it 
+# makes things hard.  Leave this ON.
+$ignoredivsinsubtext = 1;
+
+# ---------------------- SubDiv Look Ahead --------------------------
+# When looking ahead to see if you have an immediate lower div,
+# set how many lines to look.  A real XML parser would not need this.
+$LOOKHOWFAR = 10;
+
+# ---------------------- Div Head Look Ahead ------------------------
+# In a <div, how far to look ahead for a <head.  A real XML parser
+# would not need this.
+$HEADLOOKLINES = 7;
+
+# ------------------ Skip in word tags -------------------------------
+# Tags normally break words.  There may be exceptions.  To run the 
+# exception, turn on the exception and list them as patterns.  
+# Tags will not be indexed and will not break words.
+$tagexception = 1;
+@listofexempttags = ('<hi[^>]*>',
+                     '<emph[^>]*>',
+		     '<\/hi>',
+		     '<\/emph>',
+		     '<orig[^>]*>',
+                     '<\/orig>',
+		     '<sic[^>]*>',
+                     '<\/sic>',
+		     '<abbr[^>]*>',
+                     '<\/abbr>',
+		      );
+# This is ugly. I am doing this by looking for these tags with a letter
+# before and after, changing them to "_" and after I get the
+# word, deleting "_".  Leave it off unless you really need it.
+# Note that you need to construct valid perl patterns.  
+
+# -------------------- Ignore DIV0 -----------------------------------
+# <div0  These are used at time to be the root level, often to
+# include the entire document.  Let's give the option to simply
+# ignore them.  Leave it off unless you see div problems, where your
+# top level div is the whole body or text.
+$ignoredivzero = 0;
+
+# ------------------- Build ID reference table -----------------------
+# Build table for handling elements with IDs.   Leave it on.
+$BUILDREFIDTABLE = 1;
+
+# ------------------- Tags and Words to Ignore ------------------------
+# Ignore tags and words.  This is a switch and list of tag/word
+# patterns to change to spaces and ignore.  Reason: the information
+# in the tags are not to be search.  These really should be 
+# milestones ... but the general point may be useful. Calls TagWordDel
+# The listtoignore must be valid patterns.
+$ignoretagswords = 1;
+@listtoignore = ('<mw[^>]*>[^<]*<\/mw>',
+                 '<A DUMMY TO HOLD THE LIST END>');
+
+# ------------------ Hyphenated Word Joiner ----------------------------
+# Softhypen word joiner.  At this time, I'm trying to join
+# words broken by &shy;\n and possibly some additional
+# selected tags.  Could be extended.  Calls JoinHyphenWords
+$joinshywords = 1;
+
+# ------------------ Abbreviation Expander for Indexing. ---------------
+# This is to handle abbreviation tags.  I have seen two types:
+#       <abbr expan="en">&emacr;</abbr>
+#       <abbr expan="Valerius Maximus">Val. Max.</abbr>
+# For now, lets's try the first.  Calls subroutine AbbrevExpand
+$abbrevexpand = 1;
+
+# ----------------- Get Div opener and closer values -------------------
+# This is to add DIV level opener and closer values to the DIV index.
+# Should be left on once it is tinkered with
+$GetDivOpenClose = 1;
+
+#  ----------------- Set Long Word Limit  -------------------
+#  Words greater than 235 characters (bytes) cause an indexing
+#  error.  This sets a limit.  Words are then truncated to fit.
+$LONGWORDLIMIT = 128;
+}
+
+# =================================================================
+# Subroutine: getthisxpath: a simple XPATH generator for divindex
+# and subdivindex files.  Not really used, but it will spit it out
+# if $DUMPXPATHS is set in texload.cfg.  Your mileage will really
+# vary here.
+# =================================================================
+sub getthisxpath() {
+    local ($tag, $w, $genpath);
+    $tag = $_[0];
+    $tag =~ tr/A-Z/a-z/;
+    $genpath = 1;
+    if ($tag =~ /\/ ?>/) {
+	$genpath = 0;
+	}
+    elsif ($tag =~ /<\//) {
+	pop(@listofxpath);
+	$genpath = 1;
+    	}
+    elsif ($tag =~ /<\!/) {
+	$genpath = 0;
+    	}
+    elsif ($tag =~ /<\?/) {
+	$genpath = 0;
+    	}
+    elsif ($tag =~ /^</) {
+	$tag =~ s/<//;
+	$tag =~ s/>//g;	
+	$tag =~ s/ ([a-z0-9]*)="([^"]*)"/\[\@$1="$2"\]/g;
+	push (@listofxpath, $tag);
+	$genpath = 1;
+		}
+    else {
+	$genpath = 0;	
+	}
+
+    if ($genpath) {
+    	$thecurrentxpath = "/";
+        foreach $w (@listofxpath) {          # generate the current path
+             $thecurrentxpath .= "/" . $w;
+          }
+	}
+
+return;
+}
+ 
+
+		
+     
+
+##########################################################################
+############################  Notes to Self  #############################
+##########################################################################
+# I have not yet exactly matched the level 2 and 3 data for the first.  
+# I have a kludge.  Needs to be fixed.
+# Important things to think about:
+# -- Inline notes are not handled at all.  Ideally we would exempt
+#    them from processing as part of object, but as they can occur
+#    just anywhere, this is problematic.  One notion would be to simply
+#    defer evaluation of notes until you have complete the document, then
+#    write out the word index data and require structural data as another
+#    <div or <HyperDiv at the end.  This requires removing the index
+#    compression which requires byte order of index.  
+# -- XPATH calculation for SQL <DIV table:  should be easy. Something that 
+#    would  allow forward compatibility for object manipulation.  
+# -- Hyphen and in word tag spanning:  This REALLY should set a flag
+#    to join words in the word handler.  This would be easy.  If flag,
+#    wait to print the word index entry until you get the rest of the
+#    word, and then simply print the entire word with the initial 
+#    object data.  Current mechanism is ugly and won't span things
+#    like hyphen words over page breaks.  Etc.
+# -- The <DIV table is not being used.  I should set it up now to be
+#    an object table with HEADS and types, as avaiable for <sp <speaker,
+#    <lg and other interesting tags.  These would then be related to
+#    standard metadata by a join on the docid.  Probably wait for
+#    interesting data.
+# -- We really, really should have a character registration table.  Alas,
+#    I don't think so at this time.
+# -- Leave hooks for 1) word object type as an integer and 2) flexible
+#    Object Depth.  This way we could say search all except notes, search
+#    only line groups, or stage directions.  Would need a table.  Default
+#    would be search all.
diff -Nuar philomine2/new_philologic_parts/KDgreek-xml-sgmlloader31.pl philomine2patched/new_philologic_parts/KDgreek-xml-sgmlloader31.pl
--- philomine2/new_philologic_parts/KDgreek-xml-sgmlloader31.pl	1969-12-31 18:00:00.000000000 -0600
+++ philomine2patched/new_philologic_parts/KDgreek-xml-sgmlloader31.pl	2018-07-27 13:29:09.643340620 -0500
@@ -0,0 +1,2500 @@
+#!/usr/bin/perl
+use DBI;
+# $Id: xml-sgmlloader.plin,v 2.1 2004/08/23 21:45:03 o Exp $
+# -----------------------------------------------------------------------
+# philologic31 2.8 -- TEI XML/SGML Full-text database engine
+# Copyright (C) 2004 University of Chicago
+# 
+# This program is free software; you can redistribute it and/or modify
+# it under the terms of the Affero General Public License as published by
+# Affero, Inc.; either version 1 of the License, or (at your option)
+# any later version.
+# 
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# Affero General Public License for more details.
+# 
+# You should have received a copy of the Affero General Public License
+# along with this program; if not, write to Affero, Inc.,
+# 510 Third Street, Suite 225, San Francisco, CA 94107 USA.
+
+# TEI XML and SGML loader.  It appears work properly on selected XML 
+# and SGML files.  Reads a list of generated object numbers, file names 
+# and sizes  Outputs raw index and additional data files.  I need to
+# describe this.  Some assembly required.  See Notes to Self at the
+# end of this script for things to do/change.
+# Last Modified: MVO March 28 2005.
+#
+# ======================= Table of Subroutines ======================
+# taghandler:         Main Tag processing function.
+# getdivhead:         Looks for <head...> under divs.
+# wordhandler:        Main Word processing function.
+# docharents:         Replace non-letter character entities.
+# havelowerdiv:       Check to see if there is an immediate subdiv.
+# makesqlsubdivrecord: prints a tabdelimited subdiv (paragraph block)
+# makesqlrecord:      Dump tab delimited object table (not done).
+# extractopenclosedata: Gets div table data in opener and closer
+# fixopenclose:       Runs standard conversions for opener/closer info
+# readdivopenclose:   A very simple parser get get opener/closer info
+# charents2utf8:      Convert Character Entities to UTF8.
+# moreentsinword:     Convert more character entities for indexing.
+# areyoupropname:     Check for upper case.  Should tag proper names.
+# lowercaseify:       Convert index word to lower case
+# up2low:             Convert Unicode to lower case.
+# inwordtagdel:       Replace in words tags with spanning character "_"
+# tagempt:               -- a helper for inwordtagdel
+# TagWordDel:         Replace tags and word patterns with " "
+# JoinHyphenWords:    Replace hyphen pattens with spanning character "_"
+# makerefidtable:     Generate cross reference table for document
+# AbbrevExpand:       Replace <abbr tags with letters and spanning char "_"
+# addtowordcount      Build the associative array for the word count
+# dumpthisdoccount:   Dumps document word count hash to a file.
+# DeleteUnicodeWordBreakers  replaces UTF byte sequences with space.
+# textloadpresets:    If I can't find textload.cfg, use these.
+# getthisxpath:       Get current XPATH ... experimental
+# ====================================================================
+# ================= Get ARGS for loader configurations ===============
+# ====================================================================
+# See if I can get the textloader.cfg file in the main PhiloLogic
+# directory.  If not, I'll use the defaults installed in this 
+# script.  
+${prefix} = "" unless ${prefix};
+$file = "${prefix}/etc/philologic31/philologic31.cfg";  
+# read in config files
+unless ($return = do $file) {
+	print STDERR "Could not find: philologic31.cfg\n";
+}
+
+$textloadcfg = $PHILOBUILDDIR . "/textload.cfg";
+if (-e $textloadcfg) {
+	print STDERR "Using configuration in $textloadcfg\n";
+	do $textloadcfg;
+	if (!$ReadTextLoadCfg) {
+		print STDERR "ERROR: May not have read all of $textloadcfg
+                              ... using presets.\n";
+		&textloadpresets();
+		}
+	}
+else {
+	print STDERR "Count not find $textloadcfg ... using presets.\n";
+	&textloadpresets();
+	}
+
+print STDERR "Characters in Words = ";
+print STDERR $CHARSINWORD;
+print STDERR "\n";
+print STDERR "Characters Excluded from Words (Char not indexed)= ";
+print STDERR $CHARSNOTTOINDEX ;
+print STDERR "\n";
+
+# This can be no more than 235 bytes.  I'm setting it smaller here
+# just to be safe.  This should also be set in textload.cfg and the
+# presets below.  Just bein' paranoid.
+if (!$LONGWORDLIMIT) {
+	$LONGWORDLIMIT = 128;
+	}
+
+# ================ End ARGS from loader configuration  ==============
+
+# ================= General Arguments and Preliminaries =============
+# These file names are required by other components of the Philo
+# loader or system.  Do not change them.
+
+$DUMPPHILOMINECHUNKS = 1; 
+
+$NEWPAGEMARKFILE = "newpagemarks.raw";
+$SQLDIVFILE = "divindex.raw";
+$SQLSUBDIVFILE = "subdivindex.raw";
+$COUNTBYDOC = "countbydocid";
+$REFIDTABLEFN = "ref2idtable";
+if ($genworddocfreq) {
+	$WORDDOCFREQDIR = "wordfreqdoc";
+	if (-d $WORDDOCFREQDIR) {
+		print STDERR "Found $WORDDOCFREQDIR \n";
+	}
+	else {
+		mkdir $WORDDOCFREQDIR;
+		print STDERR "Made Dir: $WORDDOCFREQDIR \n";
+	}
+}
+
+		
+
+$LENSHIM = 0; # Don't ask.
+
+# Read in a file from argv having the DOCID and then the
+# filename.  This is generated.  You can run a debugging routine
+# to output words, tags and the raw index
+
+$temp = $ARGV[0];
+if ($temp =~ /-debug/i) {
+    $debug = 1;
+    $textfile = $ARGV[1];
+}
+else {
+    $textfile = $ARGV[0];
+}
+$dbfile = "/var/www/artflsrv02/cgi-bin/perseus/GreekLexicon16.db";
+
+
+# Open a couple of additional files.
+# Page marks always....
+open (PAGEMARKFILE, ">> $NEWPAGEMARKFILE");
+
+# We want total counts by document this is simply 
+# docid \t count of total words in the document.
+
+open (DOCWORDTOTAL, ">> $COUNTBYDOC");
+
+# Div index only when set.
+if ($printsqldivtable) {
+	open (DIVINDEXFILE, ">> $SQLDIVFILE");
+	}
+
+# SubDiv index only when set.
+if ($printsqlsubdivtable) {
+	open (SUBDIVINDEXFILE, ">> $SQLSUBDIVFILE");
+	}
+
+
+# Open the ref2idtable file handle  
+if ($BUILDREFIDTABLE) {
+        open (REFIDTABLE, ">> $REFIDTABLEFN");
+        }
+
+# ======================================================================
+# ==================== The Main Loop ===================================
+# ======================================================================
+
+# Read in the list of files.  I should check for this.
+
+chomp($textfile);
+open FILEINTXT, "$textfile" or die "Couldn't fine $textfile\n";
+$morphdb = DBI->connect("DBI:SQLite:dbname=$dbfile", '', '', {PrintError, 1}) or die "Couldn't connect to DB:$dbfile\n";
+if ($morphdb->err() ) {
+    die "$DBI::errstr\n"; 
+}
+print STDERR $morphdb->tables;
+#$morphdb->do("set names utf8;");
+#$morphdb->do("set character set utf8;");
+#$morphdb->do("set character_set_connection=utf8;");
+while ($pfline = <FILEINTXT>) {
+   @plainline = split (/ /, $pfline);
+   $docid = $plainline[0];
+   $filename = $plainline[1];
+   $filename =~ s/\n//;
+
+# Initializing for each document.
+   $thewholething = "";
+   $inthetext = 0;
+   $firstidflag = 1;
+
+# Let the user know you are loading this offender
+   print STDERR "Loading $docid ===> $filename... \n";
+
+# Put the whole XML document as a string ... this works reasonably
+# quickly even for 20MB documents.  Again, I should check for the
+# file and possibly also check to see if it has a few vital things,
+# like a couple of valid tags, otherwise the loader fails.
+
+   $gotadiv = 0;
+   $gotafront = 0;
+   $gotopenclose = 0;
+   $gotaparagraph = 0;
+   open (THEXMLFILE, $filename) or die "Couldn't open $filename\n"; 
+   while (<THEXMLFILE>) {
+	if (/<div/i) {
+		$gotadiv += 1;
+		$gotaparagraph = 0;
+		}
+
+        if (/<p>/i || /<p /i) {
+                $gotaparagraph += 1;
+                }
+
+	if (!$gotopenclose) {                 # Check for opener/closer
+		if (/<opener/i) {             # Why parse for it later if you
+			$gotopenclose = 1;    # don't have any in the doc?
+			}
+		if (/<closer/i) {
+			$gotopenclose = 1;
+			}
+		}
+
+	if (/<front/i) {
+		$gotafront += 1;
+		}
+	if (/<\/front/) {
+	   	$gotadiv = 0;
+		}
+	$thewholething .= $_;
+	}
+   close (THEXMLFILE);
+
+# First pass, print page objects and byte offsets.  Print out an
+# initial page object if you don't have any.  I should probably
+# put this in the page tag handler, but I still need to check
+# for an initial page tag, so leave it for now.  
+
+   $gotpage = 0;
+   while ($thewholething =~ m/(<pb)/gi) {
+	$gotpage = 1;
+	$thepagetag = $1;
+	$startbyte = pos($thewholething) - length($thepagetag); 
+	print "page $docid $startbyte\n";
+	}
+   if (!$gotpage) {
+        print "page $docid 0\n";
+        }
+   $currentpagetag = "na";
+
+# Print the initial structure which covers the information at the
+# beginning of the file, which we are not indexing, until we get to
+# a <front, <body, or <div (and <HyperDiv).
+
+   print "p1 $docid 0 0\n";
+   print "t1 $docid 0 -1 0\n";
+   print "p2 $docid 0 -1 0\n";
+   print "t2 $docid 0 -1 -1 0\n";
+   print "p3 $docid 0 -1 -1 0\n";
+   print "t3 $docid 0 -1 -1 -1 0\n";
+
+   $DIV1 = 0;
+   $DIV2 = -1;
+   $DIV3 = -1;
+   $docpgobject = 0;
+   $contextdivlevel = 0;
+
+# In case we have notes or other objects that did not close
+# in the previous document, initialize these.
+   $NODEEPEROBJECTS = 0;
+   $INANOTE = 0;
+
+#  Replace  DOS <CR> characters with spaces since they can 
+#  give us all kinds of difficulties.
+   $thewholething =~ s/\015/ /g;
+
+# Now, we're going to split the tags out with newlines and put it all in 
+# a list.  This splits words on tags and will do so for words with 
+# inline tags, such as italics or superscripts.  So, before we do this,
+# let's check to see if we would run a couple of general fixes to
+# the the $wholething.
+
+# Join Hyphenated words.  It performs the required changes to 
+# $thewholething.
+
+if ($joinshywords) {
+	    &JoinHyphenWords;
+	}
+
+# Replace newlines with spaces.  Remember that we have seen lots of
+# tags with newlines, which can make a mess of things.
+
+   $thewholething =~ s/\n/ /g;
+
+# If set, run the Abbreviation Expander here, since these are tags
+# and words.  
+   if ($abbrevexpand) {
+       $thewholething =~ s/(<abbr[^>]*>\&[^;]*;<\/abbr>)/&AbbrevExpand($1)/gie;
+       }
+
+# Call the inword tag delete function if the switch is on.  This reads
+# the global $thewholething
+   if ($tagexception) {
+            &inwordtagdel();
+       }
+
+# Call the tag and word delete function if the switch is on.  This reads
+# the global $thewholething
+   if ($ignoretagswords) {
+            &TagWordDel();
+       }
+     
+# Add newlines to the beginning and end of all tags 
+   $thewholething =~ s/</\n</g;
+   $thewholething =~ s/>/>\n/g;
+# Split it into a list on newlines.
+   @INSTREAM = split(/\n/, $thewholething);  
+   $thewholething = ""; 
+
+#                  And finally, generate the index.
+# Read the list by lines ... distinguishing between tags and words
+# and keeping track of bytes read in, so you do to a taghandler
+# or a word handler.
+
+   $bytesreadin = 0;
+   $inlinecount = 0;
+   $totalwordsindoc = 0;
+   %wordtaginfo = ();
+   foreach $inline (@INSTREAM) {
+#
+#  Let's start indexing words and objects at either the <text
+#  of the <docbody tag.  We can add more.
+
+		if ($inline =~ /<text>/i || $inline =~ /<text /i) {
+			$inthetext = 1;
+		}
+		if ($inline =~ /<docbody/i) {
+			$inthetext = 1;
+		}
+# This is debugging code: print what's going in after preprocessing.
+		if ($debug) {
+			print "$inline\n";
+		}
+# End of debugging code
+
+		$inlinecount += 1;
+		if ($inline =~ /^</) {
+			$bytesreadin = $bytesreadin + length($inline);
+			if ($DUMPXPATHS) {
+				&getthisxpath($inline);
+			}
+			&taghandler($inline)
+		}
+		else {
+			&wordhandler($inline);
+			$bytesreadin = $bytesreadin + length($inline);
+		}
+	} 
+
+#   Print out the total word count per document here
+	print DOCWORDTOTAL "$docid\t$totalwordsindoc\n";  
+#   Print out word count for this document
+	if ($genworddocfreq) {
+	    &dumpthisdoccount();
+	}
+	if ($DUMPPHILOMINECHUNKS) {
+#		unless (($startid == $laststartid && $endid==$lastendid) | $nowordtags) {
+#		if ($wordtagflag && ($endid!=$lastendid)) {
+		if ($wordtagflag) {
+			$AllRawChunks .= "\t$startid\t$endid";
+			$wordtagflag=0;
+		}
+	    &dumpthisdocchunks();
+
+	}
+}
+
+# ======================== END OF THE MAIN LOOP =========================
+
+# =======================================================================
+# ============================== SUBROUTINES ============================
+# =======================================================================
+
+# =======================================================================
+# Subroutine: taghandler
+# This is used to track the objects
+# and output structural and navigation raw index data such as:
+# p1 1 3 9309
+# t1 PHASE FIRST 1 3 -1 9309
+# parag 1 3 1 0 0 9420
+# sent 1 3 1 0 0 0 9420
+# parag and sent do not always have to be these, but can also
+# be linegroups and lines, etc.  These are objects below divs.
+# I should also check for explicit sentence tags <sent> but
+# we have never actually seen a database that has these.  We
+# HAVE build some ourselves.  Do we need more object levels?  Yes.
+# Philo 3....  Also, we will probably want an type in word.
+#
+# See the notes below regarding tags so far
+# =================================================================
+
+sub taghandler() { 
+local ($thetag);
+$thetag = $_[0];
+
+if ($inthetext) {
+
+# Are we in a text tag in a quote <q> so we can tell if were
+# should disregard <div tags inside.  This is a setable argument
+# on top.
+
+        if ($thetag =~ /<text/i && $intextquote) {
+                $inquotetexttag = 1;
+                }
+        if ($thetag =~ /<\/text/i ) {
+                $inquotetexttag = 0;
+                }
+# are we in a quote?
+        if ($thetag =~ /<q[ >]/i ) {
+                $intextquote = 1;
+                }
+        if ($thetag =~ /<\/q>/i ) {
+                $intextquote = 0;
+                }
+
+# PARAGRAPHS: needs to check for paragraphs with attributes
+#             should also check if in a linegroup and do nothing if so.
+
+	if ($thetag =~ /<p>/i || $thetag =~ /<p /i) {
+            $dothispara = 1;
+	    if ($INANOTE) {
+		$dothispara = 0;
+		}
+	    if ($NODEEPEROBJECTS) {
+		$dothispara = 0;
+		}
+	    if ($dothispara) {
+		  $paracount += 1;
+		  $PARA += 1;
+		  $SENT = 0;
+		  $WORD = -1;
+		  $parabyte = $bytesreadin - (length($thetag) + $LENSHIM);
+		  print "parag $docid $DIV1 $DIV2 $DIV3 $PARA $parabyte\n";
+		  print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $parabyte\n";
+		  if ($DUMPPHILOMINECHUNKS) {
+			&newchunksubdiv();
+			}
+		}
+	    }
+
+# NOTES -- treat as para objects and set flag to not set paras in notes.
+# Currently treating them as distinct paragraphs.  Let's do this only
+# when the Note has a ID= statement, since these will be linked from
+# other statements, etc.  
+	if ($thetag =~ /<note /i) {
+	   if ($thetag =~ / id=/i) {
+             $paracount += 1;
+             $PARA += 1;
+             $SENT = 0;
+             $WORD = -1;
+             $parabyte = $bytesreadin - (length($thetag) + $LENSHIM);
+             print "parag $docid $DIV1 $DIV2 $DIV3 $PARA $parabyte\n";
+             print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $parabyte\n";
+             if ($DUMPPHILOMINECHUNKS) {
+                   &newchunksubdiv();
+                   }
+	     $INANOTE = 1;
+                if ($printsqlsubdivtable) {
+                        &makesqlsubdivrecord($thetag);
+                        }
+
+	   }
+        }
+
+	if ($thetag =~ /<\/note/i && $INANOTE > 0) {
+                $paracount += 1;
+                $PARA += 1;
+                $SENT = 0;
+                $WORD = -1;
+                $parabyte = $bytesreadin - (length($thetag) + $LENSHIM);
+                print "parag $docid $DIV1 $DIV2 $DIV3 $PARA $parabyte\n";
+                print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $parabyte\n";
+                if ($DUMPPHILOMINECHUNKS) {
+                   &newchunksubdiv();
+                   }
+
+		$INANOTE = 0;
+		}
+
+# EPIGRAPH: treat as para objects
+        if ($thetag =~ /<epigraph/i) {
+                $paracount += 1;
+                $PARA += 1;
+                $SENT = 0;
+                $WORD = -1;
+                $parabyte = $bytesreadin - (length($thetag) + $LENSHIM);
+                print "parag $docid $DIV1 $DIV2 $DIV3 $PARA $parabyte\n";
+                print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $parabyte\n";
+                if ($DUMPPHILOMINECHUNKS) {
+                   &newchunksubdiv();
+                   }
+                if ($printsqlsubdivtable) {
+                        &makesqlsubdivrecord($thetag);
+                        }
+		$NODEEPEROBJECTS = 1;
+                }
+	
+# END EPIGRAPH: these always often trailing objects ....
+        if ($thetag =~ /<\/epigraph/i) {
+                $paracount += 1;
+                $PARA += 1;
+                $SENT = 0;
+                $WORD = -1;
+                $parabyte = $bytesreadin - (length($thetag) + $LENSHIM);
+                print "parag $docid $DIV1 $DIV2 $DIV3 $PARA $parabyte\n";
+                print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $parabyte\n";
+                if ($DUMPPHILOMINECHUNKS) {
+                   &newchunksubdiv();
+                   }    
+
+#               if ($printsqlsubdivtable) {
+#                        &makesqlsubdivrecord($thetag);
+#                        }
+                $NODEEPEROBJECTS = 0;
+                }
+
+
+# LIST: treat as para objects
+        if ($thetag =~ /<list/i  && $NODEEPEROBJECTS < 1) {
+                $paracount += 1;
+                $PARA += 1;
+                $SENT = 0;
+                $WORD = -1;
+                $parabyte = $bytesreadin - (length($thetag) + $LENSHIM);
+                print "parag $docid $DIV1 $DIV2 $DIV3 $PARA $parabyte\n";
+                print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $parabyte\n";
+                if ($DUMPPHILOMINECHUNKS) {
+                   &newchunksubdiv();
+                   }    
+                if ($printsqlsubdivtable) {
+                        &makesqlsubdivrecord($thetag);
+                        }
+                }
+
+# ========================= SPEECH BREAKS ==============================
+# SPEECH BREAKS: treat them as para objects 
+        if ($thetag =~ /<sp /i || $thetag =~ /<sp>/i) {
+                $paracount += 1;
+                $PARA += 1;
+                $SENT = 0;
+                $WORD = -1;
+                $parabyte = $bytesreadin - (length($thetag) + $LENSHIM);
+                print "parag $docid $DIV1 $DIV2 $DIV3 $PARA $parabyte\n";
+                print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $parabyte\n";
+                if ($DUMPPHILOMINECHUNKS) {
+                   &newchunksubdiv();
+                   }   
+                   
+                if ($printsqlsubdivtable) {
+                        &makesqlsubdivrecord($thetag);
+                        }
+		$NODEEPEROBJECTS = 1;
+                }
+
+# END: SPEECH BREAKS: treat them as para objects
+        if ($thetag =~ /<\/sp /i || $thetag =~ /<\/sp>/i) {
+		$NODEEPEROBJECTS = 0;
+		}
+
+# ========================= ARGUMENT BREAKS ==============================
+# ARGUMENT BREAKS: treat them as para objects
+        if ($thetag =~ /<argument /i || $thetag =~ /<argument>/i) {
+                $paracount += 1;
+                $PARA += 1;
+                $SENT = 0;
+                $WORD = -1;
+                $parabyte = $bytesreadin - (length($thetag) + $LENSHIM);
+                print "parag $docid $DIV1 $DIV2 $DIV3 $PARA $parabyte\n";
+                print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $parabyte\n";
+                if ($DUMPPHILOMINECHUNKS) {
+                   &newchunksubdiv();
+                   }    
+
+                if ($printsqlsubdivtable) {
+                        &makesqlsubdivrecord($thetag);
+                        }
+                $NODEEPEROBJECTS = 1;
+                }
+
+# END: ARGUMENT BREAKS: treat them as para objects
+        if ($thetag =~ /<\/argument /i || $thetag =~ /<\/argument>/i) {
+                $NODEEPEROBJECTS = 0;
+                }
+
+# ========================= OPENER BREAKS ==============================
+# OPENER BREAKS: treat them as para objects
+        if ($thetag =~ /<opener /i || $thetag =~ /<opener>/i) {
+                $paracount += 1;
+                $PARA += 1;
+                $SENT = 0;
+                $WORD = -1;
+                $parabyte = $bytesreadin - (length($thetag) + $LENSHIM);
+                print "parag $docid $DIV1 $DIV2 $DIV3 $PARA $parabyte\n";
+                print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $parabyte\n";
+                if ($DUMPPHILOMINECHUNKS) {
+                   &newchunksubdiv();
+                   }    
+                if ($printsqlsubdivtable) {
+                        &makesqlsubdivrecord($thetag);
+                        }
+                $NODEEPEROBJECTS = 1;
+                }
+
+# END: OPENER BREAKS: treat them as para objects
+        if ($thetag =~ /<\/opener /i || $thetag =~ /<\/opener>/i) {
+                $NODEEPEROBJECTS = 0;
+                }
+
+# ========================= CLOSER BREAKS ==============================
+# CLOSER BREAKS: treat them as para objects
+        if ($thetag =~ /<closer /i || $thetag =~ /<closer>/i) {
+                $paracount += 1;
+                $PARA += 1;
+                $SENT = 0;
+                $WORD = -1;
+                $parabyte = $bytesreadin - (length($thetag) + $LENSHIM);
+                print "parag $docid $DIV1 $DIV2 $DIV3 $PARA $parabyte\n";
+                print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $parabyte\n";
+                if ($DUMPPHILOMINECHUNKS) {
+                   &newchunksubdiv();
+                   }    
+                if ($printsqlsubdivtable) {
+                        &makesqlsubdivrecord($thetag);
+                        }
+                $NODEEPEROBJECTS = 1;
+                }
+
+# END: CLOSER BREAKS: treat them as para objects
+        if ($thetag =~ /<\/closer /i || $thetag =~ /<\/closer>/i) {
+                $NODEEPEROBJECTS = 0;
+                }
+
+
+# =========================  STAGE DIRECTIONS ===========================
+# STAGE DIRECTIONS: treat them as para objects
+        if ($thetag =~ /<stage/i && $NODEEPEROBJECTS < 1) {
+                $paracount += 1;
+                $PARA += 1;
+                $SENT = 0;
+                $WORD = -1;
+                $parabyte = $bytesreadin - (length($thetag) + $LENSHIM);
+                print "parag $docid $DIV1 $DIV2 $DIV3 $PARA $parabyte\n";
+                print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $parabyte\n";
+                if ($DUMPPHILOMINECHUNKS) {
+                   &newchunksubdiv();
+                   }    
+
+                if ($printsqlsubdivtable) {
+                        &makesqlsubdivrecord($thetag);
+                        }
+                }
+
+# =========================  CAST LIST ===================================
+# CAST LIST: treat them as para objects
+        if ($thetag =~ /<castlist/i) {
+                $paracount += 1;
+                $PARA += 1;
+                $SENT = 0;
+                $WORD = -1;
+                $parabyte = $bytesreadin - (length($thetag) + $LENSHIM);
+                print "parag $docid $DIV1 $DIV2 $DIV3 $PARA $parabyte\n";
+                print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $parabyte\n";
+                if ($DUMPPHILOMINECHUNKS) {
+                   &newchunksubdiv();
+                   }    
+
+                if ($printsqlsubdivtable) {
+                        &makesqlsubdivrecord($thetag);
+                        }
+                }
+
+# PAGE BREAKS: this updates the currentpagetag or sets it to "na"
+#              if not found.  Note I assume n="[sometag]".  
+#              Also note that I am adding the pagetag to the output
+#              in order to split them out to replace the late function
+#              for doc in `cat plain.files | awk '{print $2"/"$3}'`; \
+#              do extpgmarks $doc; done > pagemarks.tmp
+#              echo '?????' | cat - pagemarks.tmp | sort -u > pagemarks
+
+
+	if ($thetag =~ /<pb/i) {
+		$temppagetag = $thetag;
+                $temppagetag =~ s/n="([^"]*)"/$1/i;
+		$currentpagetag = $1;
+		$currentpagetag =~ s/  */\_/g;
+		$currentpagetag =~ s/\-/\_/g;
+		$currentpagetag =~ tr/A-Z/a-z/;
+		if (!$currentpagetag) {
+			$currentpagetag = "na";
+			}
+		if ($debug) {
+			print "pgtag $currentpagetag\n";
+			}
+		print PAGEMARKFILE "$currentpagetag\n";
+		$docpgobject += 1;
+		}
+
+# LINE GROUP TAGS: treat linegroups same a paragraphs, set or unset the global
+#                  variable INLINEGROUP.
+
+	if ($thetag =~ /<lg/i  && $NODEEPEROBJECTS < 1) {
+                $paracount += 1;
+                $PARA += 1;
+                $SENT = 0;
+                $WORD = -1;
+		if ($lngrpbreaksent) {
+			$INLINEGROUP = 1;
+		}
+                $parabyte = $bytesreadin - (length($thetag) + $LENSHIM);
+                print "parag $docid $DIV1 $DIV2 $DIV3 $PARA $parabyte\n";
+                print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $parabyte\n";
+                if ($DUMPPHILOMINECHUNKS) {
+                   &newchunksubdiv();
+                   }    
+
+		if ($printsqlsubdivtable) {
+			&makesqlsubdivrecord($thetag);
+			}
+                }
+
+        if ($thetag =~ /<\/lg/i) {
+		$INLINEGROUP = 0;
+		}
+
+# END LINE TAG: use this to break "sentences" if INLINEGROUP.  This is
+#               if to set searching in line groups to lines rather than
+#               sentences.  
+
+	if ($thetag =~ /<\/l>/i) {
+	  if ($INLINEGROUP && $lngrpbreaksent) {
+            if ($WORD > 2 ) {
+              $SENT += 1;
+              $WORD = -1;
+              $sentbyte = $bytesreadin - (length($thetag) + $LENSHIM);
+              print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $sentbyte\n";
+              }
+	    }
+	  }
+			
+
+# SENTENCE TAG: <s> </s>.  We have never seen a sample of these
+# but let's add the required code to note the beginning of a new
+# sentence and to turn off automatic sentence tagging
+        if ($thetag =~ /<s>/i) {
+	    $SENT += 1;
+	    $WORD = -1;
+            $sentbyte = $bytesreadin - (length($thetag) + $LENSHIM);
+            print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $sentbyte\n";
+	    $INTAGGEDSENT = 1;
+	    }
+        if ($thetag =~ /<\/s>/i) {
+	    $INTAGGEDSENT = 0;
+	    }
+
+# DOCBODY: this is for MEP.  We will change them here to a <div1 for
+#          the time being.  Note that I am replacing with the correct
+#          number of bytes to keep the offsets right -- kludge.
+	if ($thetag =~ /<docbody/i) {
+	   $thetag =~ s/<docbody/<div1   /i;
+	   }
+
+# FRONT: Treat <front as a <div and set <divs in front as being
+#        one div level deeper.  
+
+         if ($thetag =~ /<front[> ]/i) {
+	      $XX = "-1";     # Don't ask  :-)   Probably don't need it.
+              $DIV1 += 1;
+              $DIV2 = -1;
+              $DIV3 = -1;
+              $PARA = -1;
+              $SENT = -1;
+              $WORD = -1;
+              $DIVLOC = $DIV1 . ":" . $DIV2 . ":" . $DIV3;
+              $divbyte = $bytesreadin - (length($thetag) + $LENSHIM);
+              print "p1 $docid $DIV1 $divbyte\n";
+              print "t1 Front Matter $docid $DIV1 $XX $divbyte\n";
+              if ($printsqldivtable) {
+		   $DIVHEAD = "Front Matter";
+                   $currentdivphiloid = $docid . ":" . $DIV1;
+                   &makesqlrecord($currentdivphiloid, $thetag);
+                   }
+              $testlowerdiv =  &havelowerdiv();
+              if (!$testlowerdiv) {
+                  print "p2 $docid $DIV1 $XX $divbyte\n";
+                  print "t2 $docid $DIV1 $XX $XX $divbyte\n";
+                  print "p3 $docid $DIV1 $XX $XX $divbyte\n";
+                  print "t3 $docid $DIV1 $XX $XX $XX $divbyte\n";
+                  $DIV2 = 0;
+                  }
+	      $INFRONTMATTER = 1; 
+	      $contextdivlevel = 1;
+         }
+
+         if ($thetag =~ /<\/front/i) {
+	      $INFRONTMATTER = 0; 
+	      $contextdivlevel = 0;
+	 }
+
+# BODY TAG: Let's set it as a <div object if we have no divs in the
+#           document.  These tend to carry on as FRONTMATTER.  Don't 
+#           have to check for lower divs, etc.
+
+	if ($thetag =~ /<body/i && !$gotadiv) {
+              $XX = "-1";     # Don't ask  :-)   Probably don't need it.
+              $DIV1 += 1;
+              $DIV2 = -1;
+              $DIV3 = -1;
+              $PARA = -1;
+              $SENT = -1;
+              $WORD = -1;
+              $DIVLOC = $DIV1 . ":" . $DIV2 . ":" . $DIV3;
+              $divbyte = $bytesreadin - (length($thetag) + $LENSHIM);
+              print "p1 $docid $DIV1 $divbyte\n";
+              $DIVHEAD = &getdivhead;
+	      if ($DIVHEAD =~ /\[NA\]/i) {
+			$DIVHEAD = "Document Body";
+			}
+              print "t1 $DIVHEAD $docid $DIV1 $XX $divbyte\n";
+              if ($printsqldivtable) {
+                   $currentdivphiloid = $docid . ":" . $DIV1;
+                   &makesqlrecord($currentdivphiloid, $thetag);
+                   }
+               print "p2 $docid $DIV1 $XX $divbyte\n";
+               print "t2 $docid $DIV1 $XX $XX $divbyte\n";
+               print "p3 $docid $DIV1 $XX $XX $divbyte\n";
+               print "t3 $docid $DIV1 $XX $XX $XX $divbyte\n";
+               $DIV2 = 0;
+              $contextdivlevel = 1;
+         }
+
+# HyperDiv: This is a Brown WWP construct.  It is defined as:
+#       a place to put a number of different kinds of information 
+#       which are related to the body of the text but do not appear 
+#       directly within its flow, for instance footnotes, acrostics, 
+#       and castlist information which is not printed in the text but 
+#       is required to provide IDREFs for the who attribute on <speaker>.
+# We are going to treat these a <div1, but not output a DIVHEAD, so 
+# these should not appear in TOCs.  For now, call it "[HyperDiv]"
+
+         if ($thetag =~ /<hyperdiv/i) {
+              $XX = "-1";     # Don't ask  :-)   Probably don't need it.
+              $DIV1 += 1;
+              $DIV2 = -1;
+              $DIV3 = -1;
+              $PARA = -1;
+              $SENT = -1;
+              $WORD = -1;
+              $DIVLOC = $DIV1 . ":" . $DIV2 . ":" . $DIV3;
+              $divbyte = $bytesreadin - (length($thetag) + $LENSHIM);
+              print "p1 $docid $DIV1 $divbyte\n";
+	      $DIVHEAD = "[HyperDiv]";
+              print "t1 $DIVHEAD $docid $DIV1 $XX $divbyte\n";
+	      $DIVHEAD = "[HyperDiv]";
+              if ($printsqldivtable) {
+                   $currentdivphiloid = $docid . ":" . $DIV1;
+                   &makesqlrecord($currentdivphiloid, $thetag);
+                   }
+               print "p2 $docid $DIV1 $XX $divbyte\n";
+               print "t2 $docid $DIV1 $XX $XX $divbyte\n";
+               print "p3 $docid $DIV1 $XX $XX $divbyte\n";
+               print "t3 $docid $DIV1 $XX $XX $XX $divbyte\n";
+               $DIV2 = 0;
+              $contextdivlevel = 1;
+         }
+
+
+# DIV TAGS: set division levels and print out div info.  A couple of
+#           assumptions:  I assume divs are numbered 1,2,3.  
+#           I output <head> info where I find it.  This could also
+#           be modified to output a structured table record with
+#           div type, and other attributes, along with the Philoid
+#           and head for searching under document levels.
+	if ($thetag =~ /<w([^>]+)>/i) {
+		%wordtaginfo = ();
+		$wordtagflag=1;
+		while ($thetag =~ /([^ ]+?)="([^\"]+?)"/g) {
+			my $attr = $1;
+			my $value = $2;
+			
+			if ($attr = "id") {
+				$endid = $value; #for philomine chunks
+				if ($firstidflag){
+					$startid = $value;
+					$firstidflag=0;
+
+				}
+#				print STDERR "looking up word ID $value\n";
+				my $parsequery = $morphdb->prepare("select * from tokens, parses where tokens.tokenid = parses.tokenid and tokens.tokenid = \"$value\";");
+
+				my $bestparse;
+                                $parsequery->execute();
+                                while (my $parse = $parsequery->fetchrow_hashref() ) {
+					if ($parse->{"prob"} > $bestparse->{"prob"}) {
+						$bestparse = $parse;
+					}
+				}
+				if (my $lexid = $bestparse->{"lex"}) {
+					my $lex = $morphdb->selectrow_hashref("select * from Lexicon where lexid=$lexid;");
+					$wordtaginfo{"lemma"} = $lex->{"lemma"};
+					$wordtaginfo{"pos"} = $lex->{"code"};
+				}
+				else {
+					$wordtaginfo{"lemma"} = $bestparse->{"lemma"};
+					$wordtaginfo{"pos"} = $bestparse->{"code"};
+				}
+				
+			}
+			
+			else {$wordtaginfo{$attr} = $value;}
+		}
+		
+	}
+	if ($thetag =~ /<\/div/i) {
+		$contextdivlevel = $contextdivlevel - 1;
+		$NODEEPEROBJECTS = 0;
+		}
+		
+        if ($thetag =~ /<div/i) {
+
+		$contextdivlevel += 1;
+		if ($contextdivlevel > 3) {
+			$contextdivlevel = 3;
+			}
+
+		if ($contextdivlevel < 1) {
+			$contextdivlevel = 1;
+			}
+
+		$XX = "-1";     # Don't ask  :-)  Probably don't need it.
+                $newdiv = $thetag;
+                $newdiv =~ m/<div(.)/i;
+		$newdivlevel = $1;
+		if ($debug) {
+			print "DIVLEVEL = $newdivlevel \n";
+			}
+
+# If it is an unnumbered DIV, let's get the level from the
+# context.  Maybe I should just do this for everything.  
+	 	if ($newdivlevel eq ">") {
+			$newdivlevel = $contextdivlevel;
+			}
+	 	if ($newdivlevel eq " ") {
+			$newdivlevel = $contextdivlevel;
+			}
+	 	if ($newdivlevel eq "0") {
+			$newdivlevel = $contextdivlevel;
+			}
+
+# Ignore div0 if instructed.
+		if ($ignoredivzero && $newdivlevel eq "0") {
+			$newdivlevel = 99;
+			}
+
+# <FRONT will be the top level div, so let's use context divlevel
+		if ($INFRONTMATTER) {
+			$newdivlevel = $contextdivlevel;
+			}
+
+# This is to ignore divs inside of internal text tags.  Setable
+# from configuration.  But we will bump the para and sent args
+
+		if ($ignoredivsinsubtext && $inquotetexttag) {
+		   $newdivlevel = 99;
+                   $paracount += 1;
+                   $PARA += 1;
+                   $SENT = 0;
+                   $WORD = -1;
+                   $parabyte = $bytesreadin - (length($thetag) + $LENSHIM);
+                   print "parag $docid $DIV1 $DIV2 $DIV3 $PARA $parabyte\n";
+                  print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $parabyte\n";
+		}
+
+
+		if ($debug) {
+			print "DIVLEVEL1 = $newdivlevel \n";
+			}
+
+# And then process the divs at the appropriate level.  We're trying
+# to keep the numbered divs if possible.
+
+		if ($newdivlevel eq "1") {
+		  $DIV1 += 1;
+		  $DIV2 = -1;
+		  $DIV3 = -1;
+		  $PARA = -1;
+		  $SENT = -1;
+		  $WORD = -1;
+		  $DIVLOC = $DIV1 . ":" . $DIV2 . ":" . $DIV3;
+		  $divbyte = $bytesreadin - (length($thetag) + $LENSHIM);
+   		  print "p1 $docid $DIV1 $divbyte\n";
+		  $DIVHEAD = &getdivhead;
+   		  print "t1 $DIVHEAD $docid $DIV1 $XX $divbyte\n";
+		  if ($printsqldivtable) {
+			$currentdivphiloid = $docid . ":" . $DIV1;
+		        &makesqlrecord($currentdivphiloid, $thetag);
+			}
+		  $testlowerdiv =  &havelowerdiv();
+		  if (!$testlowerdiv) {
+                      print "p2 $docid $DIV1 $XX $divbyte\n";
+                      print "t2 $docid $DIV1 $XX $XX $divbyte\n";
+                      print "p3 $docid $DIV1 $XX $XX $divbyte\n";
+                      print "t3 $docid $DIV1 $XX $XX $XX $divbyte\n";
+		      $DIV2 = 0;   # MARCHHACK was 0
+		  }
+                }
+
+                if ($newdivlevel eq "2") {
+                  $DIV2 += 1;
+                  $DIV3 = -1;
+                  $PARA = -1;
+                  $SENT = -1;
+                  $WORD = -1;
+                  $DIVLOC = $DIV1 . ":" . $DIV2 . ":" . $DIV3;
+                  $divbyte = $bytesreadin - (length($thetag) + $LENSHIM);
+                  print "p2 $docid $DIV1 $DIV2 $divbyte\n";
+		  $DIVHEAD = &getdivhead;
+                  print "t2 $DIVHEAD $docid $DIV1 $DIV2 $XX $divbyte\n";
+                  if ($printsqldivtable) {
+                        $currentdivphiloid = $docid . ":" . $DIV1 . ":" . $DIV2;
+                        &makesqlrecord($currentdivphiloid, $thetag);
+                        }
+                  $testlowerdiv =  &havelowerdiv();
+                  if (!$testlowerdiv) {
+                      print "p3 $docid $DIV1 $DIV2 $XX $divbyte\n";
+                      print "t3 $docid $DIV1 $DIV2 $XX $XX $divbyte\n";
+		      $DIV3 = 0;  # MARCHHACK was 0
+		  }
+
+                }
+                if ($newdivlevel eq "3") {
+                  $DIV3 += 1;
+                  $PARA = -1;
+                  $SENT = -1;
+		  $WORD = -1;
+                  $DIVLOC = $DIV1 . ":" . $DIV2 . ":" . $DIV3;
+                  $divbyte = $bytesreadin - (length($thetag) + $LENSHIM);
+                  print "p3 $docid $DIV1 $DIV2 $DIV3 $divbyte\n";
+		  $DIVHEAD = &getdivhead;
+                  print "t3 $DIVHEAD $docid $DIV1 $DIV2 $DIV3 $XX $divbyte\n";
+		  if ($printsqldivtable) {
+                        $currentdivphiloid = $docid . ":" . $DIV1 . ":" . $DIV2;
+			$currentdivphiloid .= ":" . $DIV3;
+                        &makesqlrecord($currentdivphiloid, $thetag);
+                        }
+
+
+                }
+
+# This is for EEBO documents with NO subdiv objects ... so I add a
+# para and sent object for the first time I see a <div.  It is a hack
+                if (!$gotaparagraph) {
+                 $gotaparagraph = 1;
+                 $paracount += 1;
+                 $PARA += 1;
+                 $SENT = 0;
+                 $WORD = -1;
+                 $parabyte = $bytesreadin - (length($thetag) + $LENSHIM);
+                 print "parag $docid $DIV1 $DIV2 $DIV3 $PARA $parabyte\n";
+                 print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $parabyte\n";
+                if ($DUMPPHILOMINECHUNKS) {
+                   &newchunksubdiv();
+                   }    
+
+                 }
+	    }
+
+# Any object that has an id will get registered in the reference table.
+# See below.
+	   if ($BUILDREFIDTABLE) {
+		if ($thetag =~ / id=/i) {
+		&makerefidtable($thetag);
+		}
+	   }
+
+      }
+
+}
+
+# =================================================================
+# Subroutine: getdivhead looks for a <head> within 5 lines of
+# a div ... and returns it to be output as a t[1-3] for our
+# table of contents/document navigation.  This is one of the BAD things
+# about not using a REAL SGML/XML parser.  Note that we could
+# also output this, with structural data, to be loaded in an
+# SQL table 
+#
+# This does not work for cases where you have the header info
+# in the <div tag, such as id="Some Title" (c.f. Cyrus).  All
+# perfectly legal, of course.
+#
+# You can also have multiple <head>s.  I should probably look for
+# these as well.
+# =================================================================
+
+sub getdivhead() {
+local ($temphead, $DIVHEAD, $lookahead, $nextline, $readmore, $x, $i);
+local ($getheadcount);
+$getheadcount = $GetMultipleDivHeads;
+$lookahead = $inlinecount;
+$readmore = 0;
+$i = 0;
+$x = 0;
+while (!$readmore && $i < $HEADLOOKLINES) {
+	$lookahead += 1;
+	$nextline = $INSTREAM[$lookahead];
+	$i++;
+	$nextline =~ s/<head\/>//i;
+        if ($nextline =~ /<div/i || $nextline =~ /<\/div/i ) {  
+                $i = $HEADLOOKLINES + 1;     # Don't go past an open or
+                $readmore = 0;               # close <div.
+                }
+	if ($nextline =~ /<head/i) {
+    		$readmore = 1;
+		}
+        if ($readmore) {
+             while ($readmore) {
+                 $lookahead += 1;
+                 $x++;
+                 $nextline = $INSTREAM[$lookahead];
+                 if ($nextline =~ /<\/head>/i) {
+                      $readmore = 0;
+                      if ($getheadcount) {
+                           $i = 2;
+                           $getheadcount = $getheadcount - 1;
+		           }
+                      else {
+			   $i = $HEADLOOKLINES + 1;
+                           }
+                      } 
+                 elsif ($x > 10) {    # Overflow trap in case you miss </head
+                      $readmore = 0;
+                      $i = $HEADLOOKLINES + 1;
+                      } 
+                 else {
+                      $DIVHEAD .= $nextline . " ";
+                      }
+                 }
+            }
+      }
+
+
+if ($DIVHEAD) {
+	$DIVHEAD = &docharents($DIVHEAD);
+	$DIVHEAD = &charents2utf8($DIVHEAD);
+	$DIVHEAD = &moreentsinword($DIVHEAD);
+	$DIVHEAD =~ s/\n<[^>]*>\n//g;
+	$DIVHEAD =~ s/\n//g;
+	$DIVHEAD =~ s/_//g;
+	$DIVHEAD =~ s/\t/ /g;
+	$DIVHEAD =~ s/  */ /g;
+	$DIVHEAD =~ s/^  *//;
+	$DIVHEAD =~ s/  *$//;
+	}
+elsif ($thetag =~ /type=/i) {
+   	$temphead = $thetag;
+   	$temphead =~ s/type="([^"]*)"//i;
+   	$temphead1 = $1;
+   	if ($temphead =~ s/n="([0-9]+)"//i) {
+   		$temphead1 .= " $1";
+   	}
+	$temphead1 = &charents2utf8($temphead1);
+  	$DIVHEAD = "[" . $temphead1 . "]";
+	}
+else {
+	$DIVHEAD = "[NA]";
+	}
+
+if ($DIVHEAD eq "[>]" || $DIVHEAD eq "[<]") {
+	        $DIVHEAD = "[NA]";
+        }
+return $DIVHEAD;
+}
+
+
+# =================================================================
+# Subroutine: wordhandler.  This needs to be split up.  It
+# takes an artbitrary string or words between two tags and
+# splits them into words and prints the raw index entry for
+# each one such as:
+#
+# word superficial 1 2 0 0 5 0 7 8616 2
+# word comprehension 1 2 0 0 5 0 8 8628 2
+#
+# It also identifies sentence breaks.  I am not checking for
+# existing sentence tags, but could and conditionalize it.
+# Also note that it does not check for sentences inside of
+# linegroups ... which are typically broken on lines.
+#
+# I am not currently handling ";" at the end of words because
+# of confusion with character ents.  Easily fixed.
+# =================================================================
+
+sub wordhandler() {
+
+local ($bunchofwords, $wordlist, $currentpos, $incount, $thenextword);
+local ($nextincount, $isyousent);
+$bunchofwords = $_[0];
+
+# We don't like many character entities, so let's change them
+# into spaces to get a clean break.
+if ($bunchofwords =~ /\&[a-zA-Z0-9\#][a-zA-Z0-9]*;/) {
+	$bunchofwords = &docharents($bunchofwords);
+	}
+# Now, we also know that there are Unicode characters which 
+# we normally want to break words.  Often, these are Microsoft characters
+# like the curly quotes. These are set in textload.cfg
+# in @UnicodeWordBreakers. 
+if ($HaveUnicodeWordBreakers) {
+        $bunchofwords = &DeleteUnicodeWordBreakers($bunchofwords);
+	}
+# Now, here's something you did not think of: Brown WWP: M&sup-r;
+# You are going to split words, on hyphens just below.  That would 
+# be a mess.  So a little exception handler which we will convert
+# to the supp(.) for indexing.
+	if ($bunchofwords =~ /&sup-/i) {
+		$bunchofwords =~ s/\&sup-([a-z0-9]);/&supp$1;/gi;
+		}
+
+        if ($DUMPPHILOMINECHUNKS && $inthetext) {
+		$copybunchofwords = $bunchofwords;
+		$copybunchofwords =~ s/\t/ /g;
+		$AllRawChunks .= $copybunchofwords . " ";
+		}
+
+# we're splitting the line of words into distinct words
+# separated by "\n"
+$bunchofwords =~ s/($CHARSINWORD)/\n$1\n/g;
+
+if ($breakapost) {
+	$bunchofwords =~ s/\'/\'\n/g;
+	}
+$bunchofwords =~ s/\n\n*/\n/g;
+@wordlist = split(/\n/, $bunchofwords);
+$currentpos = $bytesreadin;
+$incount = 0;
+if ($inthetext) {
+   foreach $theword (@wordlist) {	
+   $lword = length($theword);
+   $incount += 1;
+#
+# Keep track of your bytes since this is where you are getting
+# the byte offsets for words.
+#
+   $currentpos += length($theword);
+#
+#  Do we have a word?  At least one of these characters.
+#
+   if ($theword =~ /[A-Za-z0-9\177-\377]/) {
+	$thelastword = $theword;
+	$posthisword = $currentpos - length($theword);
+# Set your byte position now, since you will be modifying the
+# word you are sending to the index after this.
+	$filebyte =  $posthisword;
+# Convert ents to utf-8
+	if ($theword =~ /\&/) {
+		$theword = &charents2utf8($theword);
+		}
+# Convert other ents to things....
+	if ($theword =~ /\&/) {
+		$theword = &moreentsinword($theword);
+		}
+# You may have some semi-colons...
+	if ($theword =~ /;$/) {
+		if ($theword =~ /\&/) {
+			$runasubroutine = 1;  # Need to write this subr...
+		}
+		else {
+		$theword =~ s/;$//;
+		}
+	}
+        $WORD += 1;
+
+# Get rid of certain characters that don't break words, but don't index.
+# These are defined in textload.cfg or below by default.
+      if ($CHARSNOTTOINDEX) {
+           $theword =~ s/($CHARSNOTTOINDEX)//g;
+        }
+
+# Call a subroutine to distinguish between words beginning with an
+# upper case and lower case character.  This USED to be a proper
+# name split in ARTFL, but we don't see many databases with proper
+# names tagged.  
+
+      if ($taguppercasewords) {
+      	$theword = &areyoupropname($theword);
+      }
+
+# And then swtich everything to lower case
+      $theword = &lowercaseify($theword);
+
+# If you have tag exemptions and you have some of the replacement
+# characters "_", then delete them from the index entry.  I've put
+# in both options, just in case.  I'm on the fence about this at the
+# moment since I have "_" in characters to match above.
+      if ($tagexception && $theword =~ /\_/) {
+		$theword =~ s/\_//g;
+	}
+      if (!$tagexception && $theword =~ /\_/) {
+		$theword =~ s/\_//g;
+	}
+
+# Check to see if the word is longer than we want.  More than 235
+# characters appear to cause problems in the indexer.  Truncate
+# to the limit as set in textload.cfg
+      if (length($theword) > $LONGWORDLIMIT) {
+	print STDERR "LONG WORD:" . $theword . "\nTruncating for index...\n";
+        $theword = substr($theword,0,$LONGWORDLIMIT);
+	}		
+
+# And then print the word raw index entry.....
+  	printf "%s %s %d %d %d %d %d %d %d %d %s\n", "word", $theword, $docid, $DIV1, $DIV2, $DIV3, $PARA, $SENT, $WORD, $filebyte, $currentpagetag ;
+  	if ($wordtaginfo{"lemma"}) {    
+      	printf "%s %s %d %d %d %d %d %d %d %d %s\n", "word", "lemma:$wordtaginfo{lemma}", $docid, $DIV1, $DIV2, $DIV3, $PARA, $SENT, $WORD, $filebyte, $currentpagetag ;
+    }
+    if ($wordtaginfo{"pos"}) {
+    	printf "%s %s %d %d %d %d %d %d %d %d %s\n", "word", "pos:$wordtaginfo{pos}", $docid, $DIV1, $DIV2, $DIV3, $PARA, $SENT, $WORD, $filebyte, $currentpagetag ;
+    }
+    if ($wordtaginfo{"lemma"} & $wordtaginfo{"pos"}) {
+    	printf "%s %s %d %d %d %d %d %d %d %d %s\n", "word","lemma:$wordtaginfo{lemma};pos:$wordtaginfo{pos}", $docid, $DIV1, $DIV2, $DIV3, $PARA, $SENT, $WORD, $filebyte, $currentpagetag ;
+    }
+	%wordtaginfo = ();
+
+    $totalwordsindoc += 1;
+	
+	if ($genworddocfreq) {                 # If we are counting words
+		&addtowordcount($theword);     # add this one.
+		}
+    }
+#
+#  If we are not in a line group, then let's check for a sentence.
+#  This is pretty rough and ready, since I would need to take
+#  Unicode uppercase, character entities uppercase, and so on.
+#  Keep it simple, since we use this only to bound searches.
+#  I am checking to make sure that we have at least a couple
+#  of words in the previous sentence.
+#  Your mileage may vary.  Should all databases be tagged with
+#  sentences?  Sure, but......
+#
+   elsif (!$INLINEGROUP && !$INTAGGEDSENT) {
+ 
+#  Always break on ! and ? 
+
+    if ($theword =~ /[\!\?]/) {
+	  if ($WORD > 2 ) {
+              $SENT += 1;
+              $WORD = -1;
+              $sentbyte = $currentpos;
+              print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $sentbyte\n";
+	     }
+          }
+#  Periods are messy.  Let's try by length of previous word and
+#  capital letters to avoid hitting abbreviations.
+
+    elsif ($theword =~ /(\.)|(\xc2\xb7)|(\xce\x87)/) {
+	  $isyousent = 1;
+	  $nextincount = $incount + 1;
+	  $thenextword = $wordlist[$nextincount];
+	 if (length($thelastword) < 3) {
+		if ($thelastword =~ /[A-Z0-9]/) {
+		    $isyousent = 0;
+		    }
+		}
+#  Periods in numbers don't break sentences.
+
+	  if ($thenextword =~ /^[a-z0-9]/) {
+		$isyousent = 0;
+		} 
+
+#  Probably want a few more rules ... but for the time being....
+#  Let's check and output if we have a sent.
+
+	  if ($isyousent) { 
+	     if ($WORD > 2 ) {
+	        $SENT += 1;
+          	$WORD = -1;
+                $sentbyte = $currentpos;
+                print "sent $docid $DIV1 $DIV2 $DIV3 $PARA $SENT $sentbyte\n";
+		}
+	     }
+	 }
+      }
+
+    }
+  }	
+}
+
+# That many closing } suggests to me that this baby needs to be
+# broken up.
+
+
+# =================================================================
+# Subroutine: docharents replaces a selected set of SGML character
+# ents with spaces in order to keep the byte count right.  We would
+# want to read a list of character ents that should NOT be considered
+# valid for including in words or, more likely, a list of VALID
+# characters from a general table.
+# =================================================================
+sub docharents {
+local ($bunchofwords);
+$bunchofwords = $_[0];
+
+if ($breakapost) {
+     $bunchofwords =~ s/\&apos;/\'     /gi;
+     }
+
+$bunchofwords =~ s/(\&space;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&mdash;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&nbsp;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&para;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&sect;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&ast;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&commat;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&ldquo;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&laquo;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&rdquo;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&raquo;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&lsquo;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&rsquo;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&quot;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&sup[0-9]*;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&mdash;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&amp;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&deg;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&ndash;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&copy;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&gt;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&lt;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&frac[0-9]*;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&pound;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&colon;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&hyphen;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&dash;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&excl;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&dagger;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&ddagger;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&times;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&blank;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&dollar;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&cent;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&verbar;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&quest;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&hellip;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&percnt;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&middot;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&plusmn;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&sqrt;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&sol;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&sdash;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&equals;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&ornament;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&rule;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&prime;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&rsqb;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&lsqb;)/" " x length($1)/gie;
+# EEBO specials
+$bunchofwords =~ s/(\&punc;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&cross;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&diamond;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&lpunctel;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&lsemicol;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&plus;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&minus;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&ounce;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&rindx;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&lindx;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&leaf;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&radic;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&dram;)/" " x length($1)/gie;
+$bunchofwords =~ s/(\&sun;)/" " x length($1)/gie;
+
+# $bunchofwords =~ s/(\&shy;)/" " x length($1)/gie;
+
+return ($bunchofwords);
+}
+
+# =================================================================
+# Subroutine: havelowerdiv looks ahead in the input stream to
+# see if we have a div immediately following the current tag.  
+# =================================================================
+
+sub havelowerdiv() {
+local ($lowerdiv, $lookahead, $nextline, $readmore, $i);
+$lookahead = $inlinecount;
+$i = 0;
+while (!$lowerdiv && $i < $LOOKHOWFAR) {
+        $lookahead += 1;
+        $nextline = $INSTREAM[$lookahead];
+        $i++;
+        if ($nextline =~ /<div/i) {
+                $lowerdiv = 1;
+                }
+    }
+return $lowerdiv;
+}
+
+# =================================================================
+# Subroutine: makesqlsubdivrecord prints a tabdelimited subdiv 
+# (paragraph block) level record for each type.... of subdiv.
+sub makesqlsubdivrecord() {
+local ($thedivtag, $philoid, $therecord);
+$thedivtag = $_[0];
+$thedivtag =~ s/\t//g;
+$philoid = $docid .":". $DIV1 .":". $DIV2 .":". $DIV3 .":". $PARA;
+$therecord = $philoid . "\t";
+
+$divinfo = "";
+$thedivtag =~ m/<([a-z0-9]*)[ >]/i;
+$divinfo = $1;
+
+if (!$divinfo) {
+	$divinfo = "SUBDIVTAGERROR: $thedivtag";
+	}
+$therecord .= $divinfo . "\t";
+
+$divinfo = "";
+if ($thedivtag =~ / type="([^"]*)"/i) {
+        $thedivtag =~ s/ type="([^"]*)"//i;
+        $divinfo = $1;
+	$divinfo = &charents2utf8($divinfo); 
+        }
+$therecord .= $divinfo . "\t";
+
+$divinfo = "";
+if ($thedivtag =~ / n="([^"]*)"/i) {
+        $thedivtag =~ s/ n="([^"]*)"//i;
+        $divinfo = $1;
+        }
+$therecord .= $divinfo . "\t";
+
+$divinfo = "";
+if ($thedivtag =~ / id="([^"]*)"/i) {
+        $thedivtag =~ s/ id="([^"]*)"//i;
+        $divinfo = $1;
+        }
+$therecord .= $divinfo . "\t";
+
+$divinfo = "";
+if ($thedivtag =~ / who="([^"]*)"/i) {
+        $thedivtag =~ s/ who="([^"]*)"//i;
+        $divinfo = $1;
+	$divinfo = &charents2utf8($divinfo);
+        }
+$therecord .= $divinfo . "\t";
+
+$divinfo = "";
+if ($thedivtag =~ / lang="([^"]*)"/i) {
+        $thedivtag =~ s/ lang="([^"]*)"//i;
+        $divinfo = $1;
+        }
+$therecord .= $divinfo . "\t";
+
+if ($DUMPXPATHS) {
+	$therecord .= $thecurrentxpath . "\t";
+	}
+else {
+	$therecord .= "\t";
+}
+
+#  $therecord .= $thedivtag . "\t";
+
+$therecord .= $docid . "\n";
+if ($debug) {
+        print "SQLSUBDIV\t" . $therecord;
+        }
+print SUBDIVINDEXFILE "$therecord";
+}
+
+	
+
+# =================================================================
+# Subroutine: makesqlrecord prints a tabdelimited div level record
+# for each div containing the title info, type, n, id, etc. with the
+# philologic31 div ID and a field open for an XPATH address.  To
+# be used for div object searching.
+# Question: should I walk thru all <div attributes and build this
+# as part of the table?  Each valid attribute would be slotted in
+# a specific field.
+# =================================================================
+
+sub makesqlrecord() {
+local ($thedivtag, $philoid, $therecord, $divinfo, $thisdivtype);
+local ($thisopenclose);
+$philoid = $_[0]; 
+$thedivtag = $_[1]; 
+
+if ($DUMPPHILOMINECHUNKS) {
+	$firstidflag=1;
+	if ($wordtagflag) {
+		$AllRawChunks .= "\t$startid\t$endid";
+		$wordtagflag=0;
+	}
+	$AllRawChunks .= "\nDIV\t" . $philoid . "\n";
+	$laststartid=$startid;
+	$lastendid=$endid;
+	}
+
+if ($debug) {
+	print "SQLDIVTAG: $thedivtag \n";
+	}
+
+$therecord = $philoid . "\t";
+if ($thedivtag =~ /<front/i && !$DIVHEAD) {
+	$therecord .= "Front Matter\t";
+	}
+else {
+	$therecord .= $DIVHEAD . "\t";
+}
+# Extract standard stuff, set it in fields.
+$thedivtag =~ s/\t//g;
+$divinfo = "";
+
+if ($thedivtag =~ /<front/i) {
+	$thisdivtype = "front";
+}
+
+if ($thedivtag =~ / type="([^"]*)"/i) {
+	$thedivtag =~ s/ type="([^"]*)"//i;
+	$divinfo = $1;
+	$thisdivtype = $divinfo;
+	$thisdivtype =~ tr/A-Z/a-z/;
+	$thisdivtype = &charents2utf8($thisdivtype);
+	}
+$therecord .= $thisdivtype . "\t";
+
+$divinfo = "";
+if ($thedivtag =~ / lang="([^"]*)"/i) {
+        $thedivtag =~ s/ lang="([^"]*)"//i;
+        $divinfo = $1;
+        }
+$therecord .= $divinfo . "\t";
+
+$divinfo = "";
+if ($thedivtag =~ / n="([^"]*)"/i) {
+        $thedivtag =~ s/ n="([^"]*)"//i;
+        $divinfo = $1;
+        }
+$therecord .= $divinfo . "\t";
+
+$divinfo = "";
+if ($thedivtag =~ / id="([^"]*)"/i) {
+        $thedivtag =~ s/ id="([^"]*)"//i;
+        $divinfo = $1;
+        }
+$therecord .= $divinfo . "\t";
+
+# New extensions: these are to be read ahead and parsed
+# assuming opener/closer in the div..... 
+
+$divocauthor = "";
+$divocdateline = "";
+$divocplacename = "";
+$divocsalutation = "";
+$divocclassification = "";
+$divocpartofspeech = "";
+
+if ($GetDivOpenClose && $gotopenclose) {
+	if ($thedivtag =~ /<div/i) {
+		$thisopenclose = &readdivopenclose($thisdivtype, $thedivtag);
+		}
+	if ($thisopenclose) {
+		&extractopenclosedata($thisopenclose);
+		}
+	}
+
+$therecord .= $divocauthor . "\t";
+$therecord .= $divocdateline . "\t";
+$therecord .= $divocplacename . "\t";
+$therecord .= $divocsalutation . "\t";
+$therecord .= $divocclassification . "\t";
+$therecord .= $divocpartofspeech . "\t";
+
+if ($DUMPXPATHS) {
+        $therecord .= $thecurrentxpath . "\t";
+        }
+else {
+        $therecord .= "\t";
+}
+
+$therecord .= $docid;
+$therecord .= "\n";
+if ($debug) {
+	print "SQLDIV\t" . $therecord;
+	}
+print DIVINDEXFILE "$therecord";
+
+}
+
+# =================================================================
+# Subroutine: extractopenclosedata, using a very simple parser, this
+#             extracts data from div level opener and closers to
+#             populate fields in the divindex table.
+# BUG: Do I need to pop a field after an </ field?????
+# =================================================================
+sub extractopenclosedata() {
+	local ($oc, $creek, $stream, $line, $thisopenclosedata, $ofinterest);
+	local ($n, $pat, $selector, $t);
+	$oc = $_[0];
+	@ofinterest =("dateline", "salute", "signed", "author", "date");
+	$oc =~ s/\n\n*/\n/g;
+	@creek = split(/\n/, $oc);
+	foreach $line (@creek) {
+		if ($line =~ /^<[a-z]/i) {
+			foreach	$n (@ofinterest) {
+				$pat = "<" . $n . "[ >]";
+				if ($line =~ /$pat/i) {
+					$selector = $n;
+				}
+			}
+		}
+		elsif ($line =~ /^<\//) {
+			$selector = "other";
+			$donothing = 0;
+			}
+		else {
+			$thisopenclosedata{$selector} .= $line . " ";
+		}
+	}
+
+        $divocdateline = $thisopenclosedata{"dateline"};
+	delete $thisopenclosedata{"dateline"};
+	if ($divocdateline) {
+		$divocdateline = &fixopenclose($divocdateline);
+		}
+	$t = $thisopenclosedata{"date"};
+	delete $thisopenclosedata{"date"};
+	if ($t) {
+		$t = &fixopenclose($t);
+		$divocdateline .= " " . $t;
+		}
+        $divocauthor = $thisopenclosedata{"signed"};
+	delete $thisopenclosedata{"signed"};
+	if ($divocauthor) {
+		$divocauthor = &fixopenclose($divocauthor);
+		}
+	if (!$divocauthor) {
+        	$divocauthor = $thisopenclosedata{"author"};
+		delete $thisopenclosedata{"author"};
+		if ($divocauthor) {
+			$divocauthor = &fixopenclose($divocauthor);
+			}
+		} 
+
+        $divocsalutation = $thisopenclosedata{"salute"};
+	delete $thisopenclosedata{"salute"};
+	if ($divocsalutation) {
+		$divocsalutation = &fixopenclose($divocsalutation);
+		}
+
+}
+
+# =================================================================
+# Subroutine: fixopenclose, runs standard conversions for the info
+#             found in div opener and closer structures.
+# =================================================================
+sub fixopenclose() {
+	local ($tofix);
+	$tofix = $_[0];
+	$tofix = &docharents($tofix);
+        $tofix = &charents2utf8($tofix);
+        $tofix = &moreentsinword($tofix);
+        $tofix =~ s/<[^>]*>/ /g;
+        $tofix =~ s/\n/ /g;
+        $tofix =~ s/_//g;
+        $tofix =~ s/\t/ /g;
+        $tofix =~ s/  */ /g;
+        $tofix =~ s/^  *//;
+        $tofix =~ s/  *$//;
+return ($tofix);
+}
+
+# =================================================================
+# Subroutine: readdivopenclose, using a very simple parser, this
+#             this reads ahead from div to get opener and closer 
+#             data.  I really shold reimplement this and the get
+#             head data into a single function using the poor man's
+#             parser, which could also be used for generating XPATHS.
+#             This would, of course, be limited to XML docs.
+# =================================================================
+sub readdivopenclose() {
+	local ($tag, $type, $linein, $readahead, $endtag, $x, $readmore);
+	local ($ttag, $y, $opener, $closer, $inopener, $incloser, $looplimit);
+	local ($rtn);
+	$looplimit = 10000;
+	$type = $_[0];
+	$ttag = $_[1];
+	$ttag =~ m/<([A-Za-z]*)/i;
+	$tag = "<" . $1;
+	$endtag = $tag;
+	$endtag =~ s/</<\//;
+	$readmore = 1;
+	$x = $inlinecount;
+	while ($readmore && $y < $looplimit) {
+		$x++;
+		$y++;
+		$readahead = $INSTREAM[$x]; 
+
+		if ($readahead =~ /<q[ >]/i) {
+			$readmore = 0;
+			}
+                if ($readahead =~ /<text/i) {
+			$readmore = 0;
+			}
+                if ($readahead =~ /<body/i) {
+			$readmore = 0;
+			}
+
+		if ($readahead =~ /$endtag/i || $readahead =~ /$tag/i) {
+			$readmore = 0;
+			}
+		if ($readahead =~ /<opener/i) {
+			$inopener++;
+			}
+		if ($readahead =~ /<\/opener/i) {
+                        $opener .= $readahead . "\n";
+                        $inopener = 0;
+                	}
+		if ($inopener) {
+			$opener .= $readahead . "\n";
+			}
+		if ($readahead =~ /<closer/i) {
+			$incloser++;
+			}
+		if ($readahead =~ /<\/closer/i) {
+                        $closer .= $readahead . "\n";
+                        $incloser = 0;
+                	}
+		if ($incloser) {
+			$closer .= $readahead . "\n";
+			}
+		
+		}
+	if ($opener) {
+		$rtn = $opener . "\n";
+		}
+	if ($closer) {
+		$rtn .= $closer . "\n";
+		}
+return $rtn;
+}
+	
+# =================================================================
+# Subroutine: charents2utf8 converts ISO-LATIN-1 character entities in
+# index words to UTF-8 for standard word index search consistency.  
+# This is for SGML data sets and XML that have character ents rather
+# than UTF-8 characters.  Should really come from a table
+# =================================================================
+
+sub charents2utf8 () {
+     local ($theword); 
+     $theword = $_[0];
+     if (!$flattenligatures) {
+           $theword =~ s/\&AElig;/\xc3\x86/g; 
+           $theword =~ s/\&szlig;/\xc3\x9F/g;
+           $theword =~ s/\&aelig;/\xc3\xA6/g;
+	   }
+     $theword =~ s/\&Agrave;/\xc3\x80/g; 
+     $theword =~ s/\&Aacute;/\xc3\x81/g; 
+     $theword =~ s/\&Acirc;/\xc3\x82/g;
+     $theword =~ s/\&Atilde;/\xc3\x83/g;
+     $theword =~ s/\&Auml;/\xc3\x84/g;
+     $theword =~ s/\&Aring;/\xc3\x85/g;
+     $theword =~ s/\&Ccedil;/\xc3\x87/g;
+     $theword =~ s/\&Egrave;/\xc3\x88/g;
+     $theword =~ s/\&Eacute;/\xc3\x89/g;
+     $theword =~ s/\&Ecirc;/\xc3\x8A/g;
+     $theword =~ s/\&Euml;/\xc3\x8B/g;
+     $theword =~ s/\&Igrave;/\xc3\x8C/g;
+     $theword =~ s/\&Iacute;/\xc3\x8D/g;
+     $theword =~ s/\&Icirc;/\xc3\x8E/g;
+     $theword =~ s/\&Iuml;/\xc3\x8F/g;
+     $theword =~ s/\&ETH;/\xc3\x90/g;
+     $theword =~ s/\&Ntilde;/\xc3\x91/g;
+     $theword =~ s/\&Ograve;/\xc3\x92/g;
+     $theword =~ s/\&Oacute;/\xc3\x93/g;
+     $theword =~ s/\&Ocirc;/\xc3\x94/g;
+     $theword =~ s/\&Otilde;/\xc3\x95/g;
+     $theword =~ s/\&Ouml;/\xc3\x96/g;
+     $theword =~ s/\&#215;/\xc3\x97/g; # MULTIPLICATION SIGN
+     $theword =~ s/\&Oslash;/\xc3\x98/g;
+     $theword =~ s/\&Ugrave;/\xc3\x99/g;
+     $theword =~ s/\&Uacute;/\xc3\x9A/g;
+     $theword =~ s/\&Ucirc;/\xc3\x9B/g;
+     $theword =~ s/\&Uuml;/\xc3\x9C/g;
+     $theword =~ s/\&Yacute;/\xc3\x9D/g;
+     $theword =~ s/\&THORN;/\xc3\x9E/g;
+     $theword =~ s/\&agrave;/\xc3\xA0/g;
+     $theword =~ s/\&aacute;/\xc3\xA1/g;
+     $theword =~ s/\&acirc;/\xc3\xA2/g;
+     $theword =~ s/\&atilde;/\xc3\xA3/g;
+     $theword =~ s/\&auml;/\xc3\xA4/g;
+     $theword =~ s/\&aring;/\xc3\xA5/g;
+     $theword =~ s/\&ccedil;/\xc3\xA7/g;
+     $theword =~ s/\&egrave;/\xc3\xA8/g;
+     $theword =~ s/\&eacute;/\xc3\xA9/g;
+     $theword =~ s/\&ecirc;/\xc3\xAA/g;
+     $theword =~ s/\&euml;/\xc3\xAB/g;
+     $theword =~ s/\&igrave;/\xc3\xAC/g;
+     $theword =~ s/\&iacute;/\xc3\xAD/g;
+     $theword =~ s/\&icirc;/\xc3\xAE/g;
+     $theword =~ s/\&iuml;/\xc3\xAF/g;
+     $theword =~ s/\&eth;/\xc3\xB0/g;
+     $theword =~ s/\&ntilde;/\xc3\xB1/g;
+     $theword =~ s/\&ograve;/\xc3\xB2/g;
+     $theword =~ s/\&oacute;/\xc3\xB3/g;
+     $theword =~ s/\&ocirc;/\xc3\xB4/g;
+     $theword =~ s/\&otilde;/\xc3\xB5/g;
+     $theword =~ s/\&ouml;/\xc3\xB6/g;
+     $theword =~ s/\&#247;/\xc3\xB7/g;   #  DIVISION SIGN
+     $theword =~ s/\&oslash;/\xc3\xB8/g;
+     $theword =~ s/\&ugrave;/\xc3\xB9/g;
+     $theword =~ s/\&uacute;/\xc3\xBA/g;
+     $theword =~ s/\&ucirc;/\xc3\xBB/g;
+     $theword =~ s/\&uuml;/\xc3\xBC/g;
+     $theword =~ s/\&yacute;/\xc3\xBD/g;
+     $theword =~ s/\&thorn;/\xc3\xBE/g;
+     $theword =~ s/\&yuml;/\xc3\xBF/g;
+# Greek Entities for HTML4 and Chadwock Healey -- Charles Cooney
+    $theword =~ s/\&agr;/\xce\xb1/g;
+    $theword =~ s/\&alpha;/\xce\xb1/g;
+    $theword =~ s/\&bgr;/\xce\xb2/g;
+    $theword =~ s/\&beta;/\xce\xb2/g;
+    $theword =~ s/\&ggr;/\xce\xb3/g;
+    $theword =~ s/\&gamma;/\xce\xb3/g;
+    $theword =~ s/\&dgr;/\xce\xb4/g;
+    $theword =~ s/\&delta;/\xce\xb4/g;
+    $theword =~ s/\&egr;/\xce\xb5/g;
+    $theword =~ s/\&epsilon;/\xce\xb5/g;
+    $theword =~ s/\&zgr;/\xce\xb6/g;
+    $theword =~ s/\&zeta;/\xce\xb6/g;
+    $theword =~ s/\&eegr;/\xce\xb7/g;
+    $theword =~ s/\&eta;/\xce\xb7/g;
+    $theword =~ s/\&thgr;/\xce\xb8/g;
+    $theword =~ s/\&theta;/\xce\xb8/g;
+    $theword =~ s/\&igr;/\xce\xb9/g;
+    $theword =~ s/\&iota;/\xce\xb9/g;
+    $theword =~ s/\&kgr;/\xce\xba/g;
+    $theword =~ s/\&kappa;/\xce\xba/g;
+    $theword =~ s/\&lgr;/\xce\xbb/g;
+    $theword =~ s/\&lambda;/\xce\xbb/g;
+    $theword =~ s/\&mgr;/\xce\xbc/g;
+    $theword =~ s/\&mu;/\xce\xbc/g;
+    $theword =~ s/\&ngr;/\xce\xbd/g;
+    $theword =~ s/\&nu;/\xce\xbd/g;
+    $theword =~ s/\&xgr;/\xce\xbe/g;
+    $theword =~ s/\&xi;/\xce\xbe/g;
+    $theword =~ s/\&ogr;/\xce\xbf/g;
+    $theword =~ s/\&omicron;/\xce\xbf/g;
+    $theword =~ s/\&pgr;/\xcf\x80/g;
+    $theword =~ s/\&pi;/\xcf\x80/g;
+    $theword =~ s/\&rgr;/\xcf\x81/g;
+    $theword =~ s/\&rho;/\xcf\x81/g;
+    $theword =~ s/\&sfgr;/\xcf\x82/g;
+    $theword =~ s/\&sigmaf;/\xcf\x82/g;
+    $theword =~ s/\&sgr;/\xcf\x83/g;
+    $theword =~ s/\&sigma;/\xcf\x83/g;
+    $theword =~ s/\&tgr;/\xcf\x84/g;
+    $theword =~ s/\&tau;/\xcf\x84/g;
+    $theword =~ s/\&ugr;/\xcf\x85/g;
+    $theword =~ s/\&upsilon;/\xcf\x85/g;
+    $theword =~ s/\&phgr;/\xcf\x86/g;
+    $theword =~ s/\&phi;/\xcf\x86/g;
+    $theword =~ s/\&khgr;/\xcf\x87/g;
+    $theword =~ s/\&chi;/\xcf\x87/g;
+    $theword =~ s/\&psgr;/\xcf\x88/g;
+    $theword =~ s/\&psi;/\xcf\x88/g;
+    $theword =~ s/\&ohgr;/\xcf\x89/g;
+    $theword =~ s/\&omega;/\xcf\x89/g;
+    $theword =~ s/\&Agr;/\xce\x91/g;
+    $theword =~ s/\&Alpha;/\xce\x91/g;
+    $theword =~ s/\&Bgr;/\xce\x92/g;
+    $theword =~ s/\&Beta;/\xce\x92/g;
+    $theword =~ s/\&Ggr;/\xce\x93/g;
+    $theword =~ s/\&Gamma;/\xce\x93/g;
+    $theword =~ s/\&Dgr;/\xce\x94/g;
+    $theword =~ s/\&Delta;/\xce\x94/g;
+    $theword =~ s/\&Egr;/\xce\x95/g;
+    $theword =~ s/\&Epsilon;/\xce\x95/g;
+    $theword =~ s/\&Zgr;/\xce\x96/g;
+    $theword =~ s/\&Zeta;/\xce\x96/g;
+    $theword =~ s/\&EEgr;/\xce\x97/g;
+    $theword =~ s/\&Eta;/\xce\x97/g;
+    $theword =~ s/\&THgr;/\xce\x98/g;
+    $theword =~ s/\&Theta;/\xce\x98/g;
+    $theword =~ s/\&Igr;/\xce\x99/g;
+    $theword =~ s/\&Iota;/\xce\x99/g;
+    $theword =~ s/\&Kgr;/\xce\x9a/g;
+    $theword =~ s/\&Kappa;/\xce\x9a/g;
+    $theword =~ s/\&Lgr;/\xce\x9b/g;
+    $theword =~ s/\&Lambda;/\xce\x9b/g;
+    $theword =~ s/\&Mgr;/\xce\x9c/g;
+    $theword =~ s/\&Mu;/\xce\x9c/g;
+    $theword =~ s/\&Ngr;/\xce\x9d/g;
+    $theword =~ s/\&Nu;/\xce\x9d/g;
+    $theword =~ s/\&Xgr;/\xce\x9e/g;
+    $theword =~ s/\&Xi;/\xce\x9e/g;
+    $theword =~ s/\&Ogr;/\xce\x9f/g;
+    $theword =~ s/\&Omicron;/\xce\x9f/g;
+    $theword =~ s/\&Pgr;/\xce\xa0/g;
+    $theword =~ s/\&Pi;/\xce\xa0/g;
+    $theword =~ s/\&Rgr;/\xce\xa1/g;
+    $theword =~ s/\&Rho;/\xce\xa1/g;
+    $theword =~ s/\&Sgr;/\xce\xa3/g;
+    $theword =~ s/\&Sigma;/\xce\xa3/g;
+    $theword =~ s/\&Tgr;/\xce\xa4/g;
+    $theword =~ s/\&Tau;/\xce\xa4/g;
+    $theword =~ s/\&Ugr;/\xce\xa5/g;
+    $theword =~ s/\&Upsilon;/\xce\xa5/g;
+    $theword =~ s/\&PHgr;/\xce\xa6/g;
+    $theword =~ s/\&Phi;/\xce\xa6/g;
+    $theword =~ s/\&KHgr;/\xce\xa7/g;
+    $theword =~ s/\&Chi;/\xce\xa7/g;
+    $theword =~ s/\&PSgr;/\xce\xa8/g;
+    $theword =~ s/\&Psi;/\xce\xa8/g;
+    $theword =~ s/\&OHgr;/\xce\xa9/g;
+    $theword =~ s/\&Omega;/\xce\xa9/g;
+
+
+return $theword;
+
+}
+
+# =================================================================
+# Subroutine: moreentsinword handles character entities in
+# index words.  There should not be many of these.         
+# =================================================================
+
+sub moreentsinword() {
+local ($theword);
+     $theword = $_[0];
+     $theword =~ s/\&apos;/\'/gi;
+     $theword =~ s/\&s;/s/gi;
+     $theword =~ s/\&([A-Za-z])macr;/$1/gi;
+     $theword =~ s/\&inverted([a-zA-Z0-9]);/$1/gi;  # WWP &invertedu; etc.
+     $theword =~ s/\&supp([a-z0-9]);/$1/gi;         # WWP &sup-.;
+     if ($flattenligatures) {
+	$theword =~ s/\&([A-Za-z][A-Za-z])lig;/$1/gi;
+	}
+return $theword;
+}
+
+# =================================================================
+# Subroutine: areyoupropname identifies upper case characters.  This
+# could be modified to tag only proper names if we ever see a database
+# with these. This is selected from an option set at the top.  Should
+# work for Latin Characters.  
+# =================================================================
+
+sub areyoupropname() {
+local ($theword);
+     $theword = $_[0];
+#     $theword =~ s/^(\p{IsUpper})/\256$1/g;
+     $theword =~ s/^([A-Z])/\256$1/;
+     $theword =~ s/^(\xc3[\x80-\x9E])/\256$1/;
+return ($theword);
+}
+
+# =================================================================
+# Subroutine: lowercaseify   translate the index entry word to
+# lowercase characters.  Recall the we have the proper name tag "\256".  
+# Need to handle this for all Unicode. 
+# =================================================================
+
+sub lowercaseify() {
+local ($theword);
+     $theword = $_[0];
+     $theword =~ tr/A-Z/a-z/;
+#     $theword =~ s/(\p{IsUpper})/\l$1/g;
+     $theword =~ s/\xc3([\x80-\x9E])/&up2low($1)/ge;
+return ($theword);
+}
+
+sub up2low() {
+local ($onechar, $rtn);
+      $onechar = $_[0];
+      $onechar =~ tr/\x80-\x9E/\xA0-\xBE/;
+      $rtn = "\xc3" . $onechar;
+return $rtn;
+}
+
+# =================================================================
+# Subroutine: inwordtagdel  An experimental inword tag spanner.  
+# For selected tags between letters, this replaces the tag with "_" 
+# (in order to keep the byte count).  This is to allow indexing of
+# words broken by tags.  
+# =================================================================
+sub inwordtagdel() {
+    local ($e);
+    foreach $e (@listofexempttags) {
+       $thewholething =~ s/([A-Za-z;])($e)([A-Za-z&])/&tagempt($1,$2,$3)/gie; 
+    }
+}
+
+sub tagempt() {
+    local ($let1, $thetag, $let2, $rtn);
+    $let1 = $_[0];
+    $thetag = $_[1];
+    $let2 = $_[2];
+    $thetag =~ s/(<[^>]*>)/"_" x length($1)/gie;
+    $rtn = $let1 . $thetag . $let2;
+    return $rtn;
+} 
+
+# =================================================================
+# Subroutine: TagWordDel 
+# Delete tag data endtag set specified in the list @listoignore.
+# Replace with string of " "in order to keep the byte count.  This is 
+# selection of things to NOT to index.
+# =================================================================
+sub TagWordDel() {      
+    local ($e);             
+    foreach $e (@listtoignore) {
+       $thewholething =~ s/($e)/" " x length($1)/gie;
+    }
+}
+
+# =================================================================
+# Subroutine: JoinHyphenWords
+# =================================================================
+sub JoinHyphenWords() {
+       $thewholething =~ s/(\&shy;[\n \t]*<lb\/>)/"_" x length($1)/gie;
+       $thewholething =~ s/(\&shy;[\n \t]*)/"_" x length($1)/gie;
+}
+
+
+# =================================================================
+# Subroutine: makerefidtable
+# Build table for handling <REFs and elements with IDs such as
+# <PB ID="p397" N="397">
+# <NOTE ID="norton-dreamnote12" PLACE="foot">
+# <REF REND="align(right)" TARGET="pf42">
+# <note id="n3" place="foot" anchored="yes" target="ref3">
+# <ref id="ref3" target="n3" targOrder="U">
+# Filehandle = REFIDTABLE
+# =================================================================
+sub makerefidtable () {
+    local ($thetag, $tagtype, $theid, $thetarget, $therecord);
+    $thetag = $_[0];
+    $thetag =~ s/<([a-zA-Z]*)//i;
+    $tagtype = $1;
+    $thetag =~ s/ id="([^"]*)"//i;
+    $theid = $1;
+    if ($theid) {
+	$therecord = $docid . "\t";
+    	$therecord .= $theid . "\t";
+    	$therecord .= $tagtype . "\t";
+# Current paragraph, which will be a note.
+	$therecord .= $DIV1 . ":" . $DIV2 . ":" . $DIV3 . ":" . $PARA . "\t";
+# Page object ... I should check this
+	$therecord .= $docpgobject . "\t";
+# And let's give them a DIV to aim at.  
+	$therecord .= $DIV1 . ":" . $DIV2 . ":" . $DIV3 . "\t";
+	$therecord .= "\n";
+	}
+    print REFIDTABLE $therecord;
+}
+
+# =================================================================
+# Subroutine: AbbrevExpand  <abbr expan="en">&emacr;</abbr>
+# =================================================================
+sub AbbrevExpand {
+	local ($rtn, $theabbrev, $p, $x, $y, $n, $abbrevcopy, $underchars);
+	$theabbrev = $_[0];
+	$abbrevcopy = $theabbrev;
+	$theabbrev =~ s/ expan="([^"]*)"//i;
+	$x = $1;
+	if ($x) {
+		$y = length($abbrevcopy);
+		$n = length($x);
+		$p = $y - $n;
+		$underchars = "_" x $p;
+		$rtn = $x . $underchars;
+		}
+	else {
+		$rtn = $abbrevcopy;
+		}
+return $rtn;
+}
+
+# =================================================================
+# Subroutine: addtowordcount  Build the associative array for the
+# word count.  It's here just in case I need to add things.  This
+# is the word as INDEXED.    
+# =================================================================
+sub addtowordcount {
+	local ($theword);
+	$theword = $_[0];
+	$THISDOCWORDCOUNT{$theword}++;
+	}
+# =================================================================
+# Subroutine: dumpthisdoccount  Write out the associative array of the
+# word count for this document.  This dumps the file into a directory
+# in work/$WORDDOCFREQDIR/ called $docid (our standard convention).
+# These will need to be copied to the target directory on installation.
+# Maybe I should just dump these right to the target directory.  Post
+# processing will be required.  I could put these scripts in the
+# directory and leave a README.  Not a standard Philo function at
+# this point.
+# DUMPS: word freq docid\n  
+# (docid since these will be merged for later processing.  Yes, I 
+# could use the filename, but I'm a wimp.
+# =================================================================
+sub dumpthisdoccount {
+	local($dirandfile, $docword, $wordfreq, $x, $y);
+	$dirandfile = $WORDDOCFREQDIR . "/" . $docid . ".rawfreq";
+	open(THISDOCCOUNT, ">$dirandfile");
+	foreach $docword (sort keys(%THISDOCWORDCOUNT)) {
+	  $x++;
+	  print THISDOCCOUNT "$docword $THISDOCWORDCOUNT{$docword} $docid\n";
+	  $y += $THISDOCWORDCOUNT{$docword};
+	  delete $THISDOCWORDCOUNT{$docword};
+	  }
+	print THISDOCCOUNT "ZZZ:TYPECOUNT $x\n";
+	print THISDOCCOUNT "ZZZ:TOKENCOUNT $y\n";
+	close (THISDOCCOUNT);
+}	
+
+# =================================================================
+# Subroutine: dumpthisdocchunks.  Write out raw object level chunks for
+# Philomine subdoc loading process.  Data format should be
+# DIV\tPhiloDivID\n
+# SUBDIV\tPhiloSubDivID\tAll the words and punct....\n
+sub dumpthisdocchunks{
+	local($dirandfile, $docword, $wordfreq, $x, $y);
+        $dirandfile = $WORDDOCFREQDIR . "/" . $docid . ".rawchunks";
+	open (THISDOCCHUNKS, ">$dirandfile");
+	print THISDOCCHUNKS $AllRawChunks;
+	close (THISDOCCHUNKS);
+	$AllRawChunks = "";
+	}
+# =================================================================
+# Subroutine: DeleteUnicodeWordBreakers ... replace UTF byte sequences
+#             with spaces before breaking into words.  This list is 
+#             set in textload.cfg and called only when 
+#             $HaveUnicodeWordBreakers is set.  This may be dangerous
+#             because you may find places where deleting this range
+#             breaks real characters.
+sub DeleteUnicodeWordBreakers {
+	local ($x, $line);
+	$line = $_[0];
+	foreach $x (@UnicodeWordBreakers) {
+		$line =~ s/($x)/" " x length($1)/gie;
+		}
+return $line;
+
+}
+
+# =================================================================
+# Subroutine: textloadpresets, if I can't find textload.cfg, I will
+#             use these presets.
+#             Set 1 = ON   0 = OFF.  Other values vary.  
+# This is hopefully a failsafe and should never be consulted
+#  =================================================================
+sub textloadpresets {
+# --------------------- Set Apostrophe Break ------------------------
+# Set to 1 to break words on apostrophe.  Probably 0 for
+# English, 1 for French.  Your milage may vary.
+$breakapost = 0;  
+
+# ------------------------ Define Word Pattern ----------------------
+# What word pattern do you want to use?  This is important.
+# We will want to add optional characters like {[]} for MSS 
+# notation and then set a function to delete these for the index 
+# in order to search across them.  [Note, leave "_" in the
+# second pattern to handle tags in words, etc., see below]
+$CHARSINWORD = "[\&A-Za-z0-9\177-\377][\&A-Za-z0-9\177-\377\_\'ʼ;]*";
+
+# ------------- Define Characters to Exclude from Index words -------
+# Leading to a second list, characters which can be in words
+# but you don't want to index.  I have not implemented this yet.  
+# Need an example.
+$CHARSNOTTOINDEX = "\[\{\]\}";
+
+# ------------------------ Dump Object Table ------------------------
+# SQL div table set, which dumps out a tab delimited line
+# of div level info, philo id, etc.  See below.  Leave this on.
+$printsqldivtable = 1;
+
+# ------------------------ Dump SubDiv Object Table -----------------
+# SQL div table set, which dumps out a tab delimited line
+# of subdiv level info, philo id, etc.  Experimental.  The idea is
+# to generate a table of para level objects, like stage directions
+# and the like in order to search these.  See below.  Leave this on.
+$printsqlsubdivtable = 1;
+
+# ------------------------ Generate Document Word Counts ------------
+# Turn this on to generate a document word count.  This will be
+# used in future for the PhiloLogic frequency package, giving
+# users word counts for documents, and possibly for z-score statistical
+# analysis.
+$genworddocfreq = 1;
+
+# ----------------------- Tag Upper Case Characters -----------------
+# Tag upper case.  This used to be for proper names, but we have
+# used it to tag upper case.   Leave it off unless you really need it.
+# Should be expanded to handle <name tags.
+$taguppercasewords = 0;
+
+# ---------------------- Treat Lines as Sentences --------------------
+# In linegroups, break sentence objects on <l and turn off
+# automatic sentence recognition.  Normally off.
+$lngrpbreaksent = 0;
+
+# ---------------------- Flatten Ligatures for Indexing --------------
+# Convert SGML ligatures to base characters for indexing.  
+# &oelig; = oe.  Leave this on.  At one point we should think
+# Unicode, but who knows if this is important.
+$flattenligatures = 1;
+
+# --------------------- Ignore recursive text divs -------------------
+# Ignore divs in internal texts.  This is for constructs which
+# quoted <q objects as new <text objects.  I have to admit
+# that recursive arguments make sense at a certain level, but 
+# violate my notion of documentary structures.  Recursion is a
+# great programming technique, but as a data representation it 
+# makes things hard.  Leave this ON.
+$ignoredivsinsubtext = 1;
+
+# ---------------------- SubDiv Look Ahead --------------------------
+# When looking ahead to see if you have an immediate lower div,
+# set how many lines to look.  A real XML parser would not need this.
+$LOOKHOWFAR = 10;
+
+# ---------------------- Div Head Look Ahead ------------------------
+# In a <div, how far to look ahead for a <head.  A real XML parser
+# would not need this.
+$HEADLOOKLINES = 7;
+
+# ------------------ Skip in word tags -------------------------------
+# Tags normally break words.  There may be exceptions.  To run the 
+# exception, turn on the exception and list them as patterns.  
+# Tags will not be indexed and will not break words.
+$tagexception = 1;
+@listofexempttags = ('<hi[^>]*>',
+                     '<emph[^>]*>',
+		     '<\/hi>',
+		     '<\/emph>',
+		     '<orig[^>]*>',
+                     '<\/orig>',
+		     '<sic[^>]*>',
+                     '<\/sic>',
+		     '<abbr[^>]*>',
+                     '<\/abbr>',
+		      );
+# This is ugly. I am doing this by looking for these tags with a letter
+# before and after, changing them to "_" and after I get the
+# word, deleting "_".  Leave it off unless you really need it.
+# Note that you need to construct valid perl patterns.  
+
+# -------------------- Ignore DIV0 -----------------------------------
+# <div0  These are used at time to be the root level, often to
+# include the entire document.  Let's give the option to simply
+# ignore them.  Leave it off unless you see div problems, where your
+# top level div is the whole body or text.
+$ignoredivzero = 0;
+
+# ------------------- Build ID reference table -----------------------
+# Build table for handling elements with IDs.   Leave it on.
+$BUILDREFIDTABLE = 1;
+
+# ------------------- Tags and Words to Ignore ------------------------
+# Ignore tags and words.  This is a switch and list of tag/word
+# patterns to change to spaces and ignore.  Reason: the information
+# in the tags are not to be search.  These really should be 
+# milestones ... but the general point may be useful. Calls TagWordDel
+# The listtoignore must be valid patterns.
+$ignoretagswords = 1;
+@listtoignore = ('<mw[^>]*>[^<]*<\/mw>',
+                 '<A DUMMY TO HOLD THE LIST END>');
+
+# ------------------ Hyphenated Word Joiner ----------------------------
+# Softhypen word joiner.  At this time, I'm trying to join
+# words broken by &shy;\n and possibly some additional
+# selected tags.  Could be extended.  Calls JoinHyphenWords
+$joinshywords = 1;
+
+# ------------------ Abbreviation Expander for Indexing. ---------------
+# This is to handle abbreviation tags.  I have seen two types:
+#       <abbr expan="en">&emacr;</abbr>
+#       <abbr expan="Valerius Maximus">Val. Max.</abbr>
+# For now, lets's try the first.  Calls subroutine AbbrevExpand
+$abbrevexpand = 1;
+
+# ----------------- Get Div opener and closer values -------------------
+# This is to add DIV level opener and closer values to the DIV index.
+# Should be left on once it is tinkered with
+$GetDivOpenClose = 1;
+
+#  ----------------- Set Long Word Limit  -------------------
+#  Words greater than 235 characters (bytes) cause an indexing
+#  error.  This sets a limit.  Words are then truncated to fit.
+$LONGWORDLIMIT = 128;
+}
+
+# =================================================================
+# Subroutine: getthisxpath: a simple XPATH generator for divindex
+# and subdivindex files.  Not really used, but it will spit it out
+# if $DUMPXPATHS is set in texload.cfg.  Your mileage will really
+# vary here.
+# =================================================================
+sub getthisxpath() {
+    local ($tag, $w, $genpath);
+    $tag = $_[0];
+    $tag =~ tr/A-Z/a-z/;
+    $genpath = 1;
+    if ($tag =~ /\/ ?>/) {
+	$genpath = 0;
+	}
+    elsif ($tag =~ /<\//) {
+	pop(@listofxpath);
+	$genpath = 1;
+    	}
+    elsif ($tag =~ /<\!/) {
+	$genpath = 0;
+    	}
+    elsif ($tag =~ /<\?/) {
+	$genpath = 0;
+    	}
+    elsif ($tag =~ /^</) {
+	$tag =~ s/<//;
+	$tag =~ s/>//g;	
+	$tag =~ s/ ([a-z0-9]*)="([^"]*)"/\[\@$1="$2"\]/g;
+	push (@listofxpath, $tag);
+	$genpath = 1;
+		}
+    else {
+	$genpath = 0;	
+	}
+
+    if ($genpath) {
+    	$thecurrentxpath = "/";
+        foreach $w (@listofxpath) {          # generate the current path
+             $thecurrentxpath .= "/" . $w;
+          }
+	}
+
+return;
+}
+ 
+
+sub newchunksubdiv {
+	local ($t);
+	$firstidflag = 1;
+#	if ($wordtagflag && ($endid!=$lastendid)) {
+	if ($wordtagflag){
+#	unless (($startid == $laststartid && $endid==$lastendid) | $nowordtags) {
+		$AllRawChunks .= "\t$startid\t$endid";
+		$wordtagflag = 0;
+	}
+	$AllRawChunks .= "\nSUBDIV\t";
+	$t = $docid . ":" . $DIV1 . ":" . $DIV2 . ":" . $DIV3 . ":" . $PARA;
+	$AllRawChunks .= $t . "\t";
+	$laststartid = $startid;
+	$lastendid = $endid;
+	}
+	
+     
+
+##########################################################################
+############################  Notes to Self  #############################
+##########################################################################
+# I have not yet exactly matched the level 2 and 3 data for the first.  
+# I have a kludge.  Needs to be fixed.
+# Important things to think about:
+# -- Inline notes are not handled at all.  Ideally we would exempt
+#    them from processing as part of object, but as they can occur
+#    just anywhere, this is problematic.  One notion would be to simply
+#    defer evaluation of notes until you have complete the document, then
+#    write out the word index data and require structural data as another
+#    <div or <HyperDiv at the end.  This requires removing the index
+#    compression which requires byte order of index.  
+# -- XPATH calculation for SQL <DIV table:  should be easy. Something that 
+#    would  allow forward compatibility for object manipulation.  
+# -- Hyphen and in word tag spanning:  This REALLY should set a flag
+#    to join words in the word handler.  This would be easy.  If flag,
+#    wait to print the word index entry until you get the rest of the
+#    word, and then simply print the entire word with the initial 
+#    object data.  Current mechanism is ugly and won't span things
+#    like hyphen words over page breaks.  Etc.
+# -- The <DIV table is not being used.  I should set it up now to be
+#    an object table with HEADS and types, as avaiable for <sp <speaker,
+#    <lg and other interesting tags.  These would then be related to
+#    standard metadata by a join on the docid.  Probably wait for
+#    interesting data.
+# -- We really, really should have a character registration table.  Alas,
+#    I don't think so at this time.
+# -- Leave hooks for 1) word object type as an integer and 2) flexible
+#    Object Depth.  This way we could say search all except notes, search
+#    only line groups, or stage directions.  Would need a table.  Default
+#    would be search all.
diff -Nuar philomine2/new_philologic_parts/loader.xmake philomine2patched/new_philologic_parts/loader.xmake
--- philomine2/new_philologic_parts/loader.xmake	2008-06-13 16:03:34.000000000 -0500
+++ philomine2patched/new_philologic_parts/loader.xmake	2018-08-04 17:40:47.451958277 -0500
@@ -23,13 +23,13 @@
 STATE= ...inherited...
 CRAPS= ...inherited...
 ECHO= ...inherited...
-EGREP= /usr/bin/grep -E
+EGREP= /bin/grep -E
 CHAROPT=...inherited...
 
 SORT= sort
 
-ICOMPRESS=	enprefix | { /sw/bin/gzip || [ "$$?" = 2 ]; }
-IEXPAND=	/sw/bin/zcat | unprefix
+ICOMPRESS=	enprefix | { /bin/gzip || [ "$$?" = 2 ]; }
+IEXPAND=	/bin/zcat | unprefix
 LEX=		flex
 LEXLIBS=	-lfl
 
@@ -151,7 +151,7 @@
 	$(BEGIN)
 	for f in $(STATE)/letter-*.rawindex; do cat $$f | $(IEXPAND); done | \
 	  indstrip bitlens | uniq -c >$@
-	/sw/bin/gawk '{n+=$$1}END{print n}' $@ | cmp - $(IMAGE)/count || { mv $@ $@.INVALID; false; }
+	/bin/gawk '{n+=$$1}END{print n}' $@ | cmp - $(IMAGE)/count || { mv $@ $@.INVALID; false; }
 	$(END)
 
 ######################################################################
@@ -231,9 +231,9 @@
 	(cd ../search-engine; make search)
 	$(END)
 
-../search-engine/libunpack_e.bundle: ../pack/dbspecs2.h
+../search-engine/libunpack_e.so: ../pack/dbspecs2.h
 	$(BEGIN)
-	(cd ../search-engine; make libunpack_e.bundle)
+	(cd ../search-engine; make libunpack_e.so)
 	$(END)
 
 ######################################################################
@@ -241,12 +241,12 @@
 ######################################################################
 
 
-loadinstall.done: all.index.valid ../search-engine/search ../search-engine/libunpack_e.bundle
+loadinstall.done: all.index.valid ../search-engine/search ../search-engine/libunpack_e.so
 	$(BEGIN)
 	cp ../search-engine/search $(IMAGE)/search2
 	ln -s $(IMAGE)/search2 $(IMAGE)/search_
 	install -m 0755 -d $(IMAGE)/lib
-	cp ../search-engine/libunpack_e.bundle $(IMAGE)/lib
+	cp ../search-engine/libunpack_e.so $(IMAGE)/lib
 	mkdocinfo ../bibliography tomsinfo > $(IMAGE)/docinfo
 	cp all.objects.valid $(IMAGE)/toms/objects
 	mkpagelist $(IMAGE)/pagemarks
@@ -259,7 +259,7 @@
 	cp -R ../installdir/lib $(IMAGE)
 	$(SORT) -rn counts | head -120 | tr -d '\256' | awk '{print $$2}' | $(SORT) | uniq > $(IMAGE)/lib/cluster.filter.wrds
 	awk '{print $$2}' < counts | ../installdir/make_wom_words.R > $(IMAGE)/words.R.wom
-	cp ../installdir/crapser-egrep-2field $(IMAGE)/crapser
+	cp ../installdir/crapser31-egrep-2field $(IMAGE)/crapser31
 	cp countbydocid $(IMAGE)
 	../utils/dividxhashmake.pl < divindex.raw > $(IMAGE)/dividxchild.tab
 	cp divindex.raw $(IMAGE)
diff -Nuar philomine2/new_philologic_parts/search3t philomine2patched/new_philologic_parts/search3t
--- philomine2/new_philologic_parts/search3t	2008-06-16 12:08:31.000000000 -0500
+++ philomine2patched/new_philologic_parts/search3t	2018-08-11 16:55:41.747763807 -0500
@@ -4,7 +4,7 @@
 #
 # $Id: search2t.plin,v 2.11 2004/06/09 20:07:28 o Exp $
 #
-# philologic 2.8 -- TEI XML/SGML Full-text database engine
+# philologic31 2.8 -- TEI XML/SGML Full-text database engine
 # Copyright (C) 2004 University of Chicago
 # 
 # This program is free software; you can redistribute it and/or modify
@@ -23,9 +23,9 @@
 
 no strict "refs";
 # require 5.002;      You can enable this if you want
-$PHILOSITECFG = "${prefix}/etc/philologic";
+$PHILOSITECFG = "${prefix}/etc/philologic31";
 do "$PHILOSITECFG/dbnames";
-do "$PHILOSITECFG/philologic.cfg";
+do "$PHILOSITECFG/philologic31.cfg";
 
 # ======================= Preliminaries ==============================
 # Get the input values and check these. Get database SYSTEM DIR, load
@@ -100,7 +100,7 @@
 	exit;
     }
 
-# Get SYSTEM_DIR from the database names file in /etc/philologic/dbnames
+# Get SYSTEM_DIR from the database names file in /etc/philologic31/dbnames
 # Generic error message if not found.
 $SYSTEM_DIR=$dbnames{"$dbname"};
 if (!$SYSTEM_DIR) {
@@ -1034,9 +1034,9 @@
 # -------------------------------------------------------------------------
 
 # ==========================================================================
-# ==================== WORD/PATTERN EXPANDER (crapser) =====================
+# ==================== WORD/PATTERN EXPANDER (crapser31) =====================
 # ==========================================================================
-# Now we will "expand" the pattern; for this we will run crapser.
+# Now we will "expand" the pattern; for this we will run crapser31.
 # TalktoExpand routine which we call will be talking to 
 # the program through a 2-way pipe.
 
@@ -1053,7 +1053,7 @@
 $word =~ s/(\+)([^#])/$1#?$2/g;
 $word =~ tr/#/\256/;
 
-push (@command, "crapser");
+push (@command, "crapser31");
 @words = split ('\+', $word);
 $nw = $#words + 1;
 
@@ -1099,7 +1099,7 @@
    }
 }
 
-# If we don't get a word back from crapser, then we print the error message,
+# If we don't get a word back from crapser31, then we print the error message,
 # run a similarity search on the word to generate a "Did you mean?" list
 # and exit.
 $testfirstword = $WL[0];
@@ -1450,7 +1450,7 @@
 }
 
 # -----------------------------------------------------------------------
-# TalktoExpand: opens a pipe to crapser, prints the word list and 
+# TalktoExpand: opens a pipe to crapser31, prints the word list and 
 #               listens for a reply.  
 # Called by search2t
 #  -----------------------------------------------------------------------
@@ -1463,7 +1463,7 @@
 pipe (CrapserReads, WeWrite);
 pipe (WeRead, CrapserWrites);	
 
-# (we will talk to crapser through these pipes)
+# (we will talk to crapser31 through these pipes)
 # Many good people got screwed up because they had forgotten
 # to unbuffer their output file descriptors:
 
@@ -1503,7 +1503,7 @@
 
 close (WeWrite);
 
-# And now, let's hear what crapser has got to say:
+# And now, let's hear what crapser31 has got to say:
 
 @WORD_LIST = <WeRead>;
 close (WeRead);
@@ -1591,7 +1591,7 @@
 open RUNSEARCH, "$MVOSEARCHARG";
 
 # and then each of the terms in the word list.  This list comes from above
-# when we ran the crapser/word exploder search.
+# when we ran the crapser31/word exploder search.
 foreach $w (@WL) {
     print RUNSEARCH $w;
     }
diff -Nuar philomine2/philomineload/KDphilominedivload.pl philomine2patched/philomineload/KDphilominedivload.pl
--- philomine2/philomineload/KDphilominedivload.pl	1969-12-31 18:00:00.000000000 -0600
+++ philomine2patched/philomineload/KDphilominedivload.pl	2018-08-13 16:55:31.207166845 -0500
@@ -0,0 +1,862 @@
+#! /usr/bin/perl 
+# ========================  philominedivload.pl  ======================
+# Generates Philomine2 div level counts of lemmas, bigrams,
+# trigrams, bigrams of lemmas and trigrams of lemmas.  Lemmas are
+# generated from the text using TreeTagger. There are a number of
+# things that need to be investigated.  I will document more as we
+# move long.
+# =====================================================================
+
+$dblang = $ARGV[0];
+
+if ($dblang eq "-english") {
+#       	use Alvis::TreeTaggerEnglish;
+	$SPLITONAPOSTROPHE = 0;    # Set on off....
+	}
+elsif ($dblang eq "-french") {
+  # 	use Alvis::TreeTaggerFrench;
+	$SPLITONAPOSTROPHE = 1;    # Set on off....
+	}
+elsif ($dblang eq "-greek") {
+	use DBI;		    # Set on off....
+	$greekflag = 1;
+    $dsn = "dbi:mysql:philologic:localhost";
+	$user = "philologic";
+	$pw = "martini";
+	#	Location of the sqlite greek lexicon database if loaded greektexts
+	$greekdb = "/var/www/artflsrv02/cgi-bin/perseus/GreekLexicon.db";
+}
+else {
+	print "Usage: philominedivload -english/-french -0.01 \n";
+	print "The second argument is the bigram/trigram retain rate, as a percentage\n";
+	print "of the instances.  You want a small number, default - 0.01 percent.\n\n";
+	print "Comment out appropriate English/French module ... we will fix it.\n";
+	exit;
+}
+
+
+if ($ARGV[1]) {
+	$t = $ARGV[1];
+	$t =~ s/\-//;
+	$bigramretain = $t;
+	$trigramretain = $t;
+	}
+else {
+	$bigramretain = 0.01;               # percentage of objects
+	$trigramretain = 0.01;              # percentage of objects
+}
+
+print "Running with parameters $dblang and $bigramretain bi/trigram retain rate.\n";
+print "Have you commented out the appropriate Alvis::TreeTagger function. (y/n);";
+$Answer = <STDIN>;
+if ($Answer =~ /^n/i) {
+	print "\nExiting....\n";
+	exit;
+}
+
+# ==================== Configuration Stuff ==========================
+#      Where to find the docinfo file and the texts.  Default for
+#      standard PhiloLogic installations and loads.
+$rawchunks = "../frequencies/wordfreqdoc/";
+$docinfofile = "../docinfo";
+#      Use the existing cluster.filter.wrds or specify one you want.
+$filterwords = "../lib/cluster.filter.wrds";
+# Here just in case.
+$CHARSINWORD = "[\&A-Za-z\177-\377][\&A-Za-z\177-\377\_\';]*";
+# We think treetagger is trained to accept case sensitive, so
+# set case handling. 1 will flatten case.  I am flattening case
+# on output for lemmas and words.
+$FLATTENCASE = 0;
+#     Normal stuff.....
+$SORT = "/usr/bin/sort";
+$GREP = "/usr/bin/grep";
+$TR = "/usr/bin/tr";
+$AWK = "/sw/bin/awk";
+$ObjOutDir = "alldivobjects/";
+$ObjDataFile = ".freqbyobject.dat";
+$ObjDataIndex = ".freqbyobject.idx";
+#     List of directories to look for, etc.
+@dirs = qw(tmp/ alldivobjects/);
+@outputtypes = qw(words lemmas bigrams trigrams bilemmas bigrams);
+
+#========================== End Configuration =========================
+# Of course, you may need to hack further down, but let's now worry abou
+# that now.
+# =====================================================================
+# List of subroutines......
+# =====================================================================
+
+#======================== Program starts here =========================
+print "Starting Philominedivload for Div Level Ojbects...\n";
+&prelimiaries();  # sets @files2read, $filterwords, creates directories
+                  # checks for certain files and directories.
+# ======================== Main Loop ==================================
+# Main Loop:  
+# -- Read in the file, fix it in various ways (fixwordsinobject), 
+# -- generate a list of lemmas in the object, which comes back as
+#    TreeTagger format which is massaged to a stream of lemmas (getlemmas).
+# -- Count store lemmas for each document: mklemmafreq 
+# -- Convert $wordsinobject into the same stream as lemmas: mkwordvector
+# -- Then for each type of "GRAM" generate a frequency list and
+#    store it in a file.
+# -- And we're done, so loop through all the documents.... more below
+# --------------------------------------------------------------------- 
+$philodocid = 0;
+
+unless ($greekflag) {
+	$ttcounter = 0;
+	&Alvis::Treetagger::reopen();
+	}
+foreach $filename (@files2read) {
+	$wordsinobject = "";
+	$lemmasinobject = "";
+	$FoundFirstDiv = 0;
+	$wordsthisdoc = &readfile2buffer($filename);
+	$wordsthisdoc = &MergeDivText($wordsthisdoc);     # MVO patch 02-12-08
+	$wordsthisdoc = &MakeDocs2Divs($wordsthisdoc);
+	@thewholething = split("\n", $wordsthisdoc);
+	unless ($greekflag) {
+ 		$ttcounter++;       
+		if ($ttcounter > 50) {
+        		&Alvis::Treetagger::reopen();
+			$ttcounter = 0;
+			}
+	}
+	foreach $wordsinobject (@thewholething) {
+		 #print "\n\n\n" . $wordsinobject . "\n\n\n";
+		$wordsinobject = &fixwordsinobject($wordsinobject);
+		 #print "\n\n\n" . $wordsinobject . "\n\n\n";
+		$lemmasinobject = &getlemmas($wordsinobject);
+		 #print $lemmasinobject . "\n\n\n";
+		$wordsinobject = &mkwordvector($wordsinobject);
+		 #print "On to frequencies!\n";
+		&mkwordfreq($wordsinobject);
+		&mklemmafreq($lemmasinobject);
+                &mkrawngrams($wordsinobject, "bigrams");
+#                &mkrawngrams($wordsinobject, "trigrams");
+                &mkrawngrams($lemmasinobject, "bilemmas");
+#                &mkrawngrams($lemmasinobject, "trilemmas");
+		$TotalNumberofObjects++;
+     		}
+	$philodocid++;
+	}
+# ======================== End Main Loop ==============================
+#
+# ======= Accumulate ngram frequencies and prune ngrams ===============
+# At this point we have 5 directories with frequency lists for
+# lemmas, bigrams, trigrams, bilemmas, trilemmas, named 
+# PHILODOCID.rewfreq.  But all of the "grams" are very spare.  So we
+# now read through all of the gram files, count them up, and then
+# prune each GRAM file of ones that do not occur in more than 
+# a set percentage of documents.  This is simply to save time and
+# space and obviously only happens once.  At the end.
+# ---------------------------------------------------------------------
+&accumulate("bigrams");
+&prunegrams("bigrams", $bigramretain);
+#&accumulate("trigrams");
+#&prunegrams("trigrams", $trigramretain);
+&accumulate("bilemmas");
+&prunegrams("bilemmas", $bigramretain);
+#&accumulate("trilemmas");
+#&prunegrams("trilemmas", $trigramretain);
+# Clean-up here.....
+# 
+print "\n\nSHOULD BE DONE.  CHECK YOUR OUTPUT! \n\n";
+# ========================== End of Program =========================
+
+# ===================================================================
+#                            SUBROUTINES 
+#===================================================================
+sub MergeDivText {
+        local ($rtn, $lin, $buf);
+        $buf = $_[0];
+        $buf =~ s/\n  +/\t/g;
+return ($buf);
+}
+
+sub MakeDocs2Divs {
+        local ($buf, $x, $p, $y, $rtn, $r, $l, $thisdiv);
+        local ($h1, $h2, $h3);
+        $buf = $_[0];
+        @r = split("\n", $buf);
+        foreach $l (@r) {
+                if ($l =~ m/^DIV/) {
+                        @p = split("\t", $l);
+                        if ($thisdiv) {
+                                $thisdiv .= "\n";
+                                $rtn .= $thisdiv;
+                                }
+                        $thisdiv = $p[1] . "\t" . $p[2] . " ";;
+                        }
+                elsif ($l =~ m/^SUBDIV/) {
+                        @p = split("\t", $l);
+                        $thisdiv .= $p[2];
+                        }
+                else {
+                         print "Words out of Div: $l \n";
+                        }
+                if ($greekflag && $thisdiv) {
+                #	$greekstartid=$p[3];
+                #	$greekendid=$p[4];
+                	$thisdiv .= "\t" . $p[3] . "\t" . $p[4] . " ";
+                	}
+                }
+
+
+        if ($thisdiv) {
+                $thisdiv .= "\n";
+                $rtn .= $thisdiv;
+                }
+return $rtn;
+}
+
+
+sub prunegrams {
+        local ($type, $filelist, $pat, $file, $percent, $nofdocs);
+        local ($mindoccount, $totalfile, $lin, $docs, $freq, $ngram);
+        local ($c, $outfile, $ngramstokeep, $buffer, $doc, $outfile);
+	local ($infile, $thisid);
+        $type = $_[0];
+        $percent = $_[1];
+        $percent = $percent / 100;
+        $nofdocs = $TotalNumberofObjects;
+        $mindoccount = int($nofdocs * $percent);
+        print "Total Number of Objects = $TotalNumberofObjects \n";
+        print "Pruning $nofdocs documents in $type.\n";
+        print "Retain ngrams in $percent percent of documents\n";
+        print "Minimum document count = $mindoccount \n";
+        $totalfile = $ObjOutDir . $type . ".totalinobjects";
+        open(INFILE, $totalfile)  or die "Error opening $totalfile\n";
+        while ($lin = <INFILE>) {
+                chop($lin);
+                ($docs, $ngram) = split(" ", $lin);
+                if ($docs >= $mindoccount) {
+                        $ngramstokeep{$ngram} = $docs;
+                        $c++;
+                        }
+        	}
+        close (INFILE);
+        print "Kept $c ngrams.\n";
+	$infile = $ObjOutDir . $type . $ObjDataFile;
+	open(INFILE, $infile) or die "Error opening $infile\n";
+	$outfile = $infile . ".pruned";
+	open(OUT, ">", $outfile) or die "Error opening $outfile\n";
+	while ($lin = <INFILE>) {
+		chop($lin);
+		$lin =~ s/^([^\t]*)\t//;
+		$buffer = $1 . "\t";
+		$lin =~ s/\|/\t/g;
+		@r = split("\t", $lin);
+                foreach $p (@r) {
+                        ($gram, $frq) = split(" ", $p);
+                	if ($ngramstokeep{$gram} > 1) {
+                                $buffer .= $gram . " " . $frq . "|";
+                                }
+                        }
+		$buffer .= "\n";
+		$buffer =~ s/\|\n/\n/;
+		print OUT $buffer;
+                $buffer = "";
+                }
+	close (INFILE);
+	close (OUT);
+	system ("rm $infile");
+	system ("mv $outfile $infile");
+	undef (%ngramstokeep);
+
+	print "Generating Object counts and index for $type \n";
+	open (INFILE, $infile)  or die "Error opening $infile\n";
+	$thisindexfile = $ObjOutDir . $type . $ObjDataIndex;
+	open (INDEXOUT, ">", $thisindexfile) or die "Error: $thisindexfile\n";
+	$countfile = $ObjOutDir . $type . "." . "count.byobject";
+	open (COUNTOUT, ">", $countfile) or die "Error opening $countfile\n";
+	$byteoffset = 0;
+	while ($lin = <INFILE>) {
+		$span = length($lin);
+		chop($lin);
+                $lin =~ s/^([^\t]*)\t//;
+		$thisdocid = $1;
+		$lin =~ s/\|/\t/g;
+		@r = split("\t", $lin);
+		$count = $#r + 1;
+		print INDEXOUT $thisdocid." ".$byteoffset." ".$span. "\n";
+		$byteoffset = $byteoffset + $span;
+		print COUNTOUT $thisdocid . " " . $count . "\n"; 
+		}
+	close (INFILE);
+	close (INDEXOUT);
+	close (COUNTOUT);
+		
+}
+
+#==================================================================
+# Subroutine: accumlate
+#==================================================================
+sub accumulate {
+        local ($type, $outfile, $infile, $bighash, $lin);
+	local ($r, $p, $gram, $frq, $x, $thecommand);
+	$type = $_[0];
+	$infile = $ObjOutDir . $type . $ObjDataFile;
+	$outfile = $ObjOutDir . $type . ".totalinobjects";
+	$thecommand = "cat " . $infile . " | ";
+	$thecommand .= " ./divaccumhelper.pl | sort | uniq -c | ./lowfreqfilter.pl ";
+	$thecommand .= " > " . $outfile ;
+        print "Accumulating $type from $infile writing to $outfile (this may take a while).";
+	print "\nSystem: $thecommand \n";
+	system("$thecommand");
+	print "\nDone.\n";
+}
+
+#==================================================================
+# Subroutine: mkrawngrams
+#==================================================================
+sub mkrawngrams {
+	local ($list, $type, $w, $wl, $f, $lastword, $span);
+	local ($buffer, $ngramhash, $types, $tokens, $trigram);
+	local ($secondword, $thisfile, $fsize1, $fsize2);
+	$list = $_[0];
+	$type = $_[1];
+#	print $list;
+	$span = 2;
+	if ($type eq "bigrams" || $type eq "bilemmas") {
+		$span = 2;
+		}
+	if ($type eq "trigrams" || $type eq "trilemmas") {
+		$span = 3;
+		}
+	@wl = split("\n", $list);	
+	foreach $w (@wl) {
+		if ($filterwords{$w} == 1) {	
+			$w = "";
+			}
+		if (length($w) < 2) {
+			$w = "";
+			}
+		if ($w =~ /[A-Za-z\177-\377]/) {
+			$tokens++;
+			if ($span == 2) {
+			     if ($lastword) {
+				$bigram = $lastword . "_" . $w;
+				$ngramhash{$bigram} += 1;
+				}
+			     $lastword = $w;
+			     }
+			if ($span == 3) {
+			     if ($secondword && $lastword) {
+			        $trigram = $lastword . "_" . $secondword;
+				$trigram .= "_" . $w;
+				$ngramhash{$trigram} += 1;
+				}
+			     $lastword = $secondword;
+			     $secondword = $w;
+			     }
+			}
+		}
+	$buffer = $DIVIDENTIFIER . "\t";;
+        foreach $w (sort keys (%ngramhash)) {
+                $types++;
+		$tokens += $ngramhash{$w};
+                $buffer .= $w . " " . $ngramhash{$w} . "|";
+		delete $ngramhash{$w};
+        	}
+        $buffer .= "\n";
+
+	$thisfile = $ObjOutDir . $type . $ObjDataFile;
+	open (OUT, ">>", $thisfile) or die "Error opening $thisfile\n";
+	print OUT $buffer;
+	close (OUT);
+	print "Wrote $types to $thisfile for DIV $DIVIDENTIFIER\n";
+return;
+}
+#==================================================================
+# Subroutine: mkwordvector
+#==================================================================
+sub mkwordvector {
+	local ($words, $wordlist, $w, $rtn);
+	$words = $_[0];
+	$words =~ s/\n/ /g;
+	$words =~ s/\015//g;
+	$words =~ s/($CHARSINWORD)/\n$1\n/g;
+# Flatten case here, since we always want them flat, whereas treetagger likes case.
+        $words =~ tr/A-Z/a-z/;
+        $words =~ s/\xc3([\x80-\x9E])/&up2low($1)/ge;
+        if ($SPLITONAPOSTROPHE) {
+                $words =~ s/\'/\n/g;
+                }
+	@wordlist = split("\n", $words);
+	foreach $w (@wordlist) {
+		$rtn .= $w . "\n";
+		}
+	undef @wordlist;
+return $rtn;
+}
+
+#==================================================================
+# Subroutine: mklemmafreq
+#==================================================================
+sub mklemmafreq {
+	local ($w, $wl, $type, $token, $whash, $lemmalist, $thisfile);
+	local ($buf, $span, $fsize1, $fsize2, $thisindexfile);
+	local ($countfile);
+	$lemmalist = $_[0];
+	@wl = split("\n", $lemmalist);
+	foreach $w (@wl) {
+		$whash{$w} += 1;
+		}
+	$buf = $DIVIDENTIFIER . "\t";
+	foreach $w (sort keys (%whash)) {
+		$buf .= "$w $whash{$w}|";
+		$type++;
+		$token += $whash{$w};
+		delete $whash{$w};
+		}
+	$buf .= "\n";
+	$thisfile = $ObjOutDir . "lemmas" . $ObjDataFile;
+	$thisindexfile = $ObjOutDir . "lemmas"  . $ObjDataIndex;
+	$fsize1 = -s ($thisfile);
+	if (!$fsize1) {
+		$fsize1 = "0";
+		}
+	open (LEM, ">>", $thisfile) or die "Error opening $thisfile\n";
+	print LEM $buf;
+	close (LEM);
+	$fsize2 = -s ($thisfile);
+	print "Wrote $type lemmas to $thisfile for DIV $DIVIDENTIFIER\n";
+	open (LEM, ">>", $thisindexfile) or die "Error open $thisindexfile\n";
+	$span = $fsize2 - $fsize1;
+	print LEM "$DIVIDENTIFIER $fsize1 $span\n";
+	print "Print IDX file = $DIVIDENTIFIER $fsize1 $span\n";
+	close (LEM);
+	$countfile = $ObjOutDir . "lemmas." . "count.byobject";
+	open (LEM, ">>", $countfile) or die "Error opening $countfile\n";
+	print LEM $DIVIDENTIFIER . "\t" . $token . "\n";
+	close (LEM);
+}
+
+#==================================================================
+# Subroutine: mkwordfreq
+#==================================================================
+sub mkwordfreq {
+        local ($w, $wl, $type, $token, $whash, $wordlist, $thisfile);
+        local ($buf, $span, $fsize1, $fsize2, $thisindexfile);
+        local ($countfile);
+        $wordlist = $_[0];
+        @wl = split("\n", $wordlist);
+        foreach $w (@wl) {
+		if ($w =~ /[a-zA-Z\177-\377]/) {
+                	$whash{$w} += 1;
+			}
+                }
+        $buf = $DIVIDENTIFIER . "\t";
+        foreach $w (sort keys (%whash)) {
+                $buf .= "$w $whash{$w}|";
+                $type++;
+                $token += $whash{$w};
+                delete $whash{$w};
+                }
+        $buf .= "\n";
+        $thisfile = $ObjOutDir . "words" . $ObjDataFile;
+        $thisindexfile = $ObjOutDir . "words"  . $ObjDataIndex;
+        $fsize1 = -s ($thisfile);
+        if (!$fsize1) {
+                $fsize1 = "0";
+                }
+        open (LEM, ">>", $thisfile) or die "Error opening $thisfile\n";
+        print LEM $buf;
+        close (LEM);
+        $fsize2 = -s ($thisfile);
+        print "Wrote $type words to $thisfile for DIV $DIVIDENTIFIER\n";
+        open (LEM, ">>", $thisindexfile) or die "Error open $thisindexfile\n";
+        $span = $fsize2 - $fsize1;
+        print LEM "$DIVIDENTIFIER $fsize1 $span\n";
+        print "Print IDX file = $DIVIDENTIFIER $fsize1 $span\n";
+        close (LEM);
+        $countfile = $ObjOutDir . "words." . "count.byobject";
+        open (LEM, ">>", $countfile) or die "Error opening $countfile\n";
+        print LEM $DIVIDENTIFIER . "\t" . $token . "\n";
+        close (LEM);
+}
+
+		
+#==================================================================
+# Subroutine: getlemmas.  
+# IMPORTANT: In cases where we get 2 resolutions for a lemma, I
+# am taking the first.  This is probably not a great idea.  TreeTagger
+# does not disambiguate everything.
+#==================================================================
+sub getlemmas {
+	local ($wordlist, $thecommand, $lin, $lemme, $pos, $surface);
+	local ($words, $a, $b, $w, $rtn, $ttout, $lin, $tt, $sentences, $sent);
+	$words = $_[0];
+    if ($greekflag){
+	#connect to sqlite database
+	$dbh = DBI->connect("DBI:SQLite:dbname=$greekdb", '','', {AutoCommit , 1}) or die "ACK: couldn't connect to sqlite - $!";
+	print "In getlemmas, using range $greekstartid - $greekendid\n";
+	foreach ($id=$greekstartid; $id<=$greekendid; $id++) {
+#		print "Foreach getlemmas loop, id is $id\n";
+		$lemme = &LemmaFinder($id);
+		if ($lemme) {
+			$rtn .= $lemme . "\n";
+			}
+		}
+	if ($FLATTENCASE) {
+		$rtn = &greekup2low($rtn);
+	}
+	undef @ids;
+    }
+    else {
+	$words =~ s/\.\.\./ /g;
+	$words =~ s/([\.,;:!\?\)\]\(\[])/ $1 /g;
+	$words =~ s/\n/ /g;
+	$words =~ s/  */ /g;
+	$words =~ s/\'/\' /g;
+	$words =~ s/aujourd' +hui/aujourd'hui/g;
+	$words =~ s/entr' +/entr'/g;
+	$words =~ s/([\xC2\xC3])([\x80-\xBF])/chr(ord($1)<<6&0xC0|ord($2)&0x3F)/eg;
+	$words =~ s/\./\. \n/g;
+	$words =~ s/ (.)\. \n/$1\. /g;
+	$words =~ s/ (mme)\. \n/$1\. /g;
+     	@sentences = split ("\n", $words);
+     	foreach $sent (@sentences) {
+	   if ($sent =~ m/[a-zA-Z\177-\377]/) {
+		$sent .= "  XXXENDTAGGINGXXX \n";
+		$l = length($sent);
+		if ($l > 8000) {
+			print "\nSENTENCE TOO LONG: $l BYTES  TRUNCATING TO 8000\n";
+			$sent = "SENTTOOLONG " . substr($sent, 0, 8000);
+			$sent .= " .  XXXENDTAGGINGXXX \n";
+			$l = length($sent);
+			}
+	#	print "\nIN L=$l: $sent";
+		$ttout = &Alvis::Treetagger::tag($sent);
+      		$ttout =~ s/([\x80-\xFF])/chr(0xC0|ord($1)>>6).chr(0x80|ord($1)&0x3F)/eg;
+        	@tt = split("\n", $ttout);
+		foreach $lin (@tt) {
+			$lin =~ s/\015//g;
+	#		print $lin . "\n";
+		        ($surface, $pos, $lemme) = split("\t", $lin);
+                	if ($lemme eq "<unknown>") {
+                        	$lemme = $surface;
+                        	}
+                	if ($lemme eq "\@card\@") {
+                        	$lemme = "";
+                        	}
+                	if ($pos =~ /SENT/ || $pos =~ /PUN/) {
+                        	$lemme = "";
+                        	}
+                	if ($lemme) {
+                        	$lemme = lc($lemme);
+                        	$lemme =~ s/\xc3([\x80-\x9E])/&up2low($1)/ge;
+                        	if ($lemme =~ /\|/) {
+                                	$lemme =~ s/\|/\t/g;
+                                	($a, $b) = split("\t", $lemme);
+                                	$lemme = $a;
+                                	}
+                        if ($lemme =~ m/([A-Za-z\177-\377]*)/) {
+                                $lemme = $1;
+                                }
+                        else {
+                                $lemme = "";
+                                }
+# May need more cleaning here too.
+                        if ($lemme) {
+                                push (@wordlist, $lemme);
+                                }
+                        }
+                }
+            }
+	}
+        foreach $w (@wordlist) {
+                $rtn .= $w . "\n";
+                }
+        undef @wordlist;
+    }
+return $rtn;
+}
+
+# $words = `echo "$words" | iconv -t ISO-8859-1 -f UTF-8`;
+# $words =~ s/\xc3(.)/$1/g;
+# $words =~ s/([\xC2\xC3])([\x80-\xBF])/chr(ord($1)<<6&0xC0|ord($2)&0x3F)/eg;
+# $wordlist = `echo "$wordlist" | iconv -f ISO-8859-1 -t UTF-8`;
+# $wordlist =~ s/([\x80-\xbf])/\xc3$1/g;
+# $wordlist =~ s/([\x80-\xFF])/chr(0xC0|ord($1)>>6).chr(0x80|ord($1)&0x3F)/eg;
+
+#==================================================================
+# Subroutine: fixwordsinobject
+#==================================================================
+sub fixwordsinobject {
+	local ($wordsinobject, $w);
+	$w = $_[0];
+	if ($w =~ s/([0-9]+)\t([0-9]+)//gi){
+		$greekstartid=$1;
+		$greekendid=$2;
+		}
+	else {
+		$greekstartid=0;
+		$greekendid=0;
+	}
+#	print $w . "\n";
+	($DIVIDENTIFIER, $wordsinobject) = split("\t", $w, 2);
+	print "IDS: $greekstartid - $greekendid\n";
+	$wordsinobject =~ s/<NEWLINE>/\n/g;
+        $wordsinobject = charents2utf8($wordsinobject);
+	if ($FLATTENCASE) {
+        	$wordsinobject =~ tr/A-Z/a-z/;
+        	$wordsinobject =~ s/\xc3([\x80-\x9E])/&up2low($1)/ge;
+             	if ($dblang eq "-greek") {
+              		$wordsinobject = &greekup2low($wordsinobject);
+              		}
+		}
+	if ($dblang eq "-greek") {
+#	      if ($wordsinobject =~ s/\t([0-9]*)\t([0-9]*)\n/ \n/gi){
+#	      	($greekstartid, $greekendid) = ($1, $2);
+#	      	}
+	      $wordsinobject =~ s/\xe2\x80[\x9c\x9d]/ /g; #curly quotes
+              $wordsinobject =~ s/([a-z])-([a-z])/$1 $2/gi;
+      	      $wordsinobject =~ s/[\.\,\?\(\)\:\;\"\!\*\'\`\[\]|]/ /g;
+      	      $wordsinobject =~ s/ +/ /gi;
+	      }
+        $wordsinobject =~ s/<[^>]*>/ /g;
+        $wordsinobject =~ s/\&[^;]*;/ /g;
+        $wordsinobject =~ s/;/ /g;
+        $wordsinobject =~ s/\-/ /g;
+	$wordsinobject =~ s/[0-9]/ /g;
+	$wordsinobject =~ s/\"/ /g;
+	$wordsinobject =~ s/\xe2\x80\x91/ /g; # Windows Hyphen.
+	$wordsinobject =~ s/\xe2\x80\x94/ /g; # Another Oddball
+return ($wordsinobject);
+}
+
+#==================================================================
+# Subroutine: readfile2buffer
+#==================================================================
+sub readfile2buffer {
+	local ($filename, $thisfile, $inthetext, $lin, $rtn);
+	$filename = $_[0];
+	$thisfile = $rawchunks . $filename;
+	$inthetext = 0;
+	print "=====================================\n";
+	print "Reading $philodocid: $filename ... \n";
+	print "=====================================\n";
+	open (DOC, $thisfile) or die "Cannot open $thisfile!\n";
+	while ($lin = <DOC>) {
+		if (length($lin) > 5) {
+                	$rtn .= $lin;
+			}
+             }
+	close (DOC);
+return ($rtn);
+}
+
+#==================================================================
+# Subroutine: preliminaries, just to get things rolling.
+#==================================================================
+sub prelimiaries {
+     local ($c, $lin, $dir, $thischunkfile, $cstring);
+
+     #die "Cannot find $loadedtextdir " unless -d $loadedtextdir;
+
+     open (DOCFILE, $docinfofile) or die "Cannot open $docinfofile!\n";
+     while ($lin = <DOCFILE>) {
+	     $cstring = $c;
+	     if (!$cstring) {
+		  $cstring = "0";
+		  }
+	     $thischunkfile = $cstring . ".rawchunks";
+             push (@files2read, $thischunkfile);
+	     # print "$thischunkfile \n";
+             $c++;
+             }
+     close(DOCFILE);
+     print "Generated $c chunk file names\n";
+     $c = 0;
+     open (FILTERWORDS, $filterwords) or die "Cannot open $filterwords!\n";
+     while ($lin = <FILTERWORDS>) {
+             chop($lin);
+             $filterwords{$lin} = 1;
+	     if ($lin =~ m/'/) {
+		$lin =~ s/\'//g;
+             	$filterwords{$lin} = 1;
+		$c++;
+		}
+     	     $c++;
+             }
+     close (FILTERWORDS);
+     print "Read in $c filter words from $filterwords\n";
+     
+     foreach $dir (@dirs) {
+             mkdir($dir) unless -d $dir;
+     	     }
+     return;
+}
+
+#==================================================================
+# Subroutine: up2low, try to lower case French accents.  I'm sure
+# there is a better way.
+#==================================================================
+sub up2low {
+      local ($onechar, $rtn);
+      $onechar = $_[0];
+      $onechar =~ tr/\x80-\x9E/\xA0-\xBE/;
+      $rtn = "\xc3" . $onechar;
+return $rtn;
+}
+
+#==================================================================
+# greekup2low: greekup2low, try to lower case Greek letters. It works,
+# but is a bit messy
+#==================================================================
+sub greekup2low {
+	my $line = lc($_[0]);
+
+    #Upper to Lowercase
+	$line =~ s/\xce\x91/\xce\xb1/gi;
+	$line =~ s/\xce\x92/\xce\xb2/gi;
+	$line =~ s/\xce\x93/\xce\xb3/gi;
+	$line =~ s/\xce\x94/\xce\xb4/gi;
+	$line =~ s/\xce\x95/\xce\xb5/gi;
+	$line =~ s/\xce\x96/\xce\xb6/gi;
+	$line =~ s/\xce\x97/\xce\xb7/gi;
+	$line =~ s/\xce\x98/\xce\xb8/gi;
+	$line =~ s/\xce\x99/\xce\xb9/gi;
+	$line =~ s/\xce\x9a/\xce\xba/gi;
+	$line =~ s/\xce\x9b/\xce\xbb/gi;
+	$line =~ s/\xce\x9c/\xce\xbc/gi;
+	$line =~ s/\xce\x9d/\xce\xbd/gi;
+	$line =~ s/\xce\x9e/\xce\xbe/gi;
+	$line =~ s/\xce\x9f/\xce\xbf/gi;
+	$line =~ s/\xce\xa0/\xcf\x80/gi;
+	$line =~ s/\xce\xa1/\xcf\x81/gi;
+	$line =~ s/\xce\xa3( |$)/\xcf\x82$1/gi;
+	$line =~ s/\xce\xa3/\xcf\x83/gi;
+	$line =~ s/\xce\xa4/\xcf\x84/gi;
+	$line =~ s/\xce\xa5/\xcf\x85/gi;
+	$line =~ s/\xce\xa6/\xcf\x86/gi;
+	$line =~ s/\xce\xa7/\xcf\x87/gi;
+	$line =~ s/\xce\xa8/\xcf\x88/gi;
+	$line =~ s/\xce\xa9/\xcf\x89/gi;
+	$line =~ s/\xe1\xbf[\xa4\xa5]/\xcf\x81/gi; ## rhos
+	$line =~ s/\xe1\xbf\xac/\xcf\x81/gi;
+	
+	$line = Encode::decode("utf8", $line);	
+	$line =~ tr/\x{1F08}-\x{1F0F}/\x{1F00}-\x{1F07}/; ## alphas
+	$line =~ tr/\x{1F88}-\x{1F8F}/\x{1F80}-\x{1F87}/;
+	$line =~ tr/\x{0386}\x{1FBC}\x{1FB8}-\x{1FBB}/\x{03AC}\x{1FB3}\x{1FB0}\x{1FB1}\x{1F70}\x{1F71}/;
+	$line =~ tr/\x{1F18}-\x{1F1D}/\x{1F10}-\x{1F15}/; ## epsilons
+	$line =~ tr/\x{1FC8}\x{1FC9}\x{0388}/\x{1F72}\x{1F73}\x{03AD}/;
+	$line =~ tr/\x{1F28}-\x{1F2F}/\x{1F20}-\x{1F27}/; ## etas
+	$line =~ tr/\x{1F98}-\x{1F9F}/\x{1F90}-\x{1F97}/;
+	$line =~ tr/\x{0389}\x{1F74}\x{1FCA}-\x{1FCC}/\x{03AE}\x{1FB0}\x{1F74}\x{1F75}\x{1FC3}/;
+	$line =~ tr/\x{1F38}-\x{1F3F}/\x{1F30}-\x{1F37}/; ## iotas
+	$line =~ tr/\x{03AA}\x{038A}\x{1FD8}-\x{1FDB}/\x{03CA}\x{03AF}\x{1FD0}\x{1FD1}\x{1F76}\x{1F77}/;
+	$line =~ tr/\x{1F48}-\x{1F4D}/\x{1F40}-\x{1F45}/; ## omicrons
+	$line =~ tr/\x{1FF8}\x{1FF9}\x{038C}/\x{1F78}\x{1F79}\x{03CC}/;
+	$line =~ tr/\x{1F58}-\x{1F5F}/\x{1F50}-\x{1F57}/; ## upsilons
+	$line =~ tr/\x{1FE8}-\x{1FEB}\x{038E}\x{03AB}/\x{1FE0}\x{1FE1}\x{1F7A}\x{1F7B}\x{03CB}\x{03CC}/;
+	$line =~ tr/\x{1F68}-\x{1F6F}/\x{1F60}-\x{1F67}/; ## omegas
+	$line =~ tr/\x{1FA8}-\x{1FAF}/\x{1FA0}-\x{1FA7}/;
+	$line =~ tr/\x{038F}\x{2126}\x{1FFA}-\x{1FFC}/\x{03CE}\x{03C9}\x{1FF2}\x{1FF4}\x{1FF3}/;
+	return Encode::encode("utf8", $line);
+}
+
+#==================================================================
+# Subroutine: LemmaFinder, retrieve lemma from sqlite database,
+# given a wordid (make sure you are using the correct database)
+#==================================================================
+sub LemmaFinder {
+	$wordid = $_[0];
+	my $lemma;
+	$parsequery = $dbh->prepare("select * from parses where tokenid=\"$wordid\" order by prob desc limit 1;");
+	$parsequery->execute();
+	my $parse = $parsequery->fetchrow_hashref();
+	if ($parse->{lex}){
+		$lexid = $parse->{lex};
+		$lemmaquery = $dbh->prepare("select lemma from Lexicon where lexid=\"$lexid\";");
+		$lemmaquery->execute();
+		$lemma = $lemmaquery->fetchrow_array();	
+	}
+	else {
+		$lemma = $parse->{lemma};
+	}
+	
+	if ($lemma eq "<unknown>") {
+		$tokenquery = $dbh->prepare("select content from tokens where tokenid=\"$wordid\";");
+		$tokenquery->execute();
+		$lemma = $tokenquery->fetchrow_array();
+	}
+#	print $lemma . " ";
+	return $lemma;
+
+} 
+
+#==================================================================
+# Subroutine: charents2utf8, convert ents to utf-8.
+#==================================================================
+sub charents2utf8 () {
+     local ($theword); 
+     $theword = $_[0];
+     $theword =~ s/\&Agrave;/\xc3\x80/g; 
+     $theword =~ s/\&Aacute;/\xc3\x81/g; 
+     $theword =~ s/\&Acirc;/\xc3\x82/g;
+     $theword =~ s/\&Atilde;/\xc3\x83/g;
+     $theword =~ s/\&Auml;/\xc3\x84/g;
+     $theword =~ s/\&Aring;/\xc3\x85/g;
+     $theword =~ s/\&Ccedil;/\xc3\x87/g;
+     $theword =~ s/\&Egrave;/\xc3\x88/g;
+     $theword =~ s/\&Eacute;/\xc3\x89/g;
+     $theword =~ s/\&Ecirc;/\xc3\x8A/g;
+     $theword =~ s/\&Euml;/\xc3\x8B/g;
+     $theword =~ s/\&Igrave;/\xc3\x8C/g;
+     $theword =~ s/\&Iacute;/\xc3\x8D/g;
+     $theword =~ s/\&Icirc;/\xc3\x8E/g;
+     $theword =~ s/\&Iuml;/\xc3\x8F/g;
+     $theword =~ s/\&ETH;/\xc3\x90/g;
+     $theword =~ s/\&Ntilde;/\xc3\x91/g;
+     $theword =~ s/\&Ograve;/\xc3\x92/g;
+     $theword =~ s/\&Oacute;/\xc3\x93/g;
+     $theword =~ s/\&Ocirc;/\xc3\x94/g;
+     $theword =~ s/\&Otilde;/\xc3\x95/g;
+     $theword =~ s/\&Ouml;/\xc3\x96/g;
+     $theword =~ s/\&#215;/\xc3\x97/g; # MULTIPLICATION SIGN
+     $theword =~ s/\&Oslash;/\xc3\x98/g;
+     $theword =~ s/\&Ugrave;/\xc3\x99/g;
+     $theword =~ s/\&Uacute;/\xc3\x9A/g;
+     $theword =~ s/\&Ucirc;/\xc3\x9B/g;
+     $theword =~ s/\&Uuml;/\xc3\x9C/g;
+     $theword =~ s/\&Yacute;/\xc3\x9D/g;
+     $theword =~ s/\&THORN;/\xc3\x9E/g;
+     $theword =~ s/\&agrave;/\xc3\xA0/g;
+     $theword =~ s/\&aacute;/\xc3\xA1/g;
+     $theword =~ s/\&acirc;/\xc3\xA2/g;
+     $theword =~ s/\&atilde;/\xc3\xA3/g;
+     $theword =~ s/\&auml;/\xc3\xA4/g;
+     $theword =~ s/\&aring;/\xc3\xA5/g;
+     $theword =~ s/\&ccedil;/\xc3\xA7/g;
+     $theword =~ s/\&egrave;/\xc3\xA8/g;
+     $theword =~ s/\&eacute;/\xc3\xA9/g;
+     $theword =~ s/\&ecirc;/\xc3\xAA/g;
+     $theword =~ s/\&euml;/\xc3\xAB/g;
+     $theword =~ s/\&igrave;/\xc3\xAC/g;
+     $theword =~ s/\&iacute;/\xc3\xAD/g;
+     $theword =~ s/\&icirc;/\xc3\xAE/g;
+     $theword =~ s/\&iuml;/\xc3\xAF/g;
+     $theword =~ s/\&eth;/\xc3\xB0/g;
+     $theword =~ s/\&ntilde;/\xc3\xB1/g;
+     $theword =~ s/\&ograve;/\xc3\xB2/g;
+     $theword =~ s/\&oacute;/\xc3\xB3/g;
+     $theword =~ s/\&ocirc;/\xc3\xB4/g;
+     $theword =~ s/\&otilde;/\xc3\xB5/g;
+     $theword =~ s/\&ouml;/\xc3\xB6/g;
+     $theword =~ s/\&#247;/\xc3\xB7/g;   #  DIVISION SIGN
+     $theword =~ s/\&oslash;/\xc3\xB8/g;
+     $theword =~ s/\&ugrave;/\xc3\xB9/g;
+     $theword =~ s/\&uacute;/\xc3\xBA/g;
+     $theword =~ s/\&ucirc;/\xc3\xBB/g;
+     $theword =~ s/\&uuml;/\xc3\xBC/g;
+     $theword =~ s/\&yacute;/\xc3\xBD/g;
+     $theword =~ s/\&thorn;/\xc3\xBE/g;
+     $theword =~ s/\&yuml;/\xc3\xBF/g;
+
+return $theword;
+
+}
diff -Nuar philomine2/philomineload/KDphilominedocload.pl philomine2patched/philomineload/KDphilominedocload.pl
--- philomine2/philomineload/KDphilominedocload.pl	1969-12-31 18:00:00.000000000 -0600
+++ philomine2patched/philomineload/KDphilominedocload.pl	2018-08-13 18:43:01.191903216 -0500
@@ -0,0 +1,715 @@
+#! /usr/bin/perl
+# ========================  philominedocload.pl  ======================
+# Generates Philomine2 document level counts of lemmas, bigrams,
+# trigrams, bigrams of lemmas and trigrams of lemmas.  Lemmas are
+# generated from the text using TreeTagger. There are a number of 
+# things that need to be investigated.  I will document more as we
+# move long.  
+# ========================== Configuration ============================
+#     Assuming that you have this in the right place, here are the
+#     configuration options. 
+#      If you want to keep the input and output files for the
+#      lemma creation (in this directory/tmp/, NOT /tmp) set to 1;
+$KEEPTreeTaggerFiles = 1;
+#      Where to find the docinfo file and the texts.  Default for
+#      standard PhiloLogic installations and loads.
+$docinfofile = "../docinfo";
+$loadedtextdir = "../TEXTS/";
+#      Use the existing cluster.filter.wrds or specify one you want.
+$filterwords = "../lib/cluster.filter.wrds";
+#     Define what's a word, but because treetagger also has it's
+#     ideas, this may be moot.
+$CHARSINWORD = "[\&A-Za-z\177-\377][\&A-Za-z\177-\377\_\';]*";
+# We think treetagger is trained to accept case sensitive, so
+# set case handling. 1 will flatten case.  I am flattening case
+# on output for lemmas and words.
+$FLATTENCASE = 0;
+#     We need to move texts into and out of TreeTagger, which
+#     currently expects Latin1.  So, put the args here.
+$ICONV = "/sw/bin/iconv -c ";    # -c to eliminate unconvertable chars
+$ICONV2TREETAGGER = $ICONV . " -f utf-8 -t latin1 ";
+$ICONVFROMTREETAGGER = $ICONV . " -f latin1 -t utf-8 ";
+#     Normal stuff.....
+$SORT = "/bin/sort";
+$GREP = "/bin/grep";
+#     List of directories to look for, etc.
+@dirs = qw(tmp/ lemmas/ bigrams/ trigrams/ bilemmas/ trilemmas/);
+#========================== End Configuration =========================
+# Of course, you may need to hack further down, but let's now worry abou
+# that now.
+
+# ============================== Read Command Line ============================
+$dblang = $ARGV[0];
+
+if ($dblang eq "-english") {
+#        $TREETAGGER = "/usr/bin/treetagger/cmd/tree-tagger-english";
+        $SPLITONAPOSTROPHE = 0;    # Set on off....
+        }
+elsif ($dblang eq "-french") {
+	#$TREETAGGER = "/usr/bin/treetagger/cmd/tree-tagger-french";
+        #$SPLITONAPOSTROPHE = 1;    # Set on off....
+        }
+elsif ($dblang eq "-greek") {
+	#$TREETAGGER = "/usr/bin/treetagger/cmd/tree-tagger-french";
+        #$SPLITONAPOSTROPHE = 1;    # Set on off....
+        #database preliminaries:
+        use DBI;		    # Set on off....
+        $dsn = "dbi:mysql:philologic:localhost";
+	$user = "philologic";
+	$pw = "martini";
+	#	Location of the sqlite greek lexicon database if loaded greektexts
+	$greekdb = "/var/www/artflsrv02/cgi-bin/perseus/GreekLexicon.db";
+        }
+else {
+        print "Usage: philominedocload -english/-french -1 \n";
+        print "The second argument is the bigram/trigram retain rate, as a percentage\n";
+        print "of the instances.  You want a small number, default - 1 percent.\n\n";
+        exit;
+}
+
+if ($ARGV[1]) {
+        $t = $ARGV[1];
+        $t =~ s/\-//;
+        $bigramretain = $t;
+        $trigramretain = $t;
+        }
+else {
+        $bigramretain = 1;               # percentage of objects
+        $trigramretain = 1;              # percentage of objects
+}
+
+print "Running with parameters $dblang and $bigramretain bi/trigram retain rate.\n";
+print "Run this? (y/n);";
+$Answer = <STDIN>;
+if ($Answer =~ /^n/i) {
+        print "\nExiting....\n";
+        exit;
+}
+
+#======================== Program starts here =========================
+print "Starting Philominedocload....\n";
+&prelimiaries();  # sets @files2read, $filterwords, creates directories
+                  # checks for certain files and directories.
+# ======================== Main Loop ==================================
+# Main Loop:  
+# -- Read in the file, fix it in various ways (fixwordsinobject), 
+# -- generate a list of lemmas in the object, which comes back as
+#    TreeTagger format which is massaged to a stream of lemmas (getlemmas).
+# -- Count store lemmas for each document: mklemmafreq 
+# -- Convert $wordsinobject into the same stream as lemmas: mkwordvector
+# -- Then for each type of "GRAM" generate a frequency list and
+#    store it in a file.
+# -- And we're done, so loop through all the documents.... more below
+# --------------------------------------------------------------------- 
+$philodocid = 0;
+foreach $filename (@files2read) {
+	$wordsinobject = "";
+	$lemmasinobject = "";
+	$wordsinobject = &readfile2buffer($filename);
+	$wordsinobject = &fixwordsinobject($wordsinobject);
+	$lemmasinobject = &getlemmas($wordsinobject);
+	&mklemmafreq($lemmasinobject);
+	$wordsinobject = mkwordvector($wordsinobject);
+	&mkrawngrams($wordsinobject, "bigrams");
+	&mkrawngrams($wordsinobject, "trigrams");
+	&mkrawngrams($lemmasinobject, "bilemmas");
+	&mkrawngrams($lemmasinobject, "trilemmas");
+	$greekwordids=""; #should probably reset this elsewhere (or not have a global variable...)
+	$philodocid++;
+}
+# ======================== End Main Loop ==============================
+#
+# ======= Accumulate ngram frequencies and prune ngrams ===============
+# At this point we have 5 directories with frequency lists for
+# lemmas, bigrams, trigrams, bilemmas, trilemmas, named 
+# PHILODOCID.rewfreq.  But all of the "grams" are very spare.  So we
+# now read through all of the gram files, count them up, and then
+# prune each GRAM file of ones that do not occur in more than 
+# a set percentage of documents.  This is simply to save time and
+# space and obviously only happens once.  At the end.
+# ---------------------------------------------------------------------
+&accumulate("bigrams");
+&prunegrams("bigrams", $bigramretain);
+&accumulate("trigrams");
+&prunegrams("trigrams", $trigramretain);
+&accumulate("bilemmas");
+&prunegrams("bilemmas", $bigramretain);
+&accumulate("trilemmas");
+&prunegrams("trilemmas", $trigramretain);
+# Clean-up here.....
+# Create the countbydoc files for featuresets
+&mkcountbydoc();
+print "\n\nSHOULD BE DONE.  CHECK YOUR OUTPUT! \n\n";
+# ========================== End of Program =========================
+
+# ===================================================================
+#                            SUBROUTINES 
+#===================================================================
+sub prunegrams {
+        local ($type, $filelist, $pat, $file, $percent, $nofdocs);
+        local ($mindoccount, $totalfile, $lin, $docs, $freq, $ngram);
+        local ($c, $outfile, $ngramstokeep, $buffer, $doc);
+        $type = $_[0];
+        $percent = $_[1];
+        $percent = $percent / 100;
+        $pat = $type . "/*.rawfreq";
+        @filelist = glob($pat);
+        $nofdocs = $#filelist;
+        $mindoccount = int($nofdocs * $percent);
+        print "Pruning $nofdocs documents in $type.\n";
+        print "Retain ngrams in $percent percent of documents\n";
+        print "Minimum document count = $mindoccount \n";
+        $totalfile = "tmp/" . $type . ".sorted";
+        open(INFILE, $totalfile)  or die "Error opening $totalfile\n";
+        while ($lin = <INFILE>) {
+                chop($lin);
+                ($docs, $freq, $ngram) = split(" ", $lin);
+                if ($docs >= $mindoccount) {
+                        $ngramstokeep{$ngram} = $docs;
+                        $c++;
+                        }
+                else {
+                        close(INFILE);
+                }
+        }
+        close (INFILE);
+        print "Kept $c ngrams.\n";
+        foreach $file (@filelist) {
+                $outfile = $file . ".test";
+                print "Pruning $file ...";
+                $x = 0;
+                $y = 0;
+                open (INFILE, $file) or die "Error opening $file \n";
+                while ($lin = <INFILE>) {
+                        $x++;
+                        chop($lin);
+                        ($ngram, $freq, $doc) = split(" ", $lin);
+                        if ($ngramstokeep{$ngram} > 1) {
+                                $buffer .= $lin . "\n";
+                                $y++;
+                                }
+                        }
+                print " Read $x $type, kept $y $type.\n";
+                close (INFILE);
+#                open (OUTFILE, ">", $file) or die "Error opening $file \n";
+                print OUTFILE $buffer;
+                $buffer = "";
+                }
+}
+
+#==================================================================
+# Subroutine: accumlate
+#==================================================================
+sub accumulate {
+        local ($type, $thecommand, $outfile);
+        $type = $_[0];
+        $thecommand = $SORT . " -b -m " . $type . "/* | ";
+        $thecommand .= $GREP . " -v \"ZZZ\" | ./accumulate.pl | ";
+        $thecommand .= $SORT . " -rn > tmp/" . $type . ".sorted";
+        print "Accumulating $type (this may take a while).... ";
+        system ("$thecommand");
+        print "Done.\n";
+}
+
+#==================================================================
+# Subroutine: mkrawngrams
+#==================================================================
+sub mkrawngrams {
+	local ($list, $type, $w, $wl, $f, $lastword, $span);
+	local ($buffer, $ngramhash, $types, $tokens, $trigram);
+	local ($secondword);
+	$list = $_[0];
+	$type = $_[1];
+	$span = 2;
+	if ($type eq "bigrams" || $type eq "bilemmas") {
+		$span = 2;
+		}
+	if ($type eq "trigrams" || $type eq "trilemmas") {
+		$span = 3;
+		}
+	$f = $type . "/" . $philodocid . ".rawfreq";
+	open(OUT, ">", $f) or die "Failed to open $f";
+	@wl = split("\n", $list);	
+	foreach $w (@wl) {
+		if ($filterwords{$w} == 1) {	
+			$w = "";
+			}
+		if ($w =~ /[A-Za-z\177-\377]/) {
+			$tokens++;
+			if ($span == 2) {
+			     if ($lastword) {
+				$bigram = $lastword . "_" . $w;
+				$ngramhash{$bigram} += 1;
+				}
+			     $lastword = $w;
+			     }
+			if ($span == 3) {
+			     if ($secondword && $lastword) {
+			        $trigram = $lastword . "_" . $secondword;
+				$trigram .= "_" . $w;
+				$ngramhash{$trigram} += 1;
+				}
+			     $lastword = $secondword;
+			     $secondword = $w;
+			     }
+			}
+		}
+	$buffer = "";
+        foreach $w (sort keys (%ngramhash)) {
+                $types++;
+                $buffer .= $w . " " . $ngramhash{$w} . " ".  $philodocid . "\n";
+		delete $ngramhash{$w};
+                }
+        $buffer .= "ZZZ:TYPECOUNT " . $types . "\n";
+        $buffer .= "ZZZ:TOKENCOUNT " . $tokens;
+        $buffer .= "\n";
+	print OUT $buffer;
+	close (OUT);
+	print "Wrote $types $type to $f \n";
+return;
+}
+#==================================================================
+# Subroutine: mkwordvector
+#==================================================================
+sub mkwordvector {
+	local ($words, $wordlist, $w, $rtn);
+	$words = $_[0];
+	$words =~ s/\n/ /g;
+	$words =~ s/($CHARSINWORD)/\n$1\n/g;
+# Flatten case here, since we always want them flat, whereas treetagger likes case.
+        $words =~ tr/A-Z/a-z/;
+        $words =~ s/\xc3([\x80-\x9E])/&up2low($1)/ge;
+	if ($SPLITONAPOSTROPHE) {
+		$words =~ s/\'/\n/g;
+		}
+	@wordlist = split("\n", $words);
+	foreach $w (@wordlist) {
+		$rtn .= $w . "\n";
+		}
+	undef @wordlist;
+return $rtn;
+}
+
+#==================================================================
+# Subroutine: mklemmafreq
+#==================================================================
+sub mklemmafreq {
+	local ($w, $wl, $type, $token, $whash, $lemmalist, $thisfile);
+	$lemmalist = $_[0];
+	@wl = split("\n", $lemmalist);
+	foreach $w (@wl) {
+		$whash{$w} += 1;
+		}
+	$thisfile = "lemmas/" . $philodocid . ".rawfreq";
+	open (LEM, ">", $thisfile) or die "Error opening $thisfile\n";
+	foreach $w (sort keys (%whash)) {
+		print LEM "$w $whash{$w} $philodocid\n";
+		$type++;
+		$token += $whash{$w};
+		delete $whash{$w};
+		}
+	print LEM "ZZZ:TYPECOUNT $type\n";
+	print LEM "ZZZ:TOKENCOUNT $token\n";
+	close (LEM);
+	print "Wrote $type lemmas to $thisfile\n";
+}
+		
+#==================================================================
+# Subroutine: getlemmas.  
+# IMPORTANT: In cases where we get 2 resolutions for a lemma, I
+# am taking the first.  This is probably not a great idea.  TreeTagger
+# does not disambiguate everything.
+#==================================================================
+sub getlemmas {
+	local ($wordlist, $thecommand, $lin, $lemme, $pos, $surface);
+	local ($words, $a, $b, $w, $rtn);
+	$words = $_[0];
+	
+	if ($dblang eq "-greek") {
+		#connect to sqlite database
+		$dbh = DBI->connect("DBI:SQLite:dbname=$greekdb", '','', {AutoCommit , 1}) or die "ACK: couldn't connect to sqlite - $!";
+		my @ids = split("\n", $greekwordids);
+		foreach $id (@ids) {
+			$lemme = &LemmaFinder($id);
+			if ($lemme) {
+				$rtn .= $lemme . "\n";
+				}
+			}
+		if ($FLATTENCASE) {
+			$rtn = &greekup2low($rtn);
+		}
+		undef @ids;
+	}
+	
+	else {
+# We may need some addition cleaning here
+	open (TFILE, ">tmp/TEMPTEXT") or die "Failed to open tmp/TEMPTEXT\n";
+	print TFILE $words;
+	close (TFILE);
+	$words = "";
+	$thecommand = "cat tmp/TEMPTEXT | " . $ICONV2TREETAGGER . " | ";
+	$thecommand .= $TREETAGGER . " | " . $ICONVFROMTREETAGGER ;
+	$thecommand .= " > tmp/TREETAGOUT";
+	system ("$thecommand");
+	open (TFILE, "tmp/TREETAGOUT") or die "Failed to open tmp/TREETAGOUT\n";
+	while ($lin = <TFILE>) {
+        	chop($lin);
+		$lin =~ s/\015//g;
+                ($surface, $pos, $lemme) = split("\t", $lin);
+                if ($lemme eq "<unknown>") {
+                        $lemme = $surface;
+                        }
+                if ($lemme eq "\@card\@") {
+                        $lemme = "";
+                        }
+                if ($pos =~ /SENT/ || $pos =~ /PUN/) {
+                        $lemme = "";
+                        }
+                if ($lemme) {
+                        $lemme = lc($lemme);
+			$lemme =~ s/\xc3([\x80-\x9E])/&up2low($1)/ge;
+			if ($lemme =~ /\|/) {
+				$lemme =~ s/\|/\t/g;
+				($a, $b) = split("\t", $lemme);
+				$lemme = $a;
+				}
+			if ($lemme =~ m/([A-Za-z\177-\377]*)/) {
+				$lemme = $1;
+				}
+			else {
+				$lemme = "";
+				}
+# May need more cleaning here too.
+			if ($lemme) {
+                        	push (@wordlist, $lemme);
+				}
+                        }
+                }
+	foreach $w (@wordlist) {
+		$rtn .= $w . "\n";
+		}
+# Keep in the inout/out for TreeTagger.  Very helpful to see just
+# how this is behaving.
+	if ($KEEPTreeTaggerFiles) {
+		$preservethisfile = "tmp/TREETAGOUT." . $philodocid;
+		system ("cp tmp/TREETAGOUT $preservethisfile");
+		$preservethisfile = "tmp/TEMPTEXT." . $philodocid;
+		system ("cp tmp/TEMPTEXT $preservethisfile");
+		}
+        system ("rm tmp/TREETAGOUT");
+        system ("rm tmp/TEMPTEXT");
+	undef @wordlist;
+}
+return $rtn;
+}
+
+#==================================================================
+# Subroutine: fixwordsinobject
+#==================================================================
+sub fixwordsinobject {
+	local ($wordsinobject);
+	$wordsinobject = $_[0];
+        if ($FLATTENCASE) {
+              $wordsinobject =~ tr/A-Z/a-z/;
+              $wordsinobject =~ s/\xc3([\x80-\x9E])/&up2low($1)/ge;
+              if ($dblang eq "-greek") {
+              	$wordsinobject = &greekup2low($wordsinobject);
+              	}
+	      }
+	if ($dblang eq "-greek") {
+	      $greekwordids;
+	      my $idedwordsinobject; #will replace wordsinobject with only those words in word tags
+	      while ($wordsinobject =~ /<w id="([0-9]*)">([^<]*)<\/w>/gi){
+	      	$greekwordids .= $1 . "\n";
+	      	$idedwordsinobject .= $2 . " "; #add to idedwordsinobject
+	      	}
+	      $wordsinobject = $idedwordsinobject; #replace with only tagged words
+	      $wordsinobject =~ s/\xe2\x80[\x9c\x9d]/ /g; #curly quotes
+	      $wordsinobject =~ s/<note [^>]*>.*?<\/note>//gi;	#take out things in note tags
+	      $wordsinobject =~ s/<bibl [^>]*>.*?<\/bibl>//gi;	#take out things in bibl tags;
+              $wordsinobject =~ s/([a-z])-([a-z])/$1 $2/gi;
+      	      $wordsinobject =~ s/[\.\,\?\(\)\:\;\"\!\*\'\`\[\]|]/ /g;
+      	      $wordsinobject =~ s/ +/ /gi;
+	      }
+	      
+        $wordsinobject = charents2utf8($wordsinobject);
+        $wordsinobject =~ s/<[^>]*>/ /g;
+        $wordsinobject =~ s/\&[^;]*;/ /g;
+        $wordsinobject =~ s/;/ /g;
+        $wordsinobject =~ s/\-/ /g;
+	$wordsinobject =~ s/[0-9]/ /g;
+
+	$wordsinobject =~ s/\xe2\x80\x91/ /g; # Windows Hyphen.
+	$wordsinobject =~ s/\xe2\x80\x94/ /g; # Another Oddball
+return ($wordsinobject);
+}
+
+#==================================================================
+# Subroutine: readfile2buffer
+#==================================================================
+sub readfile2buffer {
+	local ($filename, $thisfile, $inthetext, $lin, $rtn);
+	$filename = $_[0];
+	$thisfile = $loadedtextdir . $filename;
+	$inthetext = 0;
+	print "Reading $philodocid: $filename ... \n";
+	open (DOC, $thisfile) or die "Cannot open $thisfile!\n";
+	while ($lin = <DOC>) {
+             if ($lin =~ /<text>/ || $lin =~ /<body>/ || $lin =~ /<div/) {
+                $inthetext = 1;
+                }
+	     if ($lin =~ /<h1>/i || $lin =~ /<\/head>/i) {
+                $inthetext = 1;
+                }
+             if ($lin =~ /<div1 type="notes">/i) {
+             	$inthetext = 0;
+             }
+             if ($inthetext) {
+                $rtn .= $lin;
+                }       
+             }
+return ($rtn);
+}
+
+#==================================================================
+# Subroutine: preliminaries, just to get things rolling.
+#==================================================================
+sub prelimiaries {
+     local ($c, $lin, $dir);
+
+     die "Cannot find $loadedtextdir " unless -d $loadedtextdir;
+
+     open (DOCFILE, $docinfofile) or die "Cannot open $docinfofile!\n";
+     while ($lin = <DOCFILE>) {
+             chop($lin);
+             @results = split(" ", $lin);
+             push (@files2read, $results[0]);
+             $c++;
+             }
+     close(DOCFILE);
+     print "Read in $c filenames to load from $docinfofile\n";
+     
+     $c = 0;
+     open (FILTERWORDS, $filterwords) or die "Cannot open $filterwords!\n";
+     while ($lin = <FILTERWORDS>) {
+             chop($lin);
+             $filterwords{$lin} = 1;
+     	     $c++;
+             }
+     close (FILTERWORDS);
+     print "Read in $c filter words from $filterwords\n";
+     
+     foreach $dir (@dirs) {
+             mkdir($dir) unless -d $dir;
+     	     }
+     return;
+}
+
+#==================================================================
+# Subroutine: up2low, try to lower case French accents.  I'm sure
+# there is a better way.
+#==================================================================
+sub up2low {
+      local ($onechar, $rtn);
+      $onechar = $_[0];
+      $onechar =~ tr/\x80-\x9E/\xA0-\xBE/;
+      $rtn = "\xc3" . $onechar;
+return $rtn;
+}
+
+#==================================================================
+# greekup2low: greekup2low, try to lower case Greek letters. It works,
+# but is a bit messy
+#==================================================================
+sub greekup2low {
+	my $line = lc($_[0]);
+
+    #Upper to Lowercase
+	$line =~ s/\xce\x91/\xce\xb1/gi;
+	$line =~ s/\xce\x92/\xce\xb2/gi;
+	$line =~ s/\xce\x93/\xce\xb3/gi;
+	$line =~ s/\xce\x94/\xce\xb4/gi;
+	$line =~ s/\xce\x95/\xce\xb5/gi;
+	$line =~ s/\xce\x96/\xce\xb6/gi;
+	$line =~ s/\xce\x97/\xce\xb7/gi;
+	$line =~ s/\xce\x98/\xce\xb8/gi;
+	$line =~ s/\xce\x99/\xce\xb9/gi;
+	$line =~ s/\xce\x9a/\xce\xba/gi;
+	$line =~ s/\xce\x9b/\xce\xbb/gi;
+	$line =~ s/\xce\x9c/\xce\xbc/gi;
+	$line =~ s/\xce\x9d/\xce\xbd/gi;
+	$line =~ s/\xce\x9e/\xce\xbe/gi;
+	$line =~ s/\xce\x9f/\xce\xbf/gi;
+	$line =~ s/\xce\xa0/\xcf\x80/gi;
+	$line =~ s/\xce\xa1/\xcf\x81/gi;
+	$line =~ s/\xce\xa3( |$)/\xcf\x82$1/gi;
+	$line =~ s/\xce\xa3/\xcf\x83/gi;
+	$line =~ s/\xce\xa4/\xcf\x84/gi;
+	$line =~ s/\xce\xa5/\xcf\x85/gi;
+	$line =~ s/\xce\xa6/\xcf\x86/gi;
+	$line =~ s/\xce\xa7/\xcf\x87/gi;
+	$line =~ s/\xce\xa8/\xcf\x88/gi;
+	$line =~ s/\xce\xa9/\xcf\x89/gi;
+	$line =~ s/\xe1\xbf[\xa4\xa5]/\xcf\x81/gi; ## rhos
+	$line =~ s/\xe1\xbf\xac/\xcf\x81/gi;
+	
+	$line = Encode::decode("utf8", $line);	
+	$line =~ tr/\x{1F08}-\x{1F0F}/\x{1F00}-\x{1F07}/; ## alphas
+	$line =~ tr/\x{1F88}-\x{1F8F}/\x{1F80}-\x{1F87}/;
+	$line =~ tr/\x{0386}\x{1FBC}\x{1FB8}-\x{1FBB}/\x{03AC}\x{1FB3}\x{1FB0}\x{1FB1}\x{1F70}\x{1F71}/;
+	$line =~ tr/\x{1F18}-\x{1F1D}/\x{1F10}-\x{1F15}/; ## epsilons
+	$line =~ tr/\x{1FC8}\x{1FC9}\x{0388}/\x{1F72}\x{1F73}\x{03AD}/;
+	$line =~ tr/\x{1F28}-\x{1F2F}/\x{1F20}-\x{1F27}/; ## etas
+	$line =~ tr/\x{1F98}-\x{1F9F}/\x{1F90}-\x{1F97}/;
+	$line =~ tr/\x{0389}\x{1F74}\x{1FCA}-\x{1FCC}/\x{03AE}\x{1FB0}\x{1F74}\x{1F75}\x{1FC3}/;
+	$line =~ tr/\x{1F38}-\x{1F3F}/\x{1F30}-\x{1F37}/; ## iotas
+	$line =~ tr/\x{03AA}\x{038A}\x{1FD8}-\x{1FDB}/\x{03CA}\x{03AF}\x{1FD0}\x{1FD1}\x{1F76}\x{1F77}/;
+	$line =~ tr/\x{1F48}-\x{1F4D}/\x{1F40}-\x{1F45}/; ## omicrons
+	$line =~ tr/\x{1FF8}\x{1FF9}\x{038C}/\x{1F78}\x{1F79}\x{03CC}/;
+	$line =~ tr/\x{1F58}-\x{1F5F}/\x{1F50}-\x{1F57}/; ## upsilons
+	$line =~ tr/\x{1FE8}-\x{1FEB}\x{038E}\x{03AB}/\x{1FE0}\x{1FE1}\x{1F7A}\x{1F7B}\x{03CB}\x{03CC}/;
+	$line =~ tr/\x{1F68}-\x{1F6F}/\x{1F60}-\x{1F67}/; ## omegas
+	$line =~ tr/\x{1FA8}-\x{1FAF}/\x{1FA0}-\x{1FA7}/;
+	$line =~ tr/\x{038F}\x{2126}\x{1FFA}-\x{1FFC}/\x{03CE}\x{03C9}\x{1FF2}\x{1FF4}\x{1FF3}/;
+	return Encode::encode("utf8", $line);
+}
+
+#==================================================================
+# Subroutine: LemmaFinder, retrieve lemma from sqlite database,
+# given a wordid (make sure you are using the correct database)
+#==================================================================
+sub LemmaFinder {
+	$wordid = $_[0];
+	my $lemma;
+	$parsequery = $dbh->prepare("select * from parses where tokenid=\"$wordid\" order by prob desc limit 1;");
+	$parsequery->execute();
+	my $parse = $parsequery->fetchrow_hashref();
+	if ($parse->{lex}){
+		$lexid = $parse->{lex};
+		$lemmaquery = $dbh->prepare("select lemma from Lexicon where lexid=\"$lexid\";");
+		$lemmaquery->execute();
+		$lemma = $lemmaquery->fetchrow_array();	
+	}
+	else {
+		$lemma = $parse->{lemma};
+	}
+	
+	if ($lemma eq "<unknown>") {
+		$tokenquery = $dbh->prepare("select content from tokens where tokenid=\"$wordid\";");
+		$tokenquery->execute();
+		$lemma = $tokenquery->fetchrow_array();
+	}
+	return $lemma;
+} 
+
+#==================================================================
+# Subroutine: charents2utf8, convert ents to utf-8.
+#==================================================================
+sub charents2utf8 () {
+     local ($theword); 
+     $theword = $_[0];
+     $theword =~ s/\&Agrave;/\xc3\x80/g; 
+     $theword =~ s/\&Aacute;/\xc3\x81/g; 
+     $theword =~ s/\&Acirc;/\xc3\x82/g;
+     $theword =~ s/\&Atilde;/\xc3\x83/g;
+     $theword =~ s/\&Auml;/\xc3\x84/g;
+     $theword =~ s/\&Aring;/\xc3\x85/g;
+     $theword =~ s/\&Ccedil;/\xc3\x87/g;
+     $theword =~ s/\&Egrave;/\xc3\x88/g;
+     $theword =~ s/\&Eacute;/\xc3\x89/g;
+     $theword =~ s/\&Ecirc;/\xc3\x8A/g;
+     $theword =~ s/\&Euml;/\xc3\x8B/g;
+     $theword =~ s/\&Igrave;/\xc3\x8C/g;
+     $theword =~ s/\&Iacute;/\xc3\x8D/g;
+     $theword =~ s/\&Icirc;/\xc3\x8E/g;
+     $theword =~ s/\&Iuml;/\xc3\x8F/g;
+     $theword =~ s/\&ETH;/\xc3\x90/g;
+     $theword =~ s/\&Ntilde;/\xc3\x91/g;
+     $theword =~ s/\&Ograve;/\xc3\x92/g;
+     $theword =~ s/\&Oacute;/\xc3\x93/g;
+     $theword =~ s/\&Ocirc;/\xc3\x94/g;
+     $theword =~ s/\&Otilde;/\xc3\x95/g;
+     $theword =~ s/\&Ouml;/\xc3\x96/g;
+     $theword =~ s/\&#215;/\xc3\x97/g; # MULTIPLICATION SIGN
+     $theword =~ s/\&Oslash;/\xc3\x98/g;
+     $theword =~ s/\&Ugrave;/\xc3\x99/g;
+     $theword =~ s/\&Uacute;/\xc3\x9A/g;
+     $theword =~ s/\&Ucirc;/\xc3\x9B/g;
+     $theword =~ s/\&Uuml;/\xc3\x9C/g;
+     $theword =~ s/\&Yacute;/\xc3\x9D/g;
+     $theword =~ s/\&THORN;/\xc3\x9E/g;
+     $theword =~ s/\&agrave;/\xc3\xA0/g;
+     $theword =~ s/\&aacute;/\xc3\xA1/g;
+     $theword =~ s/\&acirc;/\xc3\xA2/g;
+     $theword =~ s/\&atilde;/\xc3\xA3/g;
+     $theword =~ s/\&auml;/\xc3\xA4/g;
+     $theword =~ s/\&aring;/\xc3\xA5/g;
+     $theword =~ s/\&ccedil;/\xc3\xA7/g;
+     $theword =~ s/\&egrave;/\xc3\xA8/g;
+     $theword =~ s/\&eacute;/\xc3\xA9/g;
+     $theword =~ s/\&ecirc;/\xc3\xAA/g;
+     $theword =~ s/\&euml;/\xc3\xAB/g;
+     $theword =~ s/\&igrave;/\xc3\xAC/g;
+     $theword =~ s/\&iacute;/\xc3\xAD/g;
+     $theword =~ s/\&icirc;/\xc3\xAE/g;
+     $theword =~ s/\&iuml;/\xc3\xAF/g;
+     $theword =~ s/\&eth;/\xc3\xB0/g;
+     $theword =~ s/\&ntilde;/\xc3\xB1/g;
+     $theword =~ s/\&ograve;/\xc3\xB2/g;
+     $theword =~ s/\&oacute;/\xc3\xB3/g;
+     $theword =~ s/\&ocirc;/\xc3\xB4/g;
+     $theword =~ s/\&otilde;/\xc3\xB5/g;
+     $theword =~ s/\&ouml;/\xc3\xB6/g;
+     $theword =~ s/\&#247;/\xc3\xB7/g;   #  DIVISION SIGN
+     $theword =~ s/\&oslash;/\xc3\xB8/g;
+     $theword =~ s/\&ugrave;/\xc3\xB9/g;
+     $theword =~ s/\&uacute;/\xc3\xBA/g;
+     $theword =~ s/\&ucirc;/\xc3\xBB/g;
+     $theword =~ s/\&uuml;/\xc3\xBC/g;
+     $theword =~ s/\&yacute;/\xc3\xBD/g;
+     $theword =~ s/\&thorn;/\xc3\xBE/g;
+     $theword =~ s/\&yuml;/\xc3\xBF/g;
+
+return $theword;
+
+}
+
+#==================================================================
+# Subroutine: mkcountbydoc, make count files for featuresets so we
+# can get the total features values for each philodocid for each
+# featureset, for use in filtering instances by total feature value
+#==================================================================
+sub mkcountbydoc() {
+	@featuresets = ('bigrams', 'bilemmas', 'lemmas');
+
+	foreach $featureset (@featuresets) {
+
+	    opendir(FDIR, $featureset) || die("Cannot open directory $featureset");
+	    @files = readdir(FDIR);
+	    closedir(FDIR);
+	    sort(@files);
+    
+	    open FOUT, ">countbydocid.$featureset";
+    
+		foreach $file (@files) {
+			if ($file =~ /(\d+)\.rawfreq/) {
+
+			    $instance = $1;
+				print "File: $file instance: $instance\n\n";
+			    $total = 0;
+			    open FIN, "$featureset/$file";
+			    while ($line = <FIN>) {
+					if ($line =~ /^\S+ (\S+) \S+$/) {
+				    	$total += $1;
+					}
+				}
+				print FOUT $instance . "\t" . $total . "\n";
+			}
+		}
+
+	    close FOUT;
+	    $res = `sort -n countbydocid.$featureset > tmp.srt`;
+	    $res = `mv tmp.srt countbydocid.$featureset`;
+	}
+}
+
